{"data":{"log_version":3,"version":"2.0.0-preview.8"},"info":{"category":"","code":"1005","extra":{},"invocation_id":"01991a9f-fd86-7a51-ade4-06aa9510b088","level":"error","msg":"error: dbt1005: Source 'dbt-project.dim_customer' not found in project. Searched for 'dim_customer'\n  --> models\\bronze\\bronze_sales.sql:3:12","name":"Generic","pid":21148,"thread":"tokio-runtime-worker","ts":"2025-09-05T16:05:18.091064Z"}}
{"data":{"completed_at":"2025-09-05T16:05:18.201974","elapsed":1.2925684452056885,"log_version":3,"success":false,"version":"2.0.0-preview.8"},"info":{"category":"","code":"","elapsed":"1.2925684452056885","extra":{},"invocation_id":"01991a9f-fd86-7a51-ade4-06aa9510b088","level":"info","msg":"  Finished 'show' target 'dev' with 1 error in 1s 291ms","name":"CommandCompleted","pid":21148,"thread":"tokio-runtime-worker","ts":"2025-09-05T16:05:18.259945Z"}}
[0m06:29:57.486573 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 06:29:57.561574 | cd0efc74-6402-4eae-b4e0-97246ae254ff ==============================
[0m06:29:57.561574 [info ] [MainThread]: Running with dbt=1.10.11
[0m06:29:57.561574 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt ', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m06:29:57.706572 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:29:57.708749 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m06:29:57.709761 [debug] [MainThread]: Command `cli deps` succeeded at 06:29:57.709761 after 0.28 seconds
[0m06:29:57.710759 [debug] [MainThread]: Flushing usage events
[0m07:12:06.391078 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 07:12:06.461015 | e03afcc4-1a7e-482c-afe7-22ce234ceb1a ==============================
[0m07:12:06.461015 [info ] [MainThread]: Running with dbt=1.10.11
[0m07:12:06.461015 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'empty': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m07:12:07.287487 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m07:12:07.287487 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m07:12:07.287487 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m07:12:08.199224 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m07:12:08.580784 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m07:12:08.741335 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:12:08.741899 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:12:08.743111 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m07:12:08.853323 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m07:12:08.887079 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m07:12:08.909329 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m07:12:08.912415 [info ] [MainThread]: 
[0m07:12:08.913529 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:12:08.913529 [info ] [MainThread]: 
[0m07:12:08.914543 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m07:12:08.914543 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m07:12:08.923860 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m07:12:08.923860 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m07:12:08.923860 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m07:12:08.925894 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m07:12:08.925894 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:12:09.977527 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d43-eb4b-1830-9d45-682278f63e0b) - Created
[0m07:12:10.637269 [debug] [ThreadPool]: SQL status: OK in 1.710 seconds
[0m07:12:10.637269 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d43-eb4b-1830-9d45-682278f63e0b, command-id=01f08d43-eb72-1c9c-be44-1936bb612f92) - Closing
[0m07:12:10.637269 [debug] [ThreadPool]: On list_dbt-project: Close
[0m07:12:10.637269 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d43-eb4b-1830-9d45-682278f63e0b) - Closing
[0m07:12:10.952177 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_source) - Creating connection
[0m07:12:10.952177 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_source'
[0m07:12:10.967838 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_source"
[0m07:12:10.967838 [debug] [ThreadPool]: On list_dbt-project_source: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_source"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'source'

  
[0m07:12:10.967838 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:12:12.069739 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d43-ec76-190b-8740-9dbad47b4f7b) - Created
[0m07:12:13.352737 [debug] [ThreadPool]: SQL status: OK in 2.380 seconds
[0m07:12:13.363801 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d43-ec76-190b-8740-9dbad47b4f7b, command-id=01f08d43-ecb4-125c-b67e-2df71480f394) - Closing
[0m07:12:13.363801 [debug] [ThreadPool]: On list_dbt-project_source: Close
[0m07:12:13.363801 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d43-ec76-190b-8740-9dbad47b4f7b) - Closing
[0m07:12:13.684189 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m07:12:13.684189 [info ] [Thread-3 (]: 1 of 4 START sql view model source.bronze_customer ............................. [RUN]
[0m07:12:13.684189 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m07:12:13.684189 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m07:12:13.684189 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m07:12:13.720200 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m07:12:13.742856 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m07:12:13.774624 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:12:13.776628 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m07:12:13.804128 [debug] [Thread-3 (]: Creating view `dbt-project`.`source`.`bronze_customer`
[0m07:12:13.810233 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m07:12:13.810233 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m07:12:13.810233 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`source`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m07:12:13.810233 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:12:14.955462 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-ee3a-1f36-88a2-5a85e0422ee5) - Created
[0m07:12:15.864351 [debug] [Thread-3 (]: SQL status: OK in 2.050 seconds
[0m07:12:15.866347 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d43-ee3a-1f36-88a2-5a85e0422ee5, command-id=01f08d43-ee6b-1b9a-900f-d15d014d64a5) - Closing
[0m07:12:15.877319 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:12:15.879322 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m07:12:15.879322 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-ee3a-1f36-88a2-5a85e0422ee5) - Closing
[0m07:12:16.239288 [info ] [Thread-3 (]: 1 of 4 OK created sql view model source.bronze_customer ........................ [[32mOK[0m in 2.55s]
[0m07:12:16.239288 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m07:12:16.239288 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m07:12:16.239288 [info ] [Thread-3 (]: 2 of 4 START sql view model source.bronze_date ................................. [RUN]
[0m07:12:16.245927 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m07:12:16.245927 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m07:12:16.245927 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m07:12:16.245927 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m07:12:16.245927 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m07:12:16.245927 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:12:16.245927 [debug] [Thread-3 (]: Creating view `dbt-project`.`source`.`bronze_date`
[0m07:12:16.245927 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m07:12:16.245927 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m07:12:16.245927 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`source`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m07:12:16.245927 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:12:17.355334 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-efa8-11f6-ae91-b40b516d0539) - Created
[0m07:12:18.353590 [debug] [Thread-3 (]: SQL status: OK in 2.110 seconds
[0m07:12:18.353590 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d43-efa8-11f6-ae91-b40b516d0539, command-id=01f08d43-efd9-19e5-b1a7-c7e831214cee) - Closing
[0m07:12:18.353590 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:12:18.353590 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m07:12:18.353590 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-efa8-11f6-ae91-b40b516d0539) - Closing
[0m07:12:18.629929 [info ] [Thread-3 (]: 2 of 4 OK created sql view model source.bronze_date ............................ [[32mOK[0m in 2.39s]
[0m07:12:18.629929 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m07:12:18.629929 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_product
[0m07:12:18.629929 [info ] [Thread-3 (]: 3 of 4 START sql view model source.bronze_product .............................. [RUN]
[0m07:12:18.629929 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_product) - Creating connection
[0m07:12:18.629929 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_product'
[0m07:12:18.629929 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_product
[0m07:12:18.629929 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_product"
[0m07:12:18.647915 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_product
[0m07:12:18.657042 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:12:18.657042 [debug] [Thread-3 (]: Creating view `dbt-project`.`source`.`bronze_product`
[0m07:12:18.657042 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_product"
[0m07:12:18.657042 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_product"
[0m07:12:18.657042 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_product"} */

  
  
  create or replace view `dbt-project`.`source`.`bronze_product`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m07:12:18.657042 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:12:20.072467 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-f12e-1864-9257-c90548b07dbe) - Created
[0m07:12:20.798946 [debug] [Thread-3 (]: SQL status: OK in 2.140 seconds
[0m07:12:20.799947 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d43-f12e-1864-9257-c90548b07dbe, command-id=01f08d43-f178-1d9b-bfe4-912d3a5395b5) - Closing
[0m07:12:20.800946 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:12:20.800946 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: Close
[0m07:12:20.801947 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-f12e-1864-9257-c90548b07dbe) - Closing
[0m07:12:21.191747 [info ] [Thread-3 (]: 3 of 4 OK created sql view model source.bronze_product ......................... [[32mOK[0m in 2.56s]
[0m07:12:21.191747 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_product
[0m07:12:21.192840 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m07:12:21.192840 [info ] [Thread-3 (]: 4 of 4 START sql view model source.bronze_sales ................................ [RUN]
[0m07:12:21.193811 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m07:12:21.193811 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m07:12:21.194846 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m07:12:21.198747 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m07:12:21.199747 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m07:12:21.202753 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:12:21.203378 [debug] [Thread-3 (]: Creating view `dbt-project`.`source`.`bronze_sales`
[0m07:12:21.204735 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m07:12:21.205871 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m07:12:21.205871 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`source`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m07:12:21.206813 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:12:22.506293 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-f2b6-1656-9ca8-9a4cac0523e5) - Created
[0m07:12:23.283413 [debug] [Thread-3 (]: SQL status: OK in 2.080 seconds
[0m07:12:23.283413 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d43-f2b6-1656-9ca8-9a4cac0523e5, command-id=01f08d43-f2ea-158f-a90c-95a84c1ab174) - Closing
[0m07:12:23.283413 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:12:23.283413 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m07:12:23.283413 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d43-f2b6-1656-9ca8-9a4cac0523e5) - Closing
[0m07:12:23.587418 [info ] [Thread-3 (]: 4 of 4 OK created sql view model source.bronze_sales ........................... [[32mOK[0m in 2.39s]
[0m07:12:23.587418 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m07:12:23.587418 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m07:12:23.587418 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m07:12:23.587418 [info ] [MainThread]: 
[0m07:12:23.587418 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 14.67 seconds (14.67s).
[0m07:12:23.604228 [debug] [MainThread]: Command end result
[0m07:12:23.736028 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m07:12:23.741281 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m07:12:23.748214 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m07:12:23.748743 [info ] [MainThread]: 
[0m07:12:23.749281 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:12:23.749845 [info ] [MainThread]: 
[0m07:12:23.750533 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m07:12:23.751596 [debug] [MainThread]: Command `dbt run` succeeded at 07:12:23.751596 after 17.43 seconds
[0m07:12:23.752184 [debug] [MainThread]: Flushing usage events
[0m07:15:19.721462 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 07:15:19.781343 | 6bcb0f98-f736-4236-9122-1d22d4a275e4 ==============================
[0m07:15:19.781343 [info ] [MainThread]: Running with dbt=1.10.11
[0m07:15:19.781343 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m07:15:20.587359 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m07:15:20.589365 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m07:15:20.589365 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m07:15:21.352459 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m07:15:21.686280 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m07:15:21.815604 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:15:21.815604 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:15:21.815604 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m07:15:21.914694 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m07:15:21.914694 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m07:15:21.930052 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m07:15:21.945727 [info ] [MainThread]: 
[0m07:15:21.945727 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:15:21.945727 [info ] [MainThread]: 
[0m07:15:21.945727 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m07:15:21.945727 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m07:15:21.953279 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m07:15:21.953279 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m07:15:21.953279 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m07:15:21.953279 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m07:15:21.953279 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:15:23.272294 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d44-5e77-192b-b1c3-6b480950ab87) - Created
[0m07:15:23.756145 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m07:15:23.758159 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d44-5e77-192b-b1c3-6b480950ab87, command-id=01f08d44-5ea6-1d84-a3a4-2e57f8196a65) - Closing
[0m07:15:23.758159 [debug] [ThreadPool]: On list_dbt-project: Close
[0m07:15:23.758159 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d44-5e77-192b-b1c3-6b480950ab87) - Closing
[0m07:15:24.062604 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m07:15:24.078486 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m07:15:24.078486 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m07:15:24.078486 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m07:15:24.094598 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:15:25.191560 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d44-5f9c-1c36-ab37-c181ade9a854) - Created
[0m07:15:25.822584 [debug] [ThreadPool]: SQL status: OK in 1.730 seconds
[0m07:15:25.838540 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d44-5f9c-1c36-ab37-c181ade9a854, command-id=01f08d44-5fd0-1c11-8ff0-4430931220d5) - Closing
[0m07:15:25.838540 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m07:15:25.838540 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d44-5f9c-1c36-ab37-c181ade9a854) - Closing
[0m07:15:26.164058 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m07:15:26.164058 [info ] [Thread-3 (]: 1 of 4 START sql view model default.bronze_customer ............................ [RUN]
[0m07:15:26.164058 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m07:15:26.164058 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m07:15:26.164058 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m07:15:26.164058 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m07:15:26.164058 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m07:15:26.186382 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:15:26.186382 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m07:15:26.208287 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customer`
[0m07:15:26.219097 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m07:15:26.219097 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m07:15:26.219097 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m07:15:26.219097 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:15:27.427918 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-60f2-1971-9214-6e330afcf06d) - Created
[0m07:15:28.226776 [debug] [Thread-3 (]: SQL status: OK in 2.010 seconds
[0m07:15:28.226776 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d44-60f2-1971-9214-6e330afcf06d, command-id=01f08d44-6123-1861-b2e1-917d852c8317) - Closing
[0m07:15:28.251094 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:15:28.253094 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m07:15:28.254132 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-60f2-1971-9214-6e330afcf06d) - Closing
[0m07:15:28.562922 [info ] [Thread-3 (]: 1 of 4 OK created sql view model default.bronze_customer ....................... [[32mOK[0m in 2.39s]
[0m07:15:28.563939 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m07:15:28.565017 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m07:15:28.565017 [info ] [Thread-3 (]: 2 of 4 START sql view model default.bronze_date ................................ [RUN]
[0m07:15:28.565957 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m07:15:28.565957 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m07:15:28.566964 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m07:15:28.569963 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m07:15:28.570965 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m07:15:28.572964 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:15:28.573964 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m07:15:28.574964 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m07:15:28.575963 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m07:15:28.575963 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m07:15:28.576964 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:15:29.834980 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-6263-1407-9b84-e58413bcf092) - Created
[0m07:15:30.636561 [debug] [Thread-3 (]: SQL status: OK in 2.060 seconds
[0m07:15:30.637569 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d44-6263-1407-9b84-e58413bcf092, command-id=01f08d44-6298-1617-a1a2-679460b838ea) - Closing
[0m07:15:30.639583 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:15:30.641589 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m07:15:30.641589 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-6263-1407-9b84-e58413bcf092) - Closing
[0m07:15:30.945742 [info ] [Thread-3 (]: 2 of 4 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.38s]
[0m07:15:30.945742 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m07:15:30.945742 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_product
[0m07:15:30.945742 [info ] [Thread-3 (]: 3 of 4 START sql view model default.bronze_product ............................. [RUN]
[0m07:15:30.945742 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_product) - Creating connection
[0m07:15:30.945742 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_product'
[0m07:15:30.945742 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_product
[0m07:15:30.961629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_product"
[0m07:15:30.963091 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_product
[0m07:15:30.969227 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:15:30.970228 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_product`
[0m07:15:30.971226 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_product"
[0m07:15:30.971226 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_product"
[0m07:15:30.972224 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_product"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_product`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m07:15:30.973474 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:15:32.158005 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-63d0-1246-ae6c-5a79d67e9740) - Created
[0m07:15:33.031295 [debug] [Thread-3 (]: SQL status: OK in 2.060 seconds
[0m07:15:33.031295 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d44-63d0-1246-ae6c-5a79d67e9740, command-id=01f08d44-63f3-11e0-abdb-578e060f70ec) - Closing
[0m07:15:33.031295 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:15:33.031295 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: Close
[0m07:15:33.031295 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-63d0-1246-ae6c-5a79d67e9740) - Closing
[0m07:15:33.350518 [info ] [Thread-3 (]: 3 of 4 OK created sql view model default.bronze_product ........................ [[32mOK[0m in 2.40s]
[0m07:15:33.354995 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_product
[0m07:15:33.354995 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m07:15:33.354995 [info ] [Thread-3 (]: 4 of 4 START sql view model default.bronze_sales ............................... [RUN]
[0m07:15:33.354995 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m07:15:33.354995 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m07:15:33.354995 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m07:15:33.366628 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m07:15:33.367776 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m07:15:33.371429 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m07:15:33.373430 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m07:15:33.375102 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m07:15:33.376058 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m07:15:33.376058 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m07:15:33.378084 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m07:15:34.634106 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-653e-187c-a810-dac55fc4320a) - Created
[0m07:15:35.435482 [debug] [Thread-3 (]: SQL status: OK in 2.060 seconds
[0m07:15:35.435482 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d44-653e-187c-a810-dac55fc4320a, command-id=01f08d44-656f-1dd6-8e2f-f3b43b53f5b3) - Closing
[0m07:15:35.435482 [debug] [Thread-3 (]: Applying tags to relation None
[0m07:15:35.435482 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m07:15:35.435482 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d44-653e-187c-a810-dac55fc4320a) - Closing
[0m07:15:35.744711 [info ] [Thread-3 (]: 4 of 4 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.39s]
[0m07:15:35.744711 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m07:15:35.760408 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m07:15:35.760408 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m07:15:35.762432 [info ] [MainThread]: 
[0m07:15:35.762432 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 13.82 seconds (13.82s).
[0m07:15:35.767687 [debug] [MainThread]: Command end result
[0m07:15:35.880354 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m07:15:35.880354 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m07:15:35.880354 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m07:15:35.880354 [info ] [MainThread]: 
[0m07:15:35.880354 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:15:35.880354 [info ] [MainThread]: 
[0m07:15:35.880354 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m07:15:35.880354 [debug] [MainThread]: Command `dbt run` succeeded at 07:15:35.880354 after 16.22 seconds
[0m07:15:35.880354 [debug] [MainThread]: Flushing usage events
[0m08:17:41.486497 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 08:17:41.542887 | 15111b5f-6eba-4b87-9bf9-c59afa40d833 ==============================
[0m08:17:41.542887 [info ] [MainThread]: Running with dbt=1.10.11
[0m08:17:41.542887 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m08:17:42.379133 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:17:42.379133 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:17:42.380149 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:17:43.227718 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:17:43.543382 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m08:17:43.672500 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:17:43.674509 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:17:43.680531 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m08:17:43.783262 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m08:17:43.786817 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m08:17:43.797629 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m08:17:43.800865 [info ] [MainThread]: 
[0m08:17:43.801635 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:17:43.802407 [info ] [MainThread]: 
[0m08:17:43.803192 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:17:43.803794 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:17:43.810528 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m08:17:43.811098 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m08:17:43.811693 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m08:17:43.811693 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m08:17:43.812259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:17:47.825743 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4d-1666-17de-8ff1-39009d0dd59e) - Created
[0m08:17:48.630877 [debug] [ThreadPool]: SQL status: OK in 4.820 seconds
[0m08:17:48.630877 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d4d-1666-17de-8ff1-39009d0dd59e, command-id=01f08d4d-1699-1616-8a82-63a1a6067107) - Closing
[0m08:17:48.630877 [debug] [ThreadPool]: On list_dbt-project: Close
[0m08:17:48.630877 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4d-1666-17de-8ff1-39009d0dd59e) - Closing
[0m08:17:48.938072 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m08:17:48.938072 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m08:17:48.954015 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m08:17:48.954015 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m08:17:48.954015 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:17:50.377206 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4d-17d6-19fc-9d65-7d82ed659abe) - Created
[0m08:17:52.469290 [debug] [ThreadPool]: SQL status: OK in 3.520 seconds
[0m08:17:52.474992 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d4d-17d6-19fc-9d65-7d82ed659abe, command-id=01f08d4d-181c-1bbf-a804-26e8e8cc3f10) - Closing
[0m08:17:52.475583 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m08:17:52.476154 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4d-17d6-19fc-9d65-7d82ed659abe) - Closing
[0m08:17:52.795949 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m08:17:52.795949 [info ] [Thread-3 (]: 1 of 6 START sql view model default.bronze_customer ............................ [RUN]
[0m08:17:52.795949 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m08:17:52.795949 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m08:17:52.800691 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m08:17:52.808713 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m08:17:52.808713 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m08:17:52.822671 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:17:52.822671 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m08:17:52.845355 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customer`
[0m08:17:52.852866 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m08:17:52.852866 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m08:17:52.852866 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m08:17:52.852866 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:17:54.005058 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1a1d-1469-a213-00b0d9e1f199) - Created
[0m08:17:55.514294 [debug] [Thread-3 (]: SQL status: OK in 2.660 seconds
[0m08:17:55.514294 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-1a1d-1469-a213-00b0d9e1f199, command-id=01f08d4d-1a43-165c-8696-8daf6b6cdded) - Closing
[0m08:17:55.514294 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:17:55.514294 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m08:17:55.530347 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1a1d-1469-a213-00b0d9e1f199) - Closing
[0m08:17:55.821739 [info ] [Thread-3 (]: 1 of 6 OK created sql view model default.bronze_customer ....................... [[32mOK[0m in 3.03s]
[0m08:17:55.821739 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m08:17:55.821739 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m08:17:55.821739 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m08:17:55.821739 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m08:17:55.821739 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m08:17:55.821739 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m08:17:55.821739 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m08:17:55.821739 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m08:17:55.840007 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:17:55.841133 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m08:17:55.842001 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m08:17:55.843151 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m08:17:55.843151 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m08:17:55.844327 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:17:57.100697 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1bee-1b89-a87b-f27b24420217) - Created
[0m08:17:58.735094 [debug] [Thread-3 (]: SQL status: OK in 2.890 seconds
[0m08:17:58.735094 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-1bee-1b89-a87b-f27b24420217, command-id=01f08d4d-1c1d-1b96-a984-0c67168c53dc) - Closing
[0m08:17:58.735094 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:17:58.735094 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m08:17:58.735094 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1bee-1b89-a87b-f27b24420217) - Closing
[0m08:17:59.020199 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 3.20s]
[0m08:17:59.020199 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m08:17:59.020199 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_product
[0m08:17:59.020199 [info ] [Thread-3 (]: 3 of 6 START sql view model default.bronze_product ............................. [RUN]
[0m08:17:59.020199 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_product) - Creating connection
[0m08:17:59.020199 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_product'
[0m08:17:59.020199 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_product
[0m08:17:59.036657 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_product"
[0m08:17:59.038335 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_product
[0m08:17:59.040072 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:17:59.041458 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_product`
[0m08:17:59.045538 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_product"
[0m08:17:59.046553 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_product"
[0m08:17:59.047635 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_product"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_product`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m08:17:59.047635 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:00.312246 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1dce-10a4-9269-8b49185a88c1) - Created
[0m08:18:01.267348 [debug] [Thread-3 (]: SQL status: OK in 2.220 seconds
[0m08:18:01.269357 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-1dce-10a4-9269-8b49185a88c1, command-id=01f08d4d-1e06-1746-a93d-55e75655d0ad) - Closing
[0m08:18:01.271363 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:18:01.273368 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: Close
[0m08:18:01.273368 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1dce-10a4-9269-8b49185a88c1) - Closing
[0m08:18:01.747236 [info ] [Thread-3 (]: 3 of 6 OK created sql view model default.bronze_product ........................ [[32mOK[0m in 2.73s]
[0m08:18:01.748326 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_product
[0m08:18:01.748910 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m08:18:01.749494 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m08:18:01.750143 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m08:18:01.750786 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m08:18:01.750786 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m08:18:01.754958 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m08:18:01.756738 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m08:18:01.759668 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:18:01.761015 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m08:18:01.761711 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m08:18:01.762771 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m08:18:01.762771 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m08:18:01.762771 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:02.874749 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1f64-1fb7-aefb-baac1619acfa) - Created
[0m08:18:03.827204 [debug] [Thread-3 (]: SQL status: OK in 2.060 seconds
[0m08:18:03.828252 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-1f64-1fb7-aefb-baac1619acfa, command-id=01f08d4d-1f8d-1e97-ab70-55c6499555e3) - Closing
[0m08:18:03.829305 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:18:03.830352 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m08:18:03.830352 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-1f64-1fb7-aefb-baac1619acfa) - Closing
[0m08:18:04.146622 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.40s]
[0m08:18:04.146622 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m08:18:04.146622 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m08:18:04.146622 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m08:18:04.146622 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m08:18:04.156782 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m08:18:04.156782 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m08:18:04.163090 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m08:18:04.163406 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m08:18:04.170028 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:18:04.173068 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m08:18:04.174115 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m08:18:04.175133 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m08:18:04.175133 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m08:18:04.175133 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:05.585569 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-20f1-1783-b71f-f258d9ba4ff4) - Created
[0m08:18:06.701204 [debug] [Thread-3 (]: SQL status: OK in 2.530 seconds
[0m08:18:06.717360 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-20f1-1783-b71f-f258d9ba4ff4, command-id=01f08d4d-212b-18b8-88bb-d807a66de80c) - Closing
[0m08:18:06.717360 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:18:06.717360 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m08:18:06.717360 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-20f1-1783-b71f-f258d9ba4ff4) - Closing
[0m08:18:06.974099 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.83s]
[0m08:18:06.974099 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m08:18:06.974099 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m08:18:06.974099 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m08:18:06.974099 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m08:18:06.983708 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m08:18:06.984504 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m08:18:06.988562 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m08:18:06.988562 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m08:18:06.988562 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:18:06.988562 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m08:18:06.988562 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m08:18:06.988562 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m08:18:06.988562 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m08:18:06.988562 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:18:08.307426 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-229c-1e25-8fe8-369d3b3edc30) - Created
[0m08:18:09.105949 [debug] [Thread-3 (]: SQL status: OK in 2.120 seconds
[0m08:18:09.105949 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4d-229c-1e25-8fe8-369d3b3edc30, command-id=01f08d4d-22cb-14b6-891f-a1131a10df05) - Closing
[0m08:18:09.105949 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:18:09.105949 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m08:18:09.105949 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4d-229c-1e25-8fe8-369d3b3edc30) - Closing
[0m08:18:09.413972 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.44s]
[0m08:18:09.413972 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m08:18:09.429721 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:18:09.429721 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:18:09.429721 [info ] [MainThread]: 
[0m08:18:09.429721 [info ] [MainThread]: Finished running 6 view models in 0 hours 0 minutes and 25.63 seconds (25.63s).
[0m08:18:09.429721 [debug] [MainThread]: Command end result
[0m08:18:09.473393 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m08:18:09.473393 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m08:18:09.485518 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m08:18:09.485518 [info ] [MainThread]: 
[0m08:18:09.485518 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:18:09.485518 [info ] [MainThread]: 
[0m08:18:09.485518 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m08:18:09.485518 [debug] [MainThread]: Command `dbt run` succeeded at 08:18:09.485518 after 28.06 seconds
[0m08:18:09.485518 [debug] [MainThread]: Flushing usage events
[0m08:29:46.384088 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 08:29:46.479201 | 695db989-05b3-42d0-a072-84dcfc570683 ==============================
[0m08:29:46.479201 [info ] [MainThread]: Running with dbt=1.10.11
[0m08:29:46.479201 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m08:29:47.270749 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m08:29:47.271751 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m08:29:47.271751 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m08:29:48.030761 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m08:29:48.342575 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m08:29:48.475682 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m08:29:48.475682 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m08:29:48.491667 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m08:29:48.598157 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m08:29:48.598157 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m08:29:48.617964 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m08:29:48.617964 [info ] [MainThread]: 
[0m08:29:48.617964 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m08:29:48.617964 [info ] [MainThread]: 
[0m08:29:48.617964 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:29:48.617964 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:29:48.631987 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m08:29:48.631987 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m08:29:48.633008 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m08:29:48.633008 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m08:29:48.633008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:29:52.468959 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4e-c642-1e96-9e7d-80253fd20722) - Created
[0m08:29:53.277578 [debug] [ThreadPool]: SQL status: OK in 4.640 seconds
[0m08:29:53.278581 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d4e-c642-1e96-9e7d-80253fd20722, command-id=01f08d4e-c687-1cd0-824c-60af281be1bf) - Closing
[0m08:29:53.279578 [debug] [ThreadPool]: On list_dbt-project: Close
[0m08:29:53.279578 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4e-c642-1e96-9e7d-80253fd20722) - Closing
[0m08:29:53.584573 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m08:29:53.584573 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m08:29:53.600412 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m08:29:53.600412 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m08:29:53.600412 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m08:29:54.936652 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4e-c7cb-12d5-b066-ba531760ea2f) - Created
[0m08:29:55.617199 [debug] [ThreadPool]: SQL status: OK in 2.020 seconds
[0m08:29:55.617199 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08d4e-c7cb-12d5-b066-ba531760ea2f, command-id=01f08d4e-c7fa-146f-928c-3c3dea633530) - Closing
[0m08:29:55.617199 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m08:29:55.617199 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08d4e-c7cb-12d5-b066-ba531760ea2f) - Closing
[0m08:29:55.998815 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m08:29:55.998815 [info ] [Thread-3 (]: 1 of 6 START sql view model default.bronze_customer ............................ [RUN]
[0m08:29:55.998815 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m08:29:55.998815 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m08:29:55.998815 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m08:29:56.014345 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m08:29:56.014345 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m08:29:56.035161 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:29:56.037243 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m08:29:56.050346 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customer`
[0m08:29:56.056402 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m08:29:56.056402 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m08:29:56.056402 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m08:29:56.056402 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:29:57.015669 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-c910-14ef-9a3e-587a4cb0d44b) - Created
[0m08:29:58.065790 [debug] [Thread-3 (]: SQL status: OK in 2.010 seconds
[0m08:29:58.065790 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-c910-14ef-9a3e-587a4cb0d44b, command-id=01f08d4e-c93a-17b1-a688-aad203ffa75a) - Closing
[0m08:29:58.081891 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:29:58.081891 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m08:29:58.081891 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-c910-14ef-9a3e-587a4cb0d44b) - Closing
[0m08:29:58.386145 [info ] [Thread-3 (]: 1 of 6 OK created sql view model default.bronze_customer ....................... [[32mOK[0m in 2.39s]
[0m08:29:58.391186 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m08:29:58.391186 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m08:29:58.391186 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m08:29:58.391186 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m08:29:58.391186 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m08:29:58.391186 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m08:29:58.391186 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m08:29:58.391186 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m08:29:58.391186 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:29:58.391186 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m08:29:58.391186 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m08:29:58.391186 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m08:29:58.391186 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m08:29:58.391186 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:29:59.666576 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-ca9c-18bf-b2da-cb78c23445c8) - Created
[0m08:30:00.790824 [debug] [Thread-3 (]: SQL status: OK in 2.400 seconds
[0m08:30:00.791944 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-ca9c-18bf-b2da-cb78c23445c8, command-id=01f08d4e-cacd-1222-a138-6f129c408901) - Closing
[0m08:30:00.793119 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:30:00.793734 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m08:30:00.794342 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-ca9c-18bf-b2da-cb78c23445c8) - Closing
[0m08:30:01.106895 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.72s]
[0m08:30:01.106895 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m08:30:01.106895 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_product
[0m08:30:01.106895 [info ] [Thread-3 (]: 3 of 6 START sql view model default.bronze_product ............................. [RUN]
[0m08:30:01.106895 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_product) - Creating connection
[0m08:30:01.106895 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_product'
[0m08:30:01.106895 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_product
[0m08:30:01.123999 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_product"
[0m08:30:01.125294 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_product
[0m08:30:01.127293 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:30:01.129294 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_product`
[0m08:30:01.130294 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_product"
[0m08:30:01.130294 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_product"
[0m08:30:01.131294 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_product"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_product`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m08:30:01.131812 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:30:02.389291 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cc3b-1a32-9ea2-750174d9ec94) - Created
[0m08:30:03.346775 [debug] [Thread-3 (]: SQL status: OK in 2.210 seconds
[0m08:30:03.346775 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-cc3b-1a32-9ea2-750174d9ec94, command-id=01f08d4e-cc6b-1316-81f7-391c6187a002) - Closing
[0m08:30:03.346775 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:30:03.346775 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_product: Close
[0m08:30:03.346775 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cc3b-1a32-9ea2-750174d9ec94) - Closing
[0m08:30:03.670521 [info ] [Thread-3 (]: 3 of 6 OK created sql view model default.bronze_product ........................ [[32mOK[0m in 2.56s]
[0m08:30:03.670521 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_product
[0m08:30:03.670521 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m08:30:03.670521 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m08:30:03.670521 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m08:30:03.670521 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m08:30:03.670521 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m08:30:03.686850 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m08:30:03.688867 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m08:30:03.693938 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:30:03.697118 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m08:30:03.699129 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m08:30:03.700134 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m08:30:03.701124 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m08:30:03.702132 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:30:04.953538 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cdbf-1733-855c-792be97aa858) - Created
[0m08:30:06.065991 [debug] [Thread-3 (]: SQL status: OK in 2.360 seconds
[0m08:30:06.065991 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-cdbf-1733-855c-792be97aa858, command-id=01f08d4e-cdf1-188c-907f-c6a0f40b39a4) - Closing
[0m08:30:06.065991 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:30:06.065991 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m08:30:06.065991 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cdbf-1733-855c-792be97aa858) - Closing
[0m08:30:06.392583 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.72s]
[0m08:30:06.392583 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m08:30:06.392583 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m08:30:06.392583 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m08:30:06.392583 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m08:30:06.392583 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m08:30:06.392583 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m08:30:06.392583 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m08:30:06.392583 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m08:30:06.410346 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:30:06.412053 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m08:30:06.412053 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m08:30:06.413922 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m08:30:06.414960 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m08:30:06.415988 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:30:07.682584 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cf5f-1924-8df6-bdacc0c8cdc7) - Created
[0m08:30:08.558372 [debug] [Thread-3 (]: SQL status: OK in 2.140 seconds
[0m08:30:08.559364 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-cf5f-1924-8df6-bdacc0c8cdc7, command-id=01f08d4e-cf93-158c-b60a-02d2b0ed92a8) - Closing
[0m08:30:08.560349 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:30:08.561375 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m08:30:08.561375 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-cf5f-1924-8df6-bdacc0c8cdc7) - Closing
[0m08:30:08.946789 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.55s]
[0m08:30:08.946789 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m08:30:08.951125 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m08:30:08.951125 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m08:30:08.951125 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m08:30:08.951125 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m08:30:08.951125 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m08:30:08.951125 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m08:30:08.951125 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m08:30:08.964060 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m08:30:08.972227 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m08:30:08.973303 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m08:30:08.974325 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m08:30:08.974325 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m08:30:08.975281 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m08:30:10.220684 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-d0e5-1fe3-b16d-0512c7acc043) - Created
[0m08:30:11.186006 [debug] [Thread-3 (]: SQL status: OK in 2.210 seconds
[0m08:30:11.186006 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08d4e-d0e5-1fe3-b16d-0512c7acc043, command-id=01f08d4e-d117-116f-a8c9-5abd7e1c281d) - Closing
[0m08:30:11.186006 [debug] [Thread-3 (]: Applying tags to relation None
[0m08:30:11.186006 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m08:30:11.186006 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08d4e-d0e5-1fe3-b16d-0512c7acc043) - Closing
[0m08:30:11.818657 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.87s]
[0m08:30:11.818657 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m08:30:11.832111 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m08:30:11.834121 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m08:30:11.835163 [info ] [MainThread]: 
[0m08:30:11.836122 [info ] [MainThread]: Finished running 6 view models in 0 hours 0 minutes and 23.22 seconds (23.22s).
[0m08:30:11.837122 [debug] [MainThread]: Command end result
[0m08:30:11.878617 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m08:30:11.881862 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m08:30:11.887297 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m08:30:11.887297 [info ] [MainThread]: 
[0m08:30:11.887297 [info ] [MainThread]: [32mCompleted successfully[0m
[0m08:30:11.887297 [info ] [MainThread]: 
[0m08:30:11.887297 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m08:30:11.887297 [debug] [MainThread]: Command `dbt run` succeeded at 08:30:11.887297 after 25.55 seconds
[0m08:30:11.887297 [debug] [MainThread]: Flushing usage events
[0m14:26:35.328345 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:26:35.518717 | bd55a3cb-b646-413e-8427-c93a6b8ce735 ==============================
[0m14:26:35.518717 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:26:35.518717 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m14:26:38.389254 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:26:38.389254 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:26:38.389254 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:26:40.272323 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:26:40.739047 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:26:40.739047 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:26:42.494579 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:26:42.505284 [debug] [MainThread]: Command `dbt run` failed at 14:26:42.505284 after 7.25 seconds
[0m14:26:42.505284 [debug] [MainThread]: Flushing usage events
[0m14:27:18.941269 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:27:19.022384 | 3b4e65bd-aff3-46ec-8d34-f0ac5d394e85 ==============================
[0m14:27:19.022384 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:27:19.022384 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:27:20.167890 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:27:20.167890 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:27:20.167890 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:27:21.406940 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:27:21.847079 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:27:21.847079 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:27:23.526789 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:27:23.538661 [debug] [MainThread]: Command `dbt run` failed at 14:27:23.538661 after 4.67 seconds
[0m14:27:23.538661 [debug] [MainThread]: Flushing usage events
[0m14:28:22.403172 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:28:22.508191 | 0a5bdc8e-6894-4460-80ea-9fca00f7d05f ==============================
[0m14:28:22.508191 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:28:22.508191 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:28:23.843183 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:28:23.843183 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:28:23.843183 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:28:25.083735 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:28:25.586614 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:28:25.586614 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:28:27.421565 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:28:27.437601 [debug] [MainThread]: Command `dbt run` failed at 14:28:27.437601 after 5.11 seconds
[0m14:28:27.437601 [debug] [MainThread]: Flushing usage events
[0m14:29:57.722864 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:29:57.839519 | 43c1afc6-835e-490a-9e95-3e41c022bdf8 ==============================
[0m14:29:57.839519 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:29:57.839519 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:29:59.038821 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:29:59.038821 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:29:59.038821 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:30:00.248432 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:30:00.689328 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:30:00.689328 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:30:02.422577 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:30:02.422577 [debug] [MainThread]: Command `dbt run` failed at 14:30:02.422577 after 4.76 seconds
[0m14:30:02.431745 [debug] [MainThread]: Flushing usage events
[0m14:31:27.237768 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:31:27.364926 | 9aca3580-e84f-47bb-8780-5c96722ae13e ==============================
[0m14:31:27.364926 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:31:27.364926 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:31:28.540818 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:31:28.540818 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:31:28.542830 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:31:29.771854 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:31:30.358427 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:31:30.365115 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:31:32.519988 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:31:32.524676 [debug] [MainThread]: Command `dbt run` failed at 14:31:32.524676 after 5.34 seconds
[0m14:31:32.524676 [debug] [MainThread]: Flushing usage events
[0m14:32:49.133782 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:32:49.228889 | dbbd91b7-9acf-4468-9d02-42f8ff37d3d8 ==============================
[0m14:32:49.228889 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:32:49.228889 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:32:50.485754 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:32:50.485754 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:32:50.485754 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:32:51.720423 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:32:52.279943 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:32:52.279943 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:32:54.015262 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:32:54.018854 [debug] [MainThread]: Command `dbt run` failed at 14:32:54.018298 after 4.97 seconds
[0m14:32:54.021270 [debug] [MainThread]: Flushing usage events
[0m14:34:07.613987 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:34:07.740163 | 09da370a-945b-4660-9e40-c83b70fc9065 ==============================
[0m14:34:07.740163 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:34:07.740163 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:34:07.913147 [debug] [MainThread]: Command `dbt clean` succeeded at 14:34:07.913147 after 0.37 seconds
[0m14:34:07.913147 [debug] [MainThread]: Flushing usage events
[0m14:34:21.332066 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:34:21.440129 | 3cc2a490-0085-4dcb-8e09-e9ce9e5e9d3c ==============================
[0m14:34:21.440129 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:34:21.440129 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:34:22.572672 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:34:22.572672 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:34:22.572672 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:34:23.675066 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:34:24.197363 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:34:24.199582 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:34:25.899050 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_customer".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_customer").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_customer (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_customer.sql)
  - model.dbt_eTl.bronze_customer (models\bronze\bronze_customer.sql)
[0m14:34:25.899050 [debug] [MainThread]: Command `dbt run` failed at 14:34:25.899050 after 4.63 seconds
[0m14:34:25.899050 [debug] [MainThread]: Flushing usage events
[0m14:36:24.351009 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:36:24.477872 | 4a70405d-f9e4-4f16-b3a2-4be5459611a2 ==============================
[0m14:36:24.477872 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:36:24.478840 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'empty': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:36:25.602960 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:36:25.602960 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:36:25.602960 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:36:26.878701 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:36:27.331142 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:36:27.331142 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:36:29.018750 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:36:29.018750 [debug] [MainThread]: Command `dbt run` failed at 14:36:29.018750 after 4.76 seconds
[0m14:36:29.018750 [debug] [MainThread]: Flushing usage events
[0m14:38:36.175299 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:38:36.290088 | 626ae829-7a0b-4ee9-84ee-8d03aaae5227 ==============================
[0m14:38:36.290088 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:38:36.290088 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:38:37.482269 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:38:37.482269 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:38:37.482269 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:38:38.556314 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:38:39.027820 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:38:39.029828 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:38:40.953400 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:38:40.953400 [debug] [MainThread]: Command `dbt run` failed at 14:38:40.953400 after 4.84 seconds
[0m14:38:40.953400 [debug] [MainThread]: Flushing usage events
[0m14:40:52.596585 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:40:52.716890 | 84d5a92c-d8d1-4bc3-a69a-af91f1b0035a ==============================
[0m14:40:52.716890 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:40:52.729808 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:40:53.844577 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:40:53.844577 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:40:53.844577 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:40:55.032575 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:40:55.488690 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:40:55.488690 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:40:57.274137 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:40:57.280639 [debug] [MainThread]: Command `dbt build` failed at 14:40:57.278586 after 4.75 seconds
[0m14:40:57.281248 [debug] [MainThread]: Flushing usage events
[0m14:42:07.468508 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:42:07.593331 | 26064231-43cc-4a14-8296-abc28e25e023 ==============================
[0m14:42:07.593331 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:42:07.593331 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:42:08.703051 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:42:08.703051 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:42:08.703051 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:42:09.974371 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:42:10.466896 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:42:10.483110 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:42:12.175496 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:42:12.177369 [debug] [MainThread]: Command `dbt run` failed at 14:42:12.177369 after 4.77 seconds
[0m14:42:12.178506 [debug] [MainThread]: Flushing usage events
[0m14:43:17.801125 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:43:17.916438 | 96db62cf-fef8-479a-ac14-37ac3f77ed8c ==============================
[0m14:43:17.916438 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:43:17.916438 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:43:19.000456 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:43:19.000456 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:43:19.000456 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:43:20.197483 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:43:20.683679 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:43:20.683679 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:43:22.383367 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:43:22.401176 [debug] [MainThread]: Command `dbt run` failed at 14:43:22.399169 after 4.66 seconds
[0m14:43:22.401176 [debug] [MainThread]: Flushing usage events
[0m14:46:42.995147 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:46:43.122403 | b815bdd5-3e19-41f0-836b-a309caa28361 ==============================
[0m14:46:43.122403 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:46:43.122403 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:46:44.412603 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:46:44.412603 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:46:44.412603 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:46:45.949576 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:46:46.428569 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:46:46.428569 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:46:48.311588 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:46:48.311588 [debug] [MainThread]: Command `dbt build` failed at 14:46:48.311588 after 5.38 seconds
[0m14:46:48.311588 [debug] [MainThread]: Flushing usage events
[0m14:47:17.540021 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:47:17.644303 | ee2a9d05-347b-41fd-9cee-ba31cc9af3ff ==============================
[0m14:47:17.644303 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:47:17.644303 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'empty': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:47:18.717638 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:47:18.717638 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:47:18.717638 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:47:19.951698 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:47:20.566998 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:47:20.566998 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:47:22.260925 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_product".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_product").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_product (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_product.sql)
  - model.dbt_eTl.bronze_product (models\bronze\bronze_product.sql)
[0m14:47:22.260925 [debug] [MainThread]: Command `dbt run` failed at 14:47:22.260925 after 4.78 seconds
[0m14:47:22.260925 [debug] [MainThread]: Flushing usage events
[0m14:49:18.690831 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:49:18.806125 | bac4d9b0-28d6-48aa-b7b3-16333c20674e ==============================
[0m14:49:18.806125 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:49:18.806125 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:49:20.070417 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:49:20.070417 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:49:20.086232 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:49:21.267164 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:49:21.733619 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:49:21.733619 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:49:23.472562 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_product".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_product").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_product (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_product.sql)
  - model.dbt_eTl.bronze_product (models\bronze\bronze_product.sql)
[0m14:49:23.475859 [debug] [MainThread]: Command `dbt run` failed at 14:49:23.475859 after 4.84 seconds
[0m14:49:23.475859 [debug] [MainThread]: Flushing usage events
[0m14:49:59.864873 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:49:59.973408 | d92dda3e-fd51-4be4-87ee-e06435229355 ==============================
[0m14:49:59.973408 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:49:59.973408 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:50:01.112250 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:50:01.112250 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:50:01.112250 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:50:02.189669 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:50:02.689816 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:50:02.689816 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:50:04.367323 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m14:50:04.371194 [debug] [MainThread]: Command `dbt run` failed at 14:50:04.371194 after 4.58 seconds
[0m14:50:04.371194 [debug] [MainThread]: Flushing usage events
[0m14:50:20.614472 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:50:20.719474 | 7b950b69-cba7-4277-800d-613650bf8e6f ==============================
[0m14:50:20.719474 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:50:20.719474 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:50:21.812629 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:50:21.812629 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:50:21.812629 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:50:22.981932 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:50:23.431966 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:50:23.431966 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:50:25.089928 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_sales".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_sales").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_sales (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_sales.sql)
  - model.dbt_eTl.bronze_sales (models\bronze\bronze_sales.sql)
[0m14:50:25.089928 [debug] [MainThread]: Command `dbt run` failed at 14:50:25.089928 after 4.54 seconds
[0m14:50:25.089928 [debug] [MainThread]: Flushing usage events
[0m14:50:41.962757 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:50:42.077014 | 00991937-3ad9-44bb-a2f4-17ecc82d0eb2 ==============================
[0m14:50:42.077014 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:50:42.077014 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m14:50:43.135606 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:50:43.135606 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:50:43.135606 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:50:44.197137 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:50:44.714307 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:50:44.715445 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:50:46.405049 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_store".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_store").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_store (models\gold\target\compiled\dbt_eTl\models\bronze\bronze_store.sql)
  - model.dbt_eTl.bronze_store (models\bronze\bronze_store.sql)
[0m14:50:46.405049 [debug] [MainThread]: Command `dbt run` failed at 14:50:46.405049 after 4.52 seconds
[0m14:50:46.405049 [debug] [MainThread]: Flushing usage events
[0m14:51:03.721275 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:51:03.838180 | e37e6dab-c1b7-4545-a742-e50fdceb09bf ==============================
[0m14:51:03.838180 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:51:03.840567 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:51:04.894171 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:51:04.894171 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:51:04.894171 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:51:06.014663 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:51:06.439773 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:51:06.439773 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:51:08.178250 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\run\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:51:08.186007 [debug] [MainThread]: Command `dbt run` failed at 14:51:08.186007 after 4.53 seconds
[0m14:51:08.186007 [debug] [MainThread]: Flushing usage events
[0m14:53:17.384369 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:53:17.512083 | 6b2b7547-e725-4199-89c3-6a99bd7e2cae ==============================
[0m14:53:17.512083 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:53:17.517693 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:53:18.684231 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:53:18.684231 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:53:18.684231 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:53:19.877434 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:53:20.547923 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:53:20.548584 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:53:22.382583 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_date".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_date").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_date (models\gold\target\run\dbt_eTl\models\bronze\bronze_date.sql)
  - model.dbt_eTl.bronze_date (models\bronze\bronze_date.sql)
[0m14:53:22.389774 [debug] [MainThread]: Command `dbt run` failed at 14:53:22.389774 after 5.08 seconds
[0m14:53:22.389774 [debug] [MainThread]: Flushing usage events
[0m14:55:34.276424 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:55:34.397280 | cb6ad52c-4838-4dee-b76f-3592d3a1c4d0 ==============================
[0m14:55:34.397280 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:55:34.397280 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:55:35.730210 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:55:35.730210 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:55:35.730210 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:55:36.983965 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:55:37.563762 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:55:37.563762 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:55:39.557005 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_product".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_product").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_product (models\gold\target\run\dbt_eTl\models\bronze\bronze_product.sql)
  - model.dbt_eTl.bronze_product (models\bronze\bronze_product.sql)
[0m14:55:39.557005 [debug] [MainThread]: Command `dbt run` failed at 14:55:39.557005 after 5.33 seconds
[0m14:55:39.557005 [debug] [MainThread]: Flushing usage events
[0m14:55:54.514596 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:55:54.624445 | 6d29b2d4-f3a4-4b89-a21a-25228e6bca8d ==============================
[0m14:55:54.624445 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:55:54.624445 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:55:55.770100 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:55:55.770100 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:55:55.770100 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:55:56.880153 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:55:57.380186 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:55:57.383791 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:55:59.107809 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\run\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m14:55:59.113254 [debug] [MainThread]: Command `dbt run` failed at 14:55:59.107809 after 4.65 seconds
[0m14:55:59.113254 [debug] [MainThread]: Flushing usage events
[0m14:57:41.829769 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:57:41.921311 | ee8346a7-8409-4b94-8c8b-b22f0cdddc7a ==============================
[0m14:57:41.921311 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:57:41.921311 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'printer_width': '80', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m14:57:42.994506 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:57:42.994506 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:57:42.994506 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:57:44.072955 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:57:44.577035 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:57:44.577035 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:57:46.545104 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\run\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m14:57:46.554775 [debug] [MainThread]: Command `dbt run` failed at 14:57:46.554775 after 4.79 seconds
[0m14:57:46.554775 [debug] [MainThread]: Flushing usage events
[0m16:41:17.393368 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:41:17.556648 | bdf64c0b-09e3-4347-a7de-3981ea442e6b ==============================
[0m16:41:17.556648 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:41:17.558514 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:41:19.551653 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:41:19.555114 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:41:19.555114 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:41:21.840603 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:41:22.422513 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:41:22.422513 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m16:41:24.906352 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\run\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m16:41:24.908103 [debug] [MainThread]: Command `dbt build` failed at 16:41:24.908103 after 7.63 seconds
[0m16:41:24.908103 [debug] [MainThread]: Flushing usage events
[0m20:09:54.902692 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:09:55.096086 | 57008b73-ac38-4ce9-b789-a99664e59d29 ==============================
[0m20:09:55.096086 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:09:55.098097 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m20:10:10.944276 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:10:10.946289 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:10:10.946289 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:10:36.011182 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:10:37.042315 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:10:37.042315 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:10:40.498516 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\run\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m20:10:40.515515 [debug] [MainThread]: Command `dbt build` failed at 20:10:40.515515 after 45.83 seconds
[0m20:10:40.518178 [debug] [MainThread]: Flushing usage events
[0m20:11:29.023842 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:11:29.166625 | 2550436e-b4cd-4f01-a8f5-8b71a44f45fe ==============================
[0m20:11:29.166625 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:11:29.166625 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m20:11:31.791511 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:11:31.791511 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:11:31.791511 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:11:34.188459 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:11:34.980852 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:11:34.980852 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:11:37.875797 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two models with the name "bronze_returns".
  
  Since these resources have the same name, dbt will be unable to find the correct resource
  when looking for ref("bronze_returns").
  
  To fix this, change the name of one of these resources:
  - model.dbt_eTl.bronze_returns (models\gold\target\run\dbt_eTl\models\bronze\bronze_returns.sql)
  - model.dbt_eTl.bronze_returns (models\bronze\bronze_returns.sql)
[0m20:11:37.883268 [debug] [MainThread]: Command `dbt build` failed at 20:11:37.883268 after 9.03 seconds
[0m20:11:37.885291 [debug] [MainThread]: Flushing usage events
[0m20:12:49.700798 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:12:49.826878 | b85928e6-603d-4055-b33d-17bd661ac7ca ==============================
[0m20:12:49.826878 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:12:49.830049 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m20:12:51.536319 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:12:51.536319 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:12:51.538330 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:12:53.165173 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:12:53.953096 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:12:53.956217 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:12:57.076005 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:12:57.242749 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:12:57.312052 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:12:57.806040 [info ] [MainThread]: Found 4 models, 6 sources, 685 macros
[0m20:12:57.810941 [info ] [MainThread]: 
[0m20:12:57.810941 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:12:57.810941 [info ] [MainThread]: 
[0m20:12:57.818485 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:12:57.818485 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:12:57.826592 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:12:57.836690 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:12:57.837358 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:12:57.837358 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:12:57.837358 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:13:00.584089 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db0-ffea-13cd-8563-83953484a7d3) - Created
[0m20:14:03.289575 [debug] [ThreadPool]: SQL status: OK in 65.450 seconds
[0m20:14:03.296623 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db0-ffea-13cd-8563-83953484a7d3, command-id=01f08db1-254d-1aac-be97-c9a7dc2227df) - Closing
[0m20:14:03.299975 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:14:03.302116 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db0-ffea-13cd-8563-83953484a7d3) - Closing
[0m20:14:04.358186 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:14:04.362196 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:14:04.454244 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:14:04.463779 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:14:04.464776 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:14:10.329928 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-29d2-1d64-9d85-08a794e21be6) - Created
[0m20:14:12.888236 [debug] [ThreadPool]: SQL status: OK in 8.420 seconds
[0m20:14:13.135148 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db1-29d2-1d64-9d85-08a794e21be6, command-id=01f08db1-2a07-11b9-a624-bac35751c0b4) - Closing
[0m20:14:13.144683 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:14:13.149811 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-29d2-1d64-9d85-08a794e21be6) - Closing
[0m20:14:13.655571 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customers
[0m20:14:13.665433 [info ] [Thread-3 (]: 1 of 4 START sql view model default.bronze_customers ........................... [RUN]
[0m20:14:13.669960 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customers) - Creating connection
[0m20:14:13.670969 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customers'
[0m20:14:13.671960 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customers
[0m20:14:13.735129 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customers"
[0m20:14:13.749067 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customers
[0m20:14:13.821691 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:14:13.845769 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:14:13.913991 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customers`
[0m20:14:13.961742 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customers"
[0m20:14:13.970935 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customers"
[0m20:14:13.971933 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customers"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customers`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:14:13.972931 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:14:15.802513 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-2d0e-162c-9384-74d7f604364e) - Created
[0m20:14:16.890652 [debug] [Thread-3 (]: SQL status: OK in 2.920 seconds
[0m20:14:16.898356 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-2d0e-162c-9384-74d7f604364e, command-id=01f08db1-2d56-1bde-befe-132fd69a989e) - Closing
[0m20:14:16.974594 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:14:16.990572 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: Close
[0m20:14:16.993046 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-2d0e-162c-9384-74d7f604364e) - Closing
[0m20:14:17.318659 [info ] [Thread-3 (]: 1 of 4 OK created sql view model default.bronze_customers ...................... [[32mOK[0m in 3.61s]
[0m20:14:17.320662 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customers
[0m20:14:17.321669 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:14:17.325889 [info ] [Thread-3 (]: 2 of 4 START sql view model default.bronze_returns ............................. [RUN]
[0m20:14:17.330887 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:14:17.331898 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:14:17.331898 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:14:17.361381 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:14:17.368003 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:14:17.379004 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:14:17.385004 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:14:17.387001 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:14:17.392026 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:14:17.396022 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:14:17.400014 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:14:18.968229 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-2ef9-133a-b8e9-2917aa20cea4) - Created
[0m20:14:20.264250 [debug] [Thread-3 (]: SQL status: OK in 2.860 seconds
[0m20:14:20.269740 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-2ef9-133a-b8e9-2917aa20cea4, command-id=01f08db1-2f25-1861-8cfc-14d996ffaedc) - Closing
[0m20:14:20.275175 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:14:20.281006 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:14:20.282019 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-2ef9-133a-b8e9-2917aa20cea4) - Closing
[0m20:14:20.582644 [info ] [Thread-3 (]: 2 of 4 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.24s]
[0m20:14:20.601879 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:14:20.604782 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:14:20.613141 [info ] [Thread-3 (]: 3 of 4 START sql view model default.bronze_sales ............................... [RUN]
[0m20:14:20.620000 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:14:20.623258 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:14:20.635250 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:14:20.655435 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:14:20.662812 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:14:20.694934 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:14:20.701293 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:14:20.706745 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:14:20.714534 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:14:20.714534 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:14:20.715778 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:14:22.315574 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-30f6-12eb-ae0b-4ab0b607b6ce) - Created
[0m20:14:23.840506 [debug] [Thread-3 (]: SQL status: OK in 3.120 seconds
[0m20:14:23.846573 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-30f6-12eb-ae0b-4ab0b607b6ce, command-id=01f08db1-3151-1aa5-bcb7-0ed464d6afd8) - Closing
[0m20:14:23.852634 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:14:23.856481 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:14:23.862582 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-30f6-12eb-ae0b-4ab0b607b6ce) - Closing
[0m20:14:24.153639 [info ] [Thread-3 (]: 3 of 4 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.53s]
[0m20:14:24.155048 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:14:24.156708 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:14:24.160812 [info ] [Thread-3 (]: 4 of 4 START sql view model default.bronze_store ............................... [RUN]
[0m20:14:24.165868 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:14:24.168256 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:14:24.170522 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:14:24.203723 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:14:24.212361 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:14:24.226003 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:14:24.230027 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:14:24.240171 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:14:24.247720 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:14:24.249730 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:14:24.251615 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:14:25.883807 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-331a-1398-a33c-0b64b1102dfb) - Created
[0m20:14:27.194431 [debug] [Thread-3 (]: SQL status: OK in 2.940 seconds
[0m20:14:27.202493 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-331a-1398-a33c-0b64b1102dfb, command-id=01f08db1-3356-1b86-ad67-ca29e3d3c718) - Closing
[0m20:14:27.212649 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:14:27.232374 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:14:27.240701 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-331a-1398-a33c-0b64b1102dfb) - Closing
[0m20:14:27.516349 [info ] [Thread-3 (]: 4 of 4 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 3.35s]
[0m20:14:27.538869 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:14:27.570503 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:14:27.588434 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:14:27.606282 [info ] [MainThread]: 
[0m20:14:27.649402 [info ] [MainThread]: Finished running 4 view models in 0 hours 1 minutes and 29.79 seconds (89.79s).
[0m20:14:27.720152 [debug] [MainThread]: Command end result
[0m20:14:27.863072 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:14:27.950516 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:14:28.082893 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:14:28.083893 [info ] [MainThread]: 
[0m20:14:28.101928 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:14:28.118067 [info ] [MainThread]: 
[0m20:14:28.128218 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m20:14:28.201138 [debug] [MainThread]: Command `dbt build` succeeded at 20:14:28.184030 after 98.59 seconds
[0m20:14:28.203143 [debug] [MainThread]: Flushing usage events
[0m20:15:18.835820 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:15:19.000265 | 5bece1e0-26e8-40b1-843e-ebf776ab6932 ==============================
[0m20:15:19.000265 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:15:19.002271 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m20:15:19.399049 [debug] [MainThread]: Command `dbt clean` succeeded at 20:15:19.399049 after 0.69 seconds
[0m20:15:19.400082 [debug] [MainThread]: Flushing usage events
[0m20:15:26.914139 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:15:27.033954 | 59c94a8a-bf13-48ec-a0e6-8cb24bb3617c ==============================
[0m20:15:27.033954 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:15:27.033954 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m20:15:28.869673 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:15:28.870758 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:15:28.871671 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:15:30.578455 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:15:31.444798 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:15:31.445310 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:15:34.715466 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:15:34.879798 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:15:34.887958 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:15:35.147899 [info ] [MainThread]: Found 4 models, 6 sources, 685 macros
[0m20:15:35.147899 [info ] [MainThread]: 
[0m20:15:35.147899 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:15:35.147899 [info ] [MainThread]: 
[0m20:15:35.147899 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:15:35.155432 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:15:35.177078 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:15:35.177078 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:15:35.177078 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:15:35.177078 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:15:35.177078 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:15:37.158027 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-5d8f-142d-bc26-148e4d9aa86d) - Created
[0m20:15:37.710298 [debug] [ThreadPool]: SQL status: OK in 2.530 seconds
[0m20:15:37.710298 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db1-5d8f-142d-bc26-148e4d9aa86d, command-id=01f08db1-5dbd-171c-a71c-3ea38c65f81a) - Closing
[0m20:15:37.710298 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:15:37.710298 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-5d8f-142d-bc26-148e4d9aa86d) - Closing
[0m20:15:37.995983 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:15:37.995983 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:15:38.023379 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:15:38.023379 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:15:38.023379 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:15:39.933743 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-5f29-13d6-b707-772ff4dce29b) - Created
[0m20:15:40.638637 [debug] [ThreadPool]: SQL status: OK in 2.620 seconds
[0m20:15:40.653998 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db1-5f29-13d6-b707-772ff4dce29b, command-id=01f08db1-5f6a-1281-bab3-3075aafc6045) - Closing
[0m20:15:40.657528 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:15:40.659202 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-5f29-13d6-b707-772ff4dce29b) - Closing
[0m20:15:40.957927 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customers
[0m20:15:40.966167 [info ] [Thread-3 (]: 1 of 4 START sql view model default.bronze_customers ........................... [RUN]
[0m20:15:40.968174 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customers) - Creating connection
[0m20:15:40.968174 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customers'
[0m20:15:40.968174 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customers
[0m20:15:40.983327 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customers"
[0m20:15:41.039458 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customers
[0m20:15:41.112876 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:15:41.118646 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:15:41.150602 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customers`
[0m20:15:41.170386 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customers"
[0m20:15:41.176131 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customers"
[0m20:15:41.178293 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customers"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customers`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:15:41.180308 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:15:42.894479 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-60ea-166a-aae2-d358212a37e9) - Created
[0m20:15:44.016421 [debug] [Thread-3 (]: SQL status: OK in 2.840 seconds
[0m20:15:44.018002 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-60ea-166a-aae2-d358212a37e9, command-id=01f08db1-612a-1f2c-ab99-9aa28d313bf6) - Closing
[0m20:15:44.041545 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:15:44.041545 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: Close
[0m20:15:44.041545 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-60ea-166a-aae2-d358212a37e9) - Closing
[0m20:15:44.325984 [info ] [Thread-3 (]: 1 of 4 OK created sql view model default.bronze_customers ...................... [[32mOK[0m in 3.35s]
[0m20:15:44.328602 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customers
[0m20:15:44.329702 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:15:44.329702 [info ] [Thread-3 (]: 2 of 4 START sql view model default.bronze_returns ............................. [RUN]
[0m20:15:44.329702 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:15:44.329702 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:15:44.329702 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:15:44.348167 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:15:44.352592 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:15:44.356516 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:15:44.361867 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:15:44.365914 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:15:44.367919 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:15:44.367919 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:15:44.369928 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:15:45.452579 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6289-12b7-9070-e2dc5a1d31f2) - Created
[0m20:15:46.675994 [debug] [Thread-3 (]: SQL status: OK in 2.310 seconds
[0m20:15:46.679199 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-6289-12b7-9070-e2dc5a1d31f2, command-id=01f08db1-62b3-1b9f-bb4a-ac0363329d58) - Closing
[0m20:15:46.679199 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:15:46.683164 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:15:46.683164 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6289-12b7-9070-e2dc5a1d31f2) - Closing
[0m20:15:47.176818 [info ] [Thread-3 (]: 2 of 4 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.84s]
[0m20:15:47.176818 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:15:47.176818 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:15:47.179853 [info ] [Thread-3 (]: 3 of 4 START sql view model default.bronze_sales ............................... [RUN]
[0m20:15:47.179853 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:15:47.182282 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:15:47.184209 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:15:47.196494 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:15:47.202435 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:15:47.220590 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:15:47.227446 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:15:47.229474 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:15:47.231489 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:15:47.231489 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:15:47.231489 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:15:48.837808 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6484-1cbb-8da6-0ef4f8b46ef8) - Created
[0m20:15:49.954462 [debug] [Thread-3 (]: SQL status: OK in 2.720 seconds
[0m20:15:49.955280 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-6484-1cbb-8da6-0ef4f8b46ef8, command-id=01f08db1-64b4-1772-b08b-4dd431c49f0a) - Closing
[0m20:15:49.955280 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:15:49.960594 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:15:49.960594 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6484-1cbb-8da6-0ef4f8b46ef8) - Closing
[0m20:15:50.374667 [info ] [Thread-3 (]: 3 of 4 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.19s]
[0m20:15:50.378296 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:15:50.378296 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:15:50.380204 [info ] [Thread-3 (]: 4 of 4 START sql view model default.bronze_store ............................... [RUN]
[0m20:15:50.380749 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:15:50.382131 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:15:50.382746 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:15:50.390439 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:15:50.394756 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:15:50.398915 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:15:50.399624 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:15:50.402816 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:15:50.404826 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:15:50.405685 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:15:50.407732 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:15:52.137801 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6681-139c-a562-057bb46fe420) - Created
[0m20:15:53.136247 [debug] [Thread-3 (]: SQL status: OK in 2.730 seconds
[0m20:15:53.139198 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-6681-139c-a562-057bb46fe420, command-id=01f08db1-66ac-1b6c-9b56-d597203245f5) - Closing
[0m20:15:53.141230 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:15:53.143241 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:15:53.145248 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-6681-139c-a562-057bb46fe420) - Closing
[0m20:15:53.409442 [info ] [Thread-3 (]: 4 of 4 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 3.03s]
[0m20:15:53.412807 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:15:53.412807 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:15:53.416692 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:15:53.416692 [info ] [MainThread]: 
[0m20:15:53.416692 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 18.27 seconds (18.27s).
[0m20:15:53.420538 [debug] [MainThread]: Command end result
[0m20:15:53.495557 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:15:53.499574 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:15:53.515432 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:15:53.518697 [info ] [MainThread]: 
[0m20:15:53.518697 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:15:53.528148 [info ] [MainThread]: 
[0m20:15:53.529155 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m20:15:53.531208 [debug] [MainThread]: Command `dbt build` succeeded at 20:15:53.531208 after 26.73 seconds
[0m20:15:53.531208 [debug] [MainThread]: Flushing usage events
[0m20:18:56.196182 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:18:56.311314 | aed61ed5-b03e-4525-a504-58f414f246e4 ==============================
[0m20:18:56.311314 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:18:56.313130 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m20:18:58.038057 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:18:58.049502 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:18:58.049502 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:18:59.524406 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:19:00.209671 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:19:00.509010 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:19:00.509010 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:19:00.509010 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:19:00.704663 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:19:00.709616 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:19:00.750743 [info ] [MainThread]: Found 4 models, 6 sources, 685 macros
[0m20:19:00.758628 [info ] [MainThread]: 
[0m20:19:00.758628 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:19:00.758628 [info ] [MainThread]: 
[0m20:19:00.762458 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:19:00.764152 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:19:00.777650 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:19:00.777650 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:19:00.777650 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:19:00.777650 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:19:00.783203 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:19:03.156945 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-d83a-182b-8bd7-aa04dcf0dc24) - Created
[0m20:19:03.727472 [debug] [ThreadPool]: SQL status: OK in 2.940 seconds
[0m20:19:03.729721 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db1-d83a-182b-8bd7-aa04dcf0dc24, command-id=01f08db1-d887-13d5-b2e5-e03a81fac28b) - Closing
[0m20:19:03.730771 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:19:03.731974 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-d83a-182b-8bd7-aa04dcf0dc24) - Closing
[0m20:19:04.104690 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:19:04.104690 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:19:04.129834 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:19:04.129834 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:19:04.132543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:19:05.646325 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-d9d5-180c-aa3b-21448fc1170e) - Created
[0m20:19:06.272815 [debug] [ThreadPool]: SQL status: OK in 2.140 seconds
[0m20:19:06.288751 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db1-d9d5-180c-aa3b-21448fc1170e, command-id=01f08db1-da01-1007-828e-91945692e800) - Closing
[0m20:19:06.288751 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:19:06.288751 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db1-d9d5-180c-aa3b-21448fc1170e) - Closing
[0m20:19:06.632732 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customers
[0m20:19:06.634757 [info ] [Thread-3 (]: 1 of 4 START sql view model default.bronze_customers ........................... [RUN]
[0m20:19:06.638815 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customers) - Creating connection
[0m20:19:06.638815 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customers'
[0m20:19:06.640821 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customers
[0m20:19:06.655036 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customers"
[0m20:19:06.660572 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customers
[0m20:19:06.689470 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:19:06.693485 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:19:06.723082 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customers`
[0m20:19:06.739985 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customers"
[0m20:19:06.748058 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customers"
[0m20:19:06.750254 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customers"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customers`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:19:06.750254 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:19:08.635660 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-db5a-1457-b2a3-011f0b61481d) - Created
[0m20:19:09.471469 [debug] [Thread-3 (]: SQL status: OK in 2.720 seconds
[0m20:19:09.473474 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-db5a-1457-b2a3-011f0b61481d, command-id=01f08db1-dbc9-1f9d-9d5b-8c660bd4d772) - Closing
[0m20:19:09.492684 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:19:09.492684 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: Close
[0m20:19:09.492684 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-db5a-1457-b2a3-011f0b61481d) - Closing
[0m20:19:09.840881 [info ] [Thread-3 (]: 1 of 4 OK created sql view model default.bronze_customers ...................... [[32mOK[0m in 3.20s]
[0m20:19:09.841947 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customers
[0m20:19:09.843019 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:19:09.843019 [info ] [Thread-3 (]: 2 of 4 START sql view model default.bronze_returns ............................. [RUN]
[0m20:19:09.843019 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:19:09.843019 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:19:09.843019 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:19:09.853368 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:19:09.853368 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:19:09.873079 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:19:09.873839 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:19:09.873839 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:19:09.873839 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:19:09.873839 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:19:09.879547 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:19:11.516748 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-dd50-1203-bbee-f562da5b70c8) - Created
[0m20:19:12.813979 [debug] [Thread-3 (]: SQL status: OK in 2.930 seconds
[0m20:19:12.816321 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-dd50-1203-bbee-f562da5b70c8, command-id=01f08db1-dd80-195a-98b0-1a7e337070f2) - Closing
[0m20:19:12.818372 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:19:12.818372 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:19:12.818372 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-dd50-1203-bbee-f562da5b70c8) - Closing
[0m20:19:13.152580 [info ] [Thread-3 (]: 2 of 4 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.31s]
[0m20:19:13.152580 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:19:13.152580 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:19:13.152580 [info ] [Thread-3 (]: 3 of 4 START sql view model default.bronze_sales ............................... [RUN]
[0m20:19:13.152580 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:19:13.152580 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:19:13.161018 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:19:13.168457 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:19:13.168457 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:19:13.176691 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:19:13.178373 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:19:13.180842 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:19:13.183717 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:19:13.185575 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:19:13.187801 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:19:14.501324 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-df1a-1157-aede-a4c5d14b5471) - Created
[0m20:19:15.505166 [debug] [Thread-3 (]: SQL status: OK in 2.320 seconds
[0m20:19:15.507175 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-df1a-1157-aede-a4c5d14b5471, command-id=01f08db1-df47-19ca-88a9-1407cd348b17) - Closing
[0m20:19:15.507175 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:19:15.507175 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:19:15.507175 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-df1a-1157-aede-a4c5d14b5471) - Closing
[0m20:19:15.978054 [info ] [Thread-3 (]: 3 of 4 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.83s]
[0m20:19:15.982203 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:19:15.984288 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:19:15.984288 [info ] [Thread-3 (]: 4 of 4 START sql view model default.bronze_store ............................... [RUN]
[0m20:19:15.984288 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:19:15.988294 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:19:15.988294 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:19:15.996377 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:19:16.001254 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:19:16.003280 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:19:16.003280 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:19:16.003280 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:19:16.012046 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:19:16.012046 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:19:16.013413 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:19:17.321083 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-e0d2-1cfd-9588-0bc7f33e3654) - Created
[0m20:19:18.356104 [debug] [Thread-3 (]: SQL status: OK in 2.340 seconds
[0m20:19:18.358112 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db1-e0d2-1cfd-9588-0bc7f33e3654, command-id=01f08db1-e0fb-1d1b-aaf4-f12faab194e0) - Closing
[0m20:19:18.359251 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:19:18.360839 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:19:18.361546 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db1-e0d2-1cfd-9588-0bc7f33e3654) - Closing
[0m20:19:18.744974 [info ] [Thread-3 (]: 4 of 4 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.76s]
[0m20:19:18.748821 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:19:18.752942 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:19:18.752942 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:19:18.754950 [info ] [MainThread]: 
[0m20:19:18.754950 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 17.99 seconds (17.99s).
[0m20:19:18.760427 [debug] [MainThread]: Command end result
[0m20:19:19.032020 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:19:19.042587 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:19:19.064297 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:19:19.068339 [info ] [MainThread]: 
[0m20:19:19.090442 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:19:19.112156 [info ] [MainThread]: 
[0m20:19:19.130465 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m20:19:19.144564 [debug] [MainThread]: Command `dbt build` succeeded at 20:19:19.144564 after 23.04 seconds
[0m20:19:19.153374 [debug] [MainThread]: Flushing usage events
[0m20:20:24.709351 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:20:24.886248 | 7fb6ca88-1852-4360-b56e-28f98f3eb3fa ==============================
[0m20:20:24.886248 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:20:24.888659 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m20:20:26.730859 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:20:26.732828 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:20:26.733807 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:20:28.722559 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:20:29.461079 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:20:29.747559 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:20:29.750552 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:20:29.763582 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:20:29.954608 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:20:29.959672 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:20:30.007095 [info ] [MainThread]: Found 4 models, 6 sources, 685 macros
[0m20:20:30.010215 [info ] [MainThread]: 
[0m20:20:30.011215 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:20:30.012326 [info ] [MainThread]: 
[0m20:20:30.014336 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:20:30.016345 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:20:30.028879 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:20:30.031160 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:20:30.033165 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:20:30.035169 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:20:30.037188 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:20:31.869436 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-0d16-111e-85c0-5472c0ff1a72) - Created
[0m20:20:32.318806 [debug] [ThreadPool]: SQL status: OK in 2.280 seconds
[0m20:20:32.320807 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-0d16-111e-85c0-5472c0ff1a72, command-id=01f08db2-0d68-14c0-95e2-43d91f1fb6a6) - Closing
[0m20:20:32.321932 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:20:32.321932 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-0d16-111e-85c0-5472c0ff1a72) - Closing
[0m20:20:32.653528 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:20:32.653528 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:20:32.688864 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:20:32.689877 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:20:32.689877 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:20:36.642677 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-0fa2-19eb-aee2-bc1c164a6c9a) - Created
[0m20:20:37.406317 [debug] [ThreadPool]: SQL status: OK in 4.720 seconds
[0m20:20:37.418330 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-0fa2-19eb-aee2-bc1c164a6c9a, command-id=01f08db2-104a-1867-99f2-6ea1b19fe8c9) - Closing
[0m20:20:37.419326 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:20:37.420328 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-0fa2-19eb-aee2-bc1c164a6c9a) - Closing
[0m20:20:37.730993 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customers
[0m20:20:37.733394 [info ] [Thread-3 (]: 1 of 4 START sql view model default.bronze_customers ........................... [RUN]
[0m20:20:37.735395 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customers) - Creating connection
[0m20:20:37.736439 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customers'
[0m20:20:37.737393 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customers
[0m20:20:37.752748 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customers"
[0m20:20:37.802678 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customers
[0m20:20:37.892505 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:20:37.895508 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:20:37.954310 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customers`
[0m20:20:37.981311 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customers"
[0m20:20:37.986762 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customers"
[0m20:20:37.987758 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customers"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customers`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:20:37.988759 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:20:39.748444 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-11df-1633-a461-e3c2377b4c1a) - Created
[0m20:20:40.673066 [debug] [Thread-3 (]: SQL status: OK in 2.690 seconds
[0m20:20:40.674756 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-11df-1633-a461-e3c2377b4c1a, command-id=01f08db2-121b-1367-897e-6717a15eddb3) - Closing
[0m20:20:40.694852 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:20:40.698214 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: Close
[0m20:20:40.699697 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-11df-1633-a461-e3c2377b4c1a) - Closing
[0m20:20:41.002683 [info ] [Thread-3 (]: 1 of 4 OK created sql view model default.bronze_customers ...................... [[32mOK[0m in 3.26s]
[0m20:20:41.003683 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customers
[0m20:20:41.004682 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:20:41.005682 [info ] [Thread-3 (]: 2 of 4 START sql view model default.bronze_returns ............................. [RUN]
[0m20:20:41.006681 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:20:41.007683 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:20:41.008681 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:20:41.019837 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:20:41.023851 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:20:41.039419 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:20:41.042427 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:20:41.044432 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:20:41.045426 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:20:41.047430 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:20:41.048429 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:20:42.513173 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-1386-1623-82cd-a7d1c66ec887) - Created
[0m20:20:44.059134 [debug] [Thread-3 (]: SQL status: OK in 3.010 seconds
[0m20:20:44.061111 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-1386-1623-82cd-a7d1c66ec887, command-id=01f08db2-13be-1d52-b969-900bf73f2103) - Closing
[0m20:20:44.064722 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:20:44.068982 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:20:44.069990 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-1386-1623-82cd-a7d1c66ec887) - Closing
[0m20:20:44.465119 [info ] [Thread-3 (]: 2 of 4 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.46s]
[0m20:20:44.468131 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:20:44.469131 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:20:44.470247 [info ] [Thread-3 (]: 3 of 4 START sql view model default.bronze_sales ............................... [RUN]
[0m20:20:44.473259 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:20:44.474260 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:20:44.475258 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:20:44.489715 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:20:44.492818 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:20:44.502803 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:20:44.507302 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:20:44.509311 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:20:44.510311 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:20:44.511517 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:20:44.512523 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:20:46.052590 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-15b6-1701-b773-9885cd23c504) - Created
[0m20:20:46.971360 [debug] [Thread-3 (]: SQL status: OK in 2.460 seconds
[0m20:20:46.973360 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-15b6-1701-b773-9885cd23c504, command-id=01f08db2-15da-1cbe-8994-d21dc365d661) - Closing
[0m20:20:46.974361 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:20:46.976360 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:20:46.976360 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-15b6-1701-b773-9885cd23c504) - Closing
[0m20:20:47.604480 [info ] [Thread-3 (]: 3 of 4 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.13s]
[0m20:20:47.606480 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:20:47.606480 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:20:47.607480 [info ] [Thread-3 (]: 4 of 4 START sql view model default.bronze_store ............................... [RUN]
[0m20:20:47.608479 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:20:47.609480 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:20:47.609480 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:20:47.617996 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:20:47.619997 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:20:47.625017 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:20:47.628996 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:20:47.631015 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:20:47.635004 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:20:47.636003 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:20:47.636003 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:20:51.590805 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-18fe-1dde-87d2-d3fd1599555c) - Created
[0m20:20:52.854418 [debug] [Thread-3 (]: SQL status: OK in 5.220 seconds
[0m20:20:52.856417 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-18fe-1dde-87d2-d3fd1599555c, command-id=01f08db2-1930-1cbd-a3ee-761f3287008c) - Closing
[0m20:20:52.857746 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:20:52.859752 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:20:52.859752 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-18fe-1dde-87d2-d3fd1599555c) - Closing
[0m20:20:53.168333 [info ] [Thread-3 (]: 4 of 4 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 5.56s]
[0m20:20:53.170333 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:20:53.172330 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:20:53.172330 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:20:53.173330 [info ] [MainThread]: 
[0m20:20:53.174346 [info ] [MainThread]: Finished running 4 view models in 0 hours 0 minutes and 23.16 seconds (23.16s).
[0m20:20:53.176332 [debug] [MainThread]: Command end result
[0m20:20:53.410423 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:20:53.416788 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:20:53.432937 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:20:53.433963 [info ] [MainThread]: 
[0m20:20:53.435037 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:20:53.435956 [info ] [MainThread]: 
[0m20:20:53.437101 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m20:20:53.439155 [debug] [MainThread]: Command `dbt build` succeeded at 20:20:53.439155 after 28.85 seconds
[0m20:20:53.439155 [debug] [MainThread]: Flushing usage events
[0m20:23:51.113344 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:23:51.225962 | 5ae4d646-273c-4cb9-b836-4dd192ca63f2 ==============================
[0m20:23:51.225962 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:23:51.229408 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m20:23:52.849924 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:23:52.849924 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:23:52.849924 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:23:54.439369 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:23:55.174463 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:23:55.452814 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:23:55.454653 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:23:55.467701 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:23:55.650782 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:23:55.659171 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:23:55.711670 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m20:23:55.715346 [info ] [MainThread]: 
[0m20:23:55.715346 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:23:55.715346 [info ] [MainThread]: 
[0m20:23:55.720075 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:23:55.721504 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:23:55.730718 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:23:55.730718 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:23:55.730718 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:23:55.730718 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:23:55.730718 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:23:59.311345 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-88b2-187f-8bf6-87d9d00c7bbc) - Created
[0m20:24:00.247410 [debug] [ThreadPool]: SQL status: OK in 4.520 seconds
[0m20:24:00.247410 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-88b2-187f-8bf6-87d9d00c7bbc, command-id=01f08db2-8931-14f7-a947-9d632016b479) - Closing
[0m20:24:00.247410 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:24:00.247410 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-88b2-187f-8bf6-87d9d00c7bbc) - Closing
[0m20:24:00.661911 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:24:00.661911 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:24:00.674996 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:24:00.674996 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:24:00.674996 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:24:02.488442 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-8abc-15b7-a1a3-68a39781a61e) - Created
[0m20:24:03.684949 [debug] [ThreadPool]: SQL status: OK in 3.010 seconds
[0m20:24:03.696392 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-8abc-15b7-a1a3-68a39781a61e, command-id=01f08db2-8af6-1272-9b13-e4a185158b99) - Closing
[0m20:24:03.698401 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:24:03.698401 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-8abc-15b7-a1a3-68a39781a61e) - Closing
[0m20:24:04.551780 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customers
[0m20:24:04.551780 [info ] [Thread-3 (]: 1 of 5 START sql view model default.bronze_customers ........................... [RUN]
[0m20:24:04.557682 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customers) - Creating connection
[0m20:24:04.557682 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customers'
[0m20:24:04.557682 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customers
[0m20:24:04.578172 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customers"
[0m20:24:04.580181 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customers
[0m20:24:04.612385 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:24:04.617601 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:24:04.644550 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customers`
[0m20:24:04.664604 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customers"
[0m20:24:04.664604 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customers"
[0m20:24:04.664604 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customers"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customers`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:24:04.664604 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:24:06.738988 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-8d48-13a2-9e42-5f7531dc8a8d) - Created
[0m20:24:08.122749 [debug] [Thread-3 (]: SQL status: OK in 3.460 seconds
[0m20:24:08.122749 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-8d48-13a2-9e42-5f7531dc8a8d, command-id=01f08db2-8d7b-1cff-8e4d-a82d65ada36e) - Closing
[0m20:24:08.152338 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:24:08.158930 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customers: Close
[0m20:24:08.164248 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-8d48-13a2-9e42-5f7531dc8a8d) - Closing
[0m20:24:08.546594 [info ] [Thread-3 (]: 1 of 5 OK created sql view model default.bronze_customers ...................... [[32mOK[0m in 3.98s]
[0m20:24:08.548618 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customers
[0m20:24:08.549149 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m20:24:08.550655 [info ] [Thread-3 (]: 2 of 5 START sql view model default.bronze_date ................................ [RUN]
[0m20:24:08.551188 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m20:24:08.552363 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m20:24:08.553328 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m20:24:08.572402 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m20:24:08.574875 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m20:24:08.583672 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:24:08.585621 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m20:24:08.587015 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m20:24:08.588045 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:24:08.588565 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m20:24:08.589090 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:24:10.675920 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-8f52-1353-b1dd-b2681913c0c5) - Created
[0m20:24:11.608694 [debug] [Thread-3 (]: SQL status: OK in 3.020 seconds
[0m20:24:11.617346 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-8f52-1353-b1dd-b2681913c0c5, command-id=01f08db2-8fd5-1a13-808e-c228fcc85d7c) - Closing
[0m20:24:11.619307 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:24:11.620037 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m20:24:11.620037 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-8f52-1353-b1dd-b2681913c0c5) - Closing
[0m20:24:12.331670 [info ] [Thread-3 (]: 2 of 5 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 3.78s]
[0m20:24:12.331670 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m20:24:12.336521 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:24:12.336521 [info ] [Thread-3 (]: 3 of 5 START sql view model default.bronze_returns ............................. [RUN]
[0m20:24:12.336521 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:24:12.336521 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:24:12.336521 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:24:12.350699 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:24:12.350699 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:24:12.361162 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:24:12.363170 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:24:12.363170 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:24:12.363170 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:24:12.363170 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:24:12.363170 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:24:13.969504 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-917d-1828-9946-8f1d1450ad91) - Created
[0m20:24:15.713987 [debug] [Thread-3 (]: SQL status: OK in 3.350 seconds
[0m20:24:15.716106 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-917d-1828-9946-8f1d1450ad91, command-id=01f08db2-91e4-1b28-9eae-a15fa68aafdd) - Closing
[0m20:24:15.717156 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:24:15.718748 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:24:15.719277 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-917d-1828-9946-8f1d1450ad91) - Closing
[0m20:24:16.038714 [info ] [Thread-3 (]: 3 of 5 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.70s]
[0m20:24:16.038714 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:24:16.038714 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:24:16.042152 [info ] [Thread-3 (]: 4 of 5 START sql view model default.bronze_sales ............................... [RUN]
[0m20:24:16.042152 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:24:16.046297 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:24:16.047108 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:24:16.054413 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:24:16.061351 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:24:16.066504 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:24:16.070228 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:24:16.071468 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:24:16.071468 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:24:16.077780 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:24:16.079053 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:24:18.075429 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-9410-174c-b33e-f35a3446ae75) - Created
[0m20:24:19.183204 [debug] [Thread-3 (]: SQL status: OK in 3.100 seconds
[0m20:24:19.183204 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-9410-174c-b33e-f35a3446ae75, command-id=01f08db2-943b-199c-9bb5-78c6184e94cf) - Closing
[0m20:24:19.199015 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:24:19.199015 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:24:19.199015 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-9410-174c-b33e-f35a3446ae75) - Closing
[0m20:24:19.511180 [info ] [Thread-3 (]: 4 of 5 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.47s]
[0m20:24:19.518532 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:24:19.518532 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:24:19.518532 [info ] [Thread-3 (]: 5 of 5 START sql view model default.bronze_store ............................... [RUN]
[0m20:24:19.518532 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:24:19.518532 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:24:19.524646 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:24:19.527177 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:24:19.532712 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:24:19.537851 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:24:19.540570 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:24:19.542582 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:24:19.542582 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:24:19.547993 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:24:19.549613 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:24:21.075057 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-95d4-1091-b4d1-815fefd0a825) - Created
[0m20:24:22.100898 [debug] [Thread-3 (]: SQL status: OK in 2.550 seconds
[0m20:24:22.100898 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-95d4-1091-b4d1-815fefd0a825, command-id=01f08db2-9604-1c52-a990-0640c0a0e863) - Closing
[0m20:24:22.100898 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:24:22.100898 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:24:22.100898 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-95d4-1091-b4d1-815fefd0a825) - Closing
[0m20:24:22.470369 [info ] [Thread-3 (]: 5 of 5 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 2.95s]
[0m20:24:22.477152 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:24:22.479163 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:24:22.479163 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:24:22.482581 [info ] [MainThread]: 
[0m20:24:22.485203 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 26.76 seconds (26.76s).
[0m20:24:22.488614 [debug] [MainThread]: Command end result
[0m20:24:22.673945 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:24:22.690503 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:24:22.692463 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:24:22.692463 [info ] [MainThread]: 
[0m20:24:22.692463 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:24:22.692463 [info ] [MainThread]: 
[0m20:24:22.692463 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m20:24:22.703919 [debug] [MainThread]: Command `dbt build` succeeded at 20:24:22.703919 after 31.71 seconds
[0m20:24:22.705672 [debug] [MainThread]: Flushing usage events
[0m20:25:20.437934 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:25:20.545166 | 664a1a5f-1401-4f0e-8358-ccd4ca259eb8 ==============================
[0m20:25:20.545166 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:25:20.545166 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m20:25:20.869145 [debug] [MainThread]: Command `dbt clean` succeeded at 20:25:20.868608 after 0.52 seconds
[0m20:25:20.870230 [debug] [MainThread]: Flushing usage events
[0m20:25:30.221206 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:25:30.329271 | d3420e85-4e91-47f2-9bae-075b16680e4b ==============================
[0m20:25:30.329271 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:25:30.329271 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m20:25:31.935521 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:25:31.938666 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:25:31.938666 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:25:33.609571 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:25:34.366696 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:25:34.366696 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m20:25:37.505086 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.dbt_eTl.example
[0m20:25:37.651106 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:25:37.659669 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:25:37.700572 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m20:25:37.701581 [info ] [MainThread]: 
[0m20:25:37.706716 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:25:37.709381 [info ] [MainThread]: 
[0m20:25:37.709381 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:25:37.709381 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:25:37.726338 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:25:37.726338 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:25:37.726338 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:25:37.729044 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:25:37.729430 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:40.128190 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-c4f4-1d84-ac10-92060eccb0f5) - Created
[0m20:25:41.110636 [debug] [ThreadPool]: SQL status: OK in 3.380 seconds
[0m20:25:41.110636 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-c4f4-1d84-ac10-92060eccb0f5, command-id=01f08db2-c52a-1061-8aaa-ab1c310f5983) - Closing
[0m20:25:41.110636 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:25:41.110636 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-c4f4-1d84-ac10-92060eccb0f5) - Closing
[0m20:25:41.439893 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:25:41.439893 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:25:41.456617 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:25:41.456617 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:25:41.456617 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:25:42.688256 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-c67a-15f9-9c7d-2a89c9821ab1) - Created
[0m20:25:43.377149 [debug] [ThreadPool]: SQL status: OK in 1.920 seconds
[0m20:25:43.386160 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db2-c67a-15f9-9c7d-2a89c9821ab1, command-id=01f08db2-c6ac-126c-aad1-b9007970be2f) - Closing
[0m20:25:43.386160 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:25:43.389654 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db2-c67a-15f9-9c7d-2a89c9821ab1) - Closing
[0m20:25:44.325914 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m20:25:44.339709 [info ] [Thread-3 (]: 1 of 5 START sql view model default.bronze_customer ............................ [RUN]
[0m20:25:44.343192 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m20:25:44.343192 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m20:25:44.343192 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m20:25:44.350634 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m20:25:44.359754 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m20:25:44.384371 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:25:44.388936 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:25:44.415899 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customer`
[0m20:25:44.436425 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m20:25:44.442984 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m20:25:44.442984 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m20:25:44.442984 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:25:46.056023 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-c86e-1d41-8342-e032c3055642) - Created
[0m20:25:46.957553 [debug] [Thread-3 (]: SQL status: OK in 2.510 seconds
[0m20:25:46.957553 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-c86e-1d41-8342-e032c3055642, command-id=01f08db2-c8ae-1d14-b9b4-201d7f9db12a) - Closing
[0m20:25:46.977065 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:25:46.977065 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m20:25:46.977065 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-c86e-1d41-8342-e032c3055642) - Closing
[0m20:25:47.230979 [info ] [Thread-3 (]: 1 of 5 OK created sql view model default.bronze_customer ....................... [[32mOK[0m in 2.87s]
[0m20:25:47.232993 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m20:25:47.232993 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m20:25:47.232993 [info ] [Thread-3 (]: 2 of 5 START sql view model default.bronze_date ................................ [RUN]
[0m20:25:47.232993 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m20:25:47.232993 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m20:25:47.232993 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m20:25:47.232993 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m20:25:47.248725 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m20:25:47.255453 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:25:47.259962 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m20:25:47.259962 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m20:25:47.259962 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:25:47.259962 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m20:25:47.259962 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:25:49.283819 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-ca61-122d-ba17-735b877effcd) - Created
[0m20:25:50.246275 [debug] [Thread-3 (]: SQL status: OK in 2.990 seconds
[0m20:25:50.246275 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-ca61-122d-ba17-735b877effcd, command-id=01f08db2-ca9b-1125-a80f-a4f83dbafb12) - Closing
[0m20:25:50.246275 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:25:50.252275 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m20:25:50.253283 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-ca61-122d-ba17-735b877effcd) - Closing
[0m20:25:50.508197 [info ] [Thread-3 (]: 2 of 5 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 3.28s]
[0m20:25:50.508197 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m20:25:50.508197 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:25:50.515646 [info ] [Thread-3 (]: 3 of 5 START sql view model default.bronze_returns ............................. [RUN]
[0m20:25:50.515646 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:25:50.515646 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:25:50.515646 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:25:50.527430 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:25:50.530367 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:25:50.543926 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:25:50.549478 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:25:50.549478 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:25:50.549478 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:25:50.549478 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:25:50.554599 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:25:51.780356 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-cbea-12fb-bd95-48e30cca9377) - Created
[0m20:25:53.136638 [debug] [Thread-3 (]: SQL status: OK in 2.580 seconds
[0m20:25:53.137736 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-cbea-12fb-bd95-48e30cca9377, command-id=01f08db2-cc3c-1128-a0cf-4b3c560c644e) - Closing
[0m20:25:53.142626 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:25:53.145236 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:25:53.145236 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-cbea-12fb-bd95-48e30cca9377) - Closing
[0m20:25:54.014282 [info ] [Thread-3 (]: 3 of 5 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.50s]
[0m20:25:54.017297 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:25:54.018250 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:25:54.018952 [info ] [Thread-3 (]: 4 of 5 START sql view model default.bronze_sales ............................... [RUN]
[0m20:25:54.020957 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:25:54.021463 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:25:54.025311 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:25:54.035414 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:25:54.040468 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:25:54.048679 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:25:54.052732 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m20:25:54.058714 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:25:54.060725 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:25:54.062235 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m20:25:54.063170 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:25:58.042195 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-cf9c-15d6-9474-7fffc6117e15) - Created
[0m20:25:59.172581 [debug] [Thread-3 (]: SQL status: OK in 5.110 seconds
[0m20:25:59.172581 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-cf9c-15d6-9474-7fffc6117e15, command-id=01f08db2-cfd3-1f36-b651-0da7fd71106c) - Closing
[0m20:25:59.180045 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:25:59.180045 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:25:59.180045 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-cf9c-15d6-9474-7fffc6117e15) - Closing
[0m20:25:59.452268 [info ] [Thread-3 (]: 4 of 5 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 5.43s]
[0m20:25:59.452268 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:25:59.452268 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:25:59.452268 [info ] [Thread-3 (]: 5 of 5 START sql view model default.bronze_store ............................... [RUN]
[0m20:25:59.452268 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:25:59.452268 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:25:59.452268 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:25:59.475555 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:25:59.475555 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:25:59.479979 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:25:59.488825 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m20:25:59.493174 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:25:59.496294 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:25:59.496294 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m20:25:59.496294 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:26:01.138053 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-d175-1394-b746-ca8fcf445d77) - Created
[0m20:26:02.234765 [debug] [Thread-3 (]: SQL status: OK in 2.740 seconds
[0m20:26:02.234765 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db2-d175-1394-b746-ca8fcf445d77, command-id=01f08db2-d1a8-1fc1-a6f5-5b35c05c75eb) - Closing
[0m20:26:02.250573 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:26:02.251998 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:26:02.251998 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db2-d175-1394-b746-ca8fcf445d77) - Closing
[0m20:26:02.615637 [info ] [Thread-3 (]: 5 of 5 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 3.16s]
[0m20:26:02.615637 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:26:02.615637 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:26:02.615637 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:26:02.621926 [info ] [MainThread]: 
[0m20:26:02.624002 [info ] [MainThread]: Finished running 5 view models in 0 hours 0 minutes and 24.91 seconds (24.91s).
[0m20:26:02.628473 [debug] [MainThread]: Command end result
[0m20:26:02.688398 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:26:02.688398 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:26:02.710610 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:26:02.710610 [info ] [MainThread]: 
[0m20:26:02.710610 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:26:02.710610 [info ] [MainThread]: 
[0m20:26:02.710610 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m20:26:02.710610 [debug] [MainThread]: Command `dbt build` succeeded at 20:26:02.710610 after 32.61 seconds
[0m20:26:02.710610 [debug] [MainThread]: Flushing usage events
[0m20:28:39.891766 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:28:40.008795 | 7c0d4cf0-b88e-42cd-855a-5b4f1b4d8ed6 ==============================
[0m20:28:40.008795 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:28:40.011870 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m20:28:41.641961 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:28:41.642488 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:28:41.643015 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:28:43.312825 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:28:44.124749 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:28:44.449134 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:28:44.449908 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:28:44.715748 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:28:44.724702 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:28:44.766690 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m20:28:44.766690 [info ] [MainThread]: 
[0m20:28:44.777498 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:28:44.778153 [info ] [MainThread]: 
[0m20:28:44.778153 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:28:44.778153 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:28:44.796735 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:28:44.797840 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:28:44.798462 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:28:44.799394 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:28:44.799394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:46.083377 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-33d1-1325-a97c-0c664a6ed8ec) - Created
[0m20:28:46.865845 [debug] [ThreadPool]: SQL status: OK in 2.070 seconds
[0m20:28:46.869922 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-33d1-1325-a97c-0c664a6ed8ec, command-id=01f08db3-33f8-1a0e-9203-b1d12da74a61) - Closing
[0m20:28:46.869922 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:28:46.869922 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-33d1-1325-a97c-0c664a6ed8ec) - Closing
[0m20:28:47.266570 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:28:47.266570 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:28:47.290364 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:28:47.298380 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:28:47.298380 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:28:48.717317 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-355c-10b4-9912-3146c51f92e1) - Created
[0m20:28:49.369612 [debug] [ThreadPool]: SQL status: OK in 2.070 seconds
[0m20:28:49.375876 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-355c-10b4-9912-3146c51f92e1, command-id=01f08db3-3593-11fe-be40-284eed582876) - Closing
[0m20:28:49.375876 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:28:49.375876 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-355c-10b4-9912-3146c51f92e1) - Closing
[0m20:28:49.682737 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m20:28:49.686975 [info ] [Thread-3 (]: 1 of 5 START sql table model default.bronze_customer ........................... [RUN]
[0m20:28:49.686975 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m20:28:49.686975 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m20:28:49.686975 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m20:28:49.708380 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m20:28:49.713107 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m20:28:49.763138 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:28:49.763138 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:28:49.790665 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_customer`
[0m20:28:49.803140 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m20:28:49.803140 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_customer`
[0m20:28:49.806502 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:28:51.277461 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-36b6-1b93-bc3a-cf302ef9f2b7) - Created
[0m20:28:52.500039 [debug] [Thread-3 (]: SQL status: OK in 2.690 seconds
[0m20:28:52.502058 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-36b6-1b93-bc3a-cf302ef9f2b7, command-id=01f08db3-3714-16d0-b714-f278002d3fab) - Closing
[0m20:28:52.605386 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m20:28:52.610889 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m20:28:52.610889 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m20:29:01.304559 [debug] [Thread-3 (]: SQL status: OK in 8.690 seconds
[0m20:29:01.308452 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-36b6-1b93-bc3a-cf302ef9f2b7, command-id=01f08db3-37e6-116b-b41c-0b1cf1395b8a) - Closing
[0m20:29:01.949840 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:29:01.983435 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m20:29:01.983435 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-36b6-1b93-bc3a-cf302ef9f2b7) - Closing
[0m20:29:02.243583 [info ] [Thread-3 (]: 1 of 5 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 12.56s]
[0m20:29:02.249494 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m20:29:02.249494 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m20:29:02.249494 [info ] [Thread-3 (]: 2 of 5 START sql table model default.bronze_date ............................... [RUN]
[0m20:29:02.249494 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m20:29:02.249494 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m20:29:02.249494 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m20:29:02.260130 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m20:29:02.262588 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m20:29:02.270596 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:29:02.276437 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_date`
[0m20:29:02.276437 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:29:02.276437 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_date`
[0m20:29:02.276437 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:29:04.417434 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-3eb3-154b-8ee6-9d78980bd866) - Created
[0m20:29:05.599417 [debug] [Thread-3 (]: SQL status: OK in 3.320 seconds
[0m20:29:05.599417 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-3eb3-154b-8ee6-9d78980bd866, command-id=01f08db3-3ee7-15df-aad6-b24b92fb3c94) - Closing
[0m20:29:05.611534 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m20:29:05.611534 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:29:05.616153 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  
[0m20:29:09.438675 [debug] [Thread-3 (]: SQL status: OK in 3.820 seconds
[0m20:29:09.438675 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-3eb3-154b-8ee6-9d78980bd866, command-id=01f08db3-3f9d-106f-ae3b-987ec3e9c647) - Closing
[0m20:29:09.438675 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:29:09.438675 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m20:29:09.445816 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-3eb3-154b-8ee6-9d78980bd866) - Closing
[0m20:29:09.713848 [info ] [Thread-3 (]: 2 of 5 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 7.46s]
[0m20:29:09.715858 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m20:29:09.719909 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:29:09.721623 [info ] [Thread-3 (]: 3 of 5 START sql view model default.bronze_returns ............................. [RUN]
[0m20:29:09.722968 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:29:09.723859 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:29:09.723859 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:29:09.741629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:29:09.743024 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:29:09.784421 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:29:09.813461 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:29:09.818894 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:29:09.821612 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:29:09.822534 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:29:09.822534 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:29:11.506935 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-42ed-15d2-b8c0-17c0098dd6a9) - Created
[0m20:29:12.508576 [debug] [Thread-3 (]: SQL status: OK in 2.690 seconds
[0m20:29:12.510584 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-42ed-15d2-b8c0-17c0098dd6a9, command-id=01f08db3-4320-1753-af3b-cd9363869a1e) - Closing
[0m20:29:12.510584 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:29:12.512592 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:29:12.514603 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-42ed-15d2-b8c0-17c0098dd6a9) - Closing
[0m20:29:12.981148 [info ] [Thread-3 (]: 3 of 5 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.26s]
[0m20:29:12.987414 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:29:12.987414 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:29:12.989421 [info ] [Thread-3 (]: 4 of 5 START sql table model default.bronze_sales .............................. [RUN]
[0m20:29:12.990465 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:29:12.992065 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:29:12.992733 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:29:13.009448 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:29:13.011470 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:29:13.019138 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:29:13.026361 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_sales`
[0m20:29:13.029382 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:29:13.030058 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_sales`
[0m20:29:13.030058 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:29:14.830376 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-44ed-111a-968d-01b8a0ccb58d) - Created
[0m20:29:15.668763 [debug] [Thread-3 (]: SQL status: OK in 2.640 seconds
[0m20:29:15.670774 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-44ed-111a-968d-01b8a0ccb58d, command-id=01f08db3-4522-15cf-9d05-c10bbf6290d9) - Closing
[0m20:29:15.674787 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:29:15.676793 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:29:15.676793 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  
[0m20:29:22.237584 [debug] [Thread-3 (]: SQL status: OK in 6.560 seconds
[0m20:29:22.239595 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-44ed-111a-968d-01b8a0ccb58d, command-id=01f08db3-459f-1b3a-9d5f-9631e12a36c6) - Closing
[0m20:29:22.532990 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:29:22.532990 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:29:22.532990 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-44ed-111a-968d-01b8a0ccb58d) - Closing
[0m20:29:22.869175 [info ] [Thread-3 (]: 4 of 5 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 9.88s]
[0m20:29:22.869175 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:29:22.869175 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:29:22.869175 [info ] [Thread-3 (]: 5 of 5 START sql table model default.bronze_store .............................. [RUN]
[0m20:29:22.869175 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:29:22.869175 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:29:22.869175 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:29:22.887457 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:29:22.888669 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:29:22.890718 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:29:22.900899 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_store`
[0m20:29:22.902928 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:29:22.904752 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_store`
[0m20:29:22.904752 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:29:24.287193 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-4a88-1de4-849f-f747c821f65b) - Created
[0m20:29:25.102330 [debug] [Thread-3 (]: SQL status: OK in 2.200 seconds
[0m20:29:25.102330 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-4a88-1de4-849f-f747c821f65b, command-id=01f08db3-4abe-170c-96c3-49326a3f8dbf) - Closing
[0m20:29:25.109647 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:29:25.110902 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:29:25.111535 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m20:29:28.242752 [debug] [Thread-3 (]: SQL status: OK in 3.130 seconds
[0m20:29:28.242752 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-4a88-1de4-849f-f747c821f65b, command-id=01f08db3-4b3b-1d68-ba1b-fe6753e75301) - Closing
[0m20:29:28.242752 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:29:28.242752 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:29:28.242752 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-4a88-1de4-849f-f747c821f65b) - Closing
[0m20:29:28.748835 [info ] [Thread-3 (]: 5 of 5 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 5.88s]
[0m20:29:28.748835 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:29:28.748835 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:29:28.748835 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:29:28.748835 [info ] [MainThread]: 
[0m20:29:28.758423 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 43.97 seconds (43.97s).
[0m20:29:28.762145 [debug] [MainThread]: Command end result
[0m20:29:28.958593 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:29:28.961789 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:29:28.977422 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:29:28.978250 [info ] [MainThread]: 
[0m20:29:28.978250 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:29:28.978250 [info ] [MainThread]: 
[0m20:29:28.978250 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m20:29:28.982922 [debug] [MainThread]: Command `dbt build` succeeded at 20:29:28.982922 after 49.27 seconds
[0m20:29:28.982922 [debug] [MainThread]: Flushing usage events
[0m20:32:25.834485 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:32:25.938989 | 0d500d3c-3e7f-4917-a096-a11e71090c80 ==============================
[0m20:32:25.938989 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:32:25.941361 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m20:32:27.907565 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:32:27.908633 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:32:27.908633 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:32:29.683609 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:32:30.572041 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:32:30.884419 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:32:30.891623 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:32:31.078007 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:32:31.093152 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:32:31.127155 [info ] [MainThread]: Found 5 models, 6 sources, 685 macros
[0m20:32:31.140873 [info ] [MainThread]: 
[0m20:32:31.145404 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:32:31.147598 [info ] [MainThread]: 
[0m20:32:31.149024 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:32:31.150696 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:32:31.170626 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:32:31.171704 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:32:31.172216 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:32:31.175367 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:32:31.176048 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:32:32.633825 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-bad2-1bed-b2df-afc934c420cd) - Created
[0m20:32:33.121957 [debug] [ThreadPool]: SQL status: OK in 1.950 seconds
[0m20:32:33.121957 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-bad2-1bed-b2df-afc934c420cd, command-id=01f08db3-bb04-1665-9ad2-5415372615d9) - Closing
[0m20:32:33.125344 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:32:33.126105 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-bad2-1bed-b2df-afc934c420cd) - Closing
[0m20:32:33.418179 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:32:33.424455 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:32:33.453546 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:32:33.453546 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:32:33.455551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:32:35.009593 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-bc43-1086-a425-5e04d19748b9) - Created
[0m20:32:35.702853 [debug] [ThreadPool]: SQL status: OK in 2.250 seconds
[0m20:32:35.711748 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-bc43-1086-a425-5e04d19748b9, command-id=01f08db3-bc6e-115d-8c78-b51cf6ff8780) - Closing
[0m20:32:35.711748 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:32:35.718052 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-bc43-1086-a425-5e04d19748b9) - Closing
[0m20:32:36.157948 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m20:32:36.161621 [info ] [Thread-3 (]: 1 of 5 START sql table model default.bronze_customer ........................... [RUN]
[0m20:32:36.165446 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m20:32:36.166633 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m20:32:36.166633 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m20:32:36.188805 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m20:32:36.204106 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m20:32:36.248237 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:32:36.250530 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:32:36.348750 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m20:32:36.348750 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m20:32:36.348750 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m20:32:36.351716 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:32:37.691277 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-bdd7-18b4-9d36-aeead56734b5) - Created
[0m20:32:40.243627 [debug] [Thread-3 (]: SQL status: OK in 3.890 seconds
[0m20:32:40.243627 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-bdd7-18b4-9d36-aeead56734b5, command-id=01f08db3-be0c-178a-9a4a-d00a8c79af49) - Closing
[0m20:32:40.327666 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:32:40.439919 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m20:32:40.442818 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-bdd7-18b4-9d36-aeead56734b5) - Closing
[0m20:32:40.902305 [info ] [Thread-3 (]: 1 of 5 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.72s]
[0m20:32:40.902305 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m20:32:40.902305 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m20:32:40.912277 [info ] [Thread-3 (]: 2 of 5 START sql table model default.bronze_date ............................... [RUN]
[0m20:32:40.915954 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m20:32:40.915954 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m20:32:40.915954 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m20:32:40.941860 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m20:32:40.968064 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m20:32:41.015185 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:32:41.052330 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m20:32:41.069007 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:32:41.069007 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  
[0m20:32:41.075398 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:32:42.809387 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c0e5-199a-99a5-71b341e401f9) - Created
[0m20:32:44.866236 [debug] [Thread-3 (]: SQL status: OK in 3.790 seconds
[0m20:32:44.869841 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-c0e5-199a-99a5-71b341e401f9, command-id=01f08db3-c112-1085-885c-c1c8880e4e15) - Closing
[0m20:32:44.878717 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:32:44.886533 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m20:32:44.888542 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c0e5-199a-99a5-71b341e401f9) - Closing
[0m20:32:45.166864 [info ] [Thread-3 (]: 2 of 5 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 4.25s]
[0m20:32:45.171406 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m20:32:45.174641 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:32:45.180479 [info ] [Thread-3 (]: 3 of 5 START sql view model default.bronze_returns ............................. [RUN]
[0m20:32:45.186239 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:32:45.188061 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:32:45.190567 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:32:45.221188 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:32:45.224345 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:32:45.304708 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:32:45.377305 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:32:45.384037 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:32:45.384037 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:32:45.384037 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:32:45.392136 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:32:47.316449 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c389-19a4-bc64-2a620c131328) - Created
[0m20:32:48.144117 [debug] [Thread-3 (]: SQL status: OK in 2.750 seconds
[0m20:32:48.151360 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-c389-19a4-bc64-2a620c131328, command-id=01f08db3-c3c0-1a80-9220-44359ff8036c) - Closing
[0m20:32:48.156947 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:32:48.162263 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:32:48.166376 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c389-19a4-bc64-2a620c131328) - Closing
[0m20:32:48.517507 [info ] [Thread-3 (]: 3 of 5 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.33s]
[0m20:32:48.524003 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:32:48.527265 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:32:48.531691 [info ] [Thread-3 (]: 4 of 5 START sql table model default.bronze_sales .............................. [RUN]
[0m20:32:48.531691 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:32:48.531691 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:32:48.531691 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:32:48.559266 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:32:48.563606 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:32:48.587470 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:32:48.597455 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:32:48.604480 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:32:48.604480 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  
[0m20:32:48.604480 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:32:50.209990 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c553-1975-b14e-5a104eb1faff) - Created
[0m20:32:52.582351 [debug] [Thread-3 (]: SQL status: OK in 3.980 seconds
[0m20:32:52.582351 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-c553-1975-b14e-5a104eb1faff, command-id=01f08db3-c580-1447-8eb0-360b33835457) - Closing
[0m20:32:52.582351 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:32:52.582351 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:32:52.582351 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c553-1975-b14e-5a104eb1faff) - Closing
[0m20:32:53.041653 [info ] [Thread-3 (]: 4 of 5 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 4.51s]
[0m20:32:53.045329 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:32:53.046844 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:32:53.046844 [info ] [Thread-3 (]: 5 of 5 START sql table model default.bronze_store .............................. [RUN]
[0m20:32:53.049733 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:32:53.049733 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:32:53.049733 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:32:53.059756 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:32:53.059756 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:32:53.068193 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:32:53.075009 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:32:53.080220 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:32:53.080220 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m20:32:53.082232 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:32:54.215058 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c7ae-1698-80f5-1a7dbf8de636) - Created
[0m20:32:56.523101 [debug] [Thread-3 (]: SQL status: OK in 3.440 seconds
[0m20:32:56.526733 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-c7ae-1698-80f5-1a7dbf8de636, command-id=01f08db3-c7df-151f-847f-66530a3dedad) - Closing
[0m20:32:56.530905 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:32:56.536401 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:32:56.538412 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-c7ae-1698-80f5-1a7dbf8de636) - Closing
[0m20:32:56.931879 [info ] [Thread-3 (]: 5 of 5 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.88s]
[0m20:32:56.933350 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:32:56.938455 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:32:56.938455 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:32:56.938455 [info ] [MainThread]: 
[0m20:32:56.940462 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 25.79 seconds (25.79s).
[0m20:32:56.943130 [debug] [MainThread]: Command end result
[0m20:32:57.174584 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:32:57.183535 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:32:57.191406 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:32:57.191941 [info ] [MainThread]: 
[0m20:32:57.192989 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:32:57.192989 [info ] [MainThread]: 
[0m20:32:57.197582 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m20:32:57.199820 [debug] [MainThread]: Command `dbt build` succeeded at 20:32:57.199292 after 31.48 seconds
[0m20:32:57.200956 [debug] [MainThread]: Flushing usage events
[0m20:34:13.034047 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 20:34:13.146321 | f423924f-a5df-4033-81c6-0d3f0b6c7204 ==============================
[0m20:34:13.146321 [info ] [MainThread]: Running with dbt=1.10.11
[0m20:34:13.146321 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m20:34:14.809429 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m20:34:14.811598 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m20:34:14.812143 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m20:34:16.449587 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m20:34:17.164919 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m20:34:17.442292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m20:34:17.442292 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m20:34:17.657554 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:34:17.667034 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:34:17.705818 [info ] [MainThread]: Found 5 models, 5 sources, 685 macros
[0m20:34:17.710606 [info ] [MainThread]: 
[0m20:34:17.710606 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m20:34:17.714788 [info ] [MainThread]: 
[0m20:34:17.716603 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:34:17.716603 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:34:17.733240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m20:34:17.733240 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m20:34:17.733240 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m20:34:17.733240 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m20:34:17.733240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:34:20.487553 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-faec-1b41-b417-7a2ef0d68811) - Created
[0m20:34:21.340766 [debug] [ThreadPool]: SQL status: OK in 3.610 seconds
[0m20:34:21.340766 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-faec-1b41-b417-7a2ef0d68811, command-id=01f08db3-fb4e-1e42-abcf-52ecc156b216) - Closing
[0m20:34:21.340766 [debug] [ThreadPool]: On list_dbt-project: Close
[0m20:34:21.340766 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-faec-1b41-b417-7a2ef0d68811) - Closing
[0m20:34:21.858862 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m20:34:21.858862 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m20:34:21.888027 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m20:34:21.888027 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m20:34:21.888027 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m20:34:23.460110 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-fce8-1e26-9932-f8fde51cf55c) - Created
[0m20:34:24.185995 [debug] [ThreadPool]: SQL status: OK in 2.300 seconds
[0m20:34:24.185995 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08db3-fce8-1e26-9932-f8fde51cf55c, command-id=01f08db3-fd10-13d6-a145-2bf32821ca96) - Closing
[0m20:34:24.185995 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m20:34:24.185995 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08db3-fce8-1e26-9932-f8fde51cf55c) - Closing
[0m20:34:24.591402 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m20:34:24.591402 [info ] [Thread-3 (]: 1 of 5 START sql table model default.bronze_customer ........................... [RUN]
[0m20:34:24.607600 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m20:34:24.608827 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m20:34:24.608827 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m20:34:24.628131 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m20:34:24.630886 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m20:34:24.664879 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:34:24.664879 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m20:34:24.778131 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m20:34:24.778131 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m20:34:24.778131 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m20:34:24.778131 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:34:26.324212 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-fe8f-130d-80e4-52271abc8f07) - Created
[0m20:34:28.673905 [debug] [Thread-3 (]: SQL status: OK in 3.900 seconds
[0m20:34:28.687080 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db3-fe8f-130d-80e4-52271abc8f07, command-id=01f08db3-fec6-1179-91ae-0523b584ca4e) - Closing
[0m20:34:28.709283 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:34:28.744382 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m20:34:28.744382 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db3-fe8f-130d-80e4-52271abc8f07) - Closing
[0m20:34:30.226614 [info ] [Thread-3 (]: 1 of 5 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 5.62s]
[0m20:34:30.233363 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m20:34:30.233363 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m20:34:30.235374 [info ] [Thread-3 (]: 2 of 5 START sql table model default.bronze_date ............................... [RUN]
[0m20:34:30.235374 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m20:34:30.235374 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m20:34:30.235374 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m20:34:30.243030 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m20:34:30.246933 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m20:34:30.252346 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:34:30.263575 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m20:34:30.265613 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m20:34:30.265613 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  
[0m20:34:30.265613 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:34:31.597570 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-01bb-1133-97f0-d27078970f98) - Created
[0m20:34:33.915104 [debug] [Thread-3 (]: SQL status: OK in 3.650 seconds
[0m20:34:33.926004 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db4-01bb-1133-97f0-d27078970f98, command-id=01f08db4-01ef-169e-bd5e-7092046bce9b) - Closing
[0m20:34:33.926004 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:34:33.931644 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m20:34:33.931644 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-01bb-1133-97f0-d27078970f98) - Closing
[0m20:34:34.311043 [info ] [Thread-3 (]: 2 of 5 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 4.08s]
[0m20:34:34.311043 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m20:34:34.311043 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m20:34:34.311043 [info ] [Thread-3 (]: 3 of 5 START sql view model default.bronze_returns ............................. [RUN]
[0m20:34:34.311043 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m20:34:34.322994 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m20:34:34.322994 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m20:34:34.333231 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m20:34:34.335238 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m20:34:34.371279 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m20:34:34.390542 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m20:34:34.390542 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m20:34:34.395121 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m20:34:34.395748 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m20:34:34.395748 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:34:35.784915 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-0435-1caa-9884-cdd6049717b2) - Created
[0m20:34:36.847753 [debug] [Thread-3 (]: SQL status: OK in 2.450 seconds
[0m20:34:36.848398 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db4-0435-1caa-9884-cdd6049717b2, command-id=01f08db4-0469-1dfa-b4bc-7d904c45761f) - Closing
[0m20:34:36.849917 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:34:36.852008 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m20:34:36.852008 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-0435-1caa-9884-cdd6049717b2) - Closing
[0m20:34:37.582026 [info ] [Thread-3 (]: 3 of 5 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.27s]
[0m20:34:37.582026 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m20:34:37.582026 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m20:34:37.582026 [info ] [Thread-3 (]: 4 of 5 START sql table model default.bronze_sales .............................. [RUN]
[0m20:34:37.582026 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m20:34:37.582026 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m20:34:37.582026 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m20:34:37.597186 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m20:34:37.597186 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m20:34:37.603717 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:34:37.607400 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m20:34:37.613691 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m20:34:37.614940 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  
[0m20:34:37.614940 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:34:39.338900 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-0656-1719-9735-b1f76bd37886) - Created
[0m20:34:41.787160 [debug] [Thread-3 (]: SQL status: OK in 4.170 seconds
[0m20:34:41.789170 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db4-0656-1719-9735-b1f76bd37886, command-id=01f08db4-068a-14b4-af03-6122b3268d93) - Closing
[0m20:34:41.794838 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:34:41.799164 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m20:34:41.799164 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-0656-1719-9735-b1f76bd37886) - Closing
[0m20:34:42.214351 [info ] [Thread-3 (]: 4 of 5 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 4.63s]
[0m20:34:42.214351 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m20:34:42.214351 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m20:34:42.217814 [info ] [Thread-3 (]: 5 of 5 START sql table model default.bronze_store .............................. [RUN]
[0m20:34:42.219924 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m20:34:42.219924 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m20:34:42.219924 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m20:34:42.235629 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m20:34:42.237741 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m20:34:42.399695 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m20:34:42.399695 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m20:34:42.399695 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m20:34:42.399695 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m20:34:42.399695 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m20:34:44.256244 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-094a-1026-8e10-5fc2f993d217) - Created
[0m20:34:46.905802 [debug] [Thread-3 (]: SQL status: OK in 4.510 seconds
[0m20:34:46.906819 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08db4-094a-1026-8e10-5fc2f993d217, command-id=01f08db4-0975-1f35-9cde-4a0b142d60f1) - Closing
[0m20:34:46.906819 [debug] [Thread-3 (]: Applying tags to relation None
[0m20:34:46.906819 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m20:34:46.906819 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08db4-094a-1026-8e10-5fc2f993d217) - Closing
[0m20:34:47.256338 [info ] [Thread-3 (]: 5 of 5 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 5.04s]
[0m20:34:47.261372 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m20:34:47.264084 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m20:34:47.264786 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m20:34:47.265821 [info ] [MainThread]: 
[0m20:34:47.266359 [info ] [MainThread]: Finished running 4 table models, 1 view model in 0 hours 0 minutes and 29.55 seconds (29.55s).
[0m20:34:47.269426 [debug] [MainThread]: Command end result
[0m20:34:47.343863 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m20:34:47.349946 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m20:34:47.359064 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m20:34:47.363787 [info ] [MainThread]: 
[0m20:34:47.363787 [info ] [MainThread]: [32mCompleted successfully[0m
[0m20:34:47.363787 [info ] [MainThread]: 
[0m20:34:47.363787 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m20:34:47.366257 [debug] [MainThread]: Command `dbt build` succeeded at 20:34:47.366257 after 34.42 seconds
[0m20:34:47.366257 [debug] [MainThread]: Flushing usage events
[0m23:37:11.109167 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 23:37:11.285657 | 9d6d1df4-a1fb-4e11-a3f4-71714849e4a5 ==============================
[0m23:37:11.285657 [info ] [MainThread]: Running with dbt=1.10.11
[0m23:37:11.287826 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m23:37:17.203560 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:37:17.204608 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:37:17.205675 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:37:19.816165 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:37:20.763037 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m23:37:21.131482 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:37:21.131482 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:37:21.365332 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:37:21.375220 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:37:21.431851 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:37:21.439621 [info ] [MainThread]: 
[0m23:37:21.439621 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:37:21.439621 [info ] [MainThread]: 
[0m23:37:21.444955 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:37:21.447842 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:37:21.472690 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m23:37:21.475063 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m23:37:21.475063 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m23:37:21.475063 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m23:37:21.475063 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:37:23.309217 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dcd-8d55-1dbe-8994-82cbd241d685) - Created
[0m23:38:24.961792 [debug] [ThreadPool]: SQL status: OK in 63.490 seconds
[0m23:38:24.977964 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dcd-8d55-1dbe-8994-82cbd241d685, command-id=01f08dcd-b1ac-1829-ad51-f72e3aeea379) - Closing
[0m23:38:24.981258 [debug] [ThreadPool]: On list_dbt-project: Close
[0m23:38:24.981258 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dcd-8d55-1dbe-8994-82cbd241d685) - Closing
[0m23:38:25.472951 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m23:38:25.472951 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m23:38:25.544800 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m23:38:25.544800 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m23:38:25.558395 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:38:27.107283 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dcd-b38b-15ea-ae0d-31011420af04) - Created
[0m23:38:29.910435 [debug] [ThreadPool]: SQL status: OK in 4.340 seconds
[0m23:38:29.974122 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dcd-b38b-15ea-ae0d-31011420af04, command-id=01f08dcd-b3ba-1ca7-884b-beffab377c81) - Closing
[0m23:38:29.979971 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m23:38:29.983998 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dcd-b38b-15ea-ae0d-31011420af04) - Closing
[0m23:38:30.629820 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m23:38:30.629820 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:38:30.629820 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m23:38:30.638948 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m23:38:30.638948 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m23:38:30.689570 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m23:38:30.694840 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m23:38:30.806005 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:38:30.806005 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:38:31.110017 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m23:38:31.114381 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:38:31.114381 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m23:38:31.122048 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:38:32.770033 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-b6f7-1466-bfda-8f6ab8ce5c74) - Created
[0m23:38:41.848912 [debug] [Thread-3 (]: SQL status: OK in 10.730 seconds
[0m23:38:41.853388 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-b6f7-1466-bfda-8f6ab8ce5c74, command-id=01f08dcd-b719-1d76-b85e-c04f19d58489) - Closing
[0m23:38:42.554415 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:38:42.666082 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m23:38:42.670109 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-b6f7-1466-bfda-8f6ab8ce5c74) - Closing
[0m23:38:42.942962 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 12.30s]
[0m23:38:42.948252 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m23:38:42.952369 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m23:38:42.952369 [info ] [Thread-3 (]: 2 of 6 START sql table model default.bronze_date ............................... [RUN]
[0m23:38:42.960738 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m23:38:42.963345 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m23:38:42.967384 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m23:38:43.037439 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m23:38:43.074205 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m23:38:43.136939 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:38:43.197741 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m23:38:43.209102 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m23:38:43.223067 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_date`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  
[0m23:38:43.233328 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:38:44.923956 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-be29-18c0-9630-3c774627f243) - Created
[0m23:38:51.748216 [debug] [Thread-3 (]: SQL status: OK in 8.520 seconds
[0m23:38:51.763870 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-be29-18c0-9630-3c774627f243, command-id=01f08dcd-be58-1feb-a2ea-6788b6eaed62) - Closing
[0m23:38:52.597736 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:38:52.604384 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m23:38:52.606290 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-be29-18c0-9630-3c774627f243) - Closing
[0m23:38:53.061469 [info ] [Thread-3 (]: 2 of 6 OK created sql table model default.bronze_date .......................... [[32mOK[0m in 10.10s]
[0m23:38:53.067217 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m23:38:53.069761 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m23:38:53.075223 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m23:38:53.079767 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m23:38:53.082235 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m23:38:53.082235 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m23:38:53.108624 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m23:38:53.119529 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m23:38:53.134696 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:38:53.146534 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m23:38:53.151561 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:38:53.157167 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m23:38:53.160383 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:38:55.086697 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-c434-1e27-ba80-c880c1196092) - Created
[0m23:38:59.001500 [debug] [Thread-3 (]: SQL status: OK in 5.840 seconds
[0m23:38:59.005181 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-c434-1e27-ba80-c880c1196092, command-id=01f08dcd-c467-1d20-bf6b-5d78528136b1) - Closing
[0m23:38:59.010349 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:38:59.018393 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m23:38:59.018393 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-c434-1e27-ba80-c880c1196092) - Closing
[0m23:38:59.273202 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 6.19s]
[0m23:38:59.277541 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m23:38:59.277541 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m23:38:59.277541 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m23:38:59.289148 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m23:38:59.289148 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m23:38:59.289148 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m23:38:59.323374 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m23:38:59.332103 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m23:38:59.439582 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:38:59.510070 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m23:38:59.531208 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m23:38:59.536409 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m23:38:59.538816 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m23:38:59.546931 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:39:00.900763 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-c7a1-1631-9086-1251e674b4e9) - Created
[0m23:39:02.234785 [debug] [Thread-3 (]: SQL status: OK in 2.690 seconds
[0m23:39:02.241624 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-c7a1-1631-9086-1251e674b4e9, command-id=01f08dcd-c7e4-14d4-93c3-09b588f8f1f8) - Closing
[0m23:39:02.246849 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:39:02.249687 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m23:39:02.257901 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-c7a1-1631-9086-1251e674b4e9) - Closing
[0m23:39:02.881037 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.59s]
[0m23:39:02.886272 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m23:39:02.888297 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m23:39:02.890316 [info ] [Thread-3 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m23:39:02.898144 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m23:39:02.902182 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m23:39:02.906227 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m23:39:03.218240 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m23:39:03.218240 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m23:39:03.236258 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:39:03.245652 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m23:39:03.254443 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m23:39:03.258264 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  
[0m23:39:03.260436 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:39:05.094365 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-ca19-1797-b355-4bfd78b67ca8) - Created
[0m23:39:08.379336 [debug] [Thread-3 (]: SQL status: OK in 5.120 seconds
[0m23:39:08.385948 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-ca19-1797-b355-4bfd78b67ca8, command-id=01f08dcd-ca61-15ff-ab0d-6ee6c8983009) - Closing
[0m23:39:08.391929 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:39:08.395115 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m23:39:08.395115 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-ca19-1797-b355-4bfd78b67ca8) - Closing
[0m23:39:08.796272 [info ] [Thread-3 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 5.89s]
[0m23:39:08.800658 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m23:39:08.801977 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m23:39:08.801977 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m23:39:08.814603 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m23:39:08.816884 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m23:39:08.816884 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m23:39:08.842014 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m23:39:08.854329 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m23:39:08.879237 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:39:08.890766 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m23:39:08.897333 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:39:08.901959 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m23:39:08.902918 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:39:10.512161 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-cd5d-149e-83a3-2cd11d7a23b5) - Created
[0m23:39:13.351578 [debug] [Thread-3 (]: SQL status: OK in 4.450 seconds
[0m23:39:13.354395 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dcd-cd5d-149e-83a3-2cd11d7a23b5, command-id=01f08dcd-cd9b-1ea5-a8bd-3ca3774ba794) - Closing
[0m23:39:13.367432 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:39:13.380362 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m23:39:13.384640 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dcd-cd5d-149e-83a3-2cd11d7a23b5) - Closing
[0m23:39:13.685300 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.88s]
[0m23:39:13.690657 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m23:39:13.699904 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:39:13.702114 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:39:13.704127 [info ] [MainThread]: 
[0m23:39:13.707136 [info ] [MainThread]: Finished running 5 table models, 1 view model in 0 hours 1 minutes and 52.26 seconds (112.26s).
[0m23:39:13.714231 [debug] [MainThread]: Command end result
[0m23:39:13.949127 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:39:13.965249 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:39:14.000551 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m23:39:14.001665 [info ] [MainThread]: 
[0m23:39:14.002685 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:39:14.004706 [info ] [MainThread]: 
[0m23:39:14.004706 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:39:14.018769 [debug] [MainThread]: Command `dbt build` succeeded at 23:39:14.015618 after 123.08 seconds
[0m23:39:14.020988 [debug] [MainThread]: Flushing usage events
[0m23:42:58.595524 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 23:42:58.723236 | 907249ce-f21b-48db-b14d-ef29a87a6614 ==============================
[0m23:42:58.723236 [info ] [MainThread]: Running with dbt=1.10.11
[0m23:42:58.723236 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'quiet': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m23:43:00.460894 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:43:00.460894 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:43:00.467973 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:43:02.215995 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:43:03.054466 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m23:43:03.354000 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:43:03.354000 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:43:03.537225 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:43:03.545218 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:43:03.583565 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:43:03.596195 [info ] [MainThread]: 
[0m23:43:03.596195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:43:03.598717 [info ] [MainThread]: 
[0m23:43:03.598717 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:43:03.598717 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:43:03.625304 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m23:43:03.625304 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m23:43:03.627312 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m23:43:03.627312 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m23:43:03.627312 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:43:04.820118 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dce-591a-157a-a60d-9f3f823d3a73) - Created
[0m23:43:05.251437 [debug] [ThreadPool]: SQL status: OK in 1.620 seconds
[0m23:43:05.254075 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dce-591a-157a-a60d-9f3f823d3a73, command-id=01f08dce-5944-15e4-b3f7-31ce9b8bd31e) - Closing
[0m23:43:05.256184 [debug] [ThreadPool]: On list_dbt-project: Close
[0m23:43:05.257915 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dce-591a-157a-a60d-9f3f823d3a73) - Closing
[0m23:43:05.579873 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m23:43:05.579873 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m23:43:05.603470 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m23:43:05.605783 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m23:43:05.605783 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:43:06.530562 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dce-5a1d-1a47-af43-9f2f019651fd) - Created
[0m23:43:07.478833 [debug] [ThreadPool]: SQL status: OK in 1.870 seconds
[0m23:43:07.488892 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dce-5a1d-1a47-af43-9f2f019651fd, command-id=01f08dce-5a4d-12ae-b95a-83b587ab3571) - Closing
[0m23:43:07.491214 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m23:43:07.491214 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dce-5a1d-1a47-af43-9f2f019651fd) - Closing
[0m23:43:07.888083 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m23:43:07.888083 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:43:07.888083 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m23:43:07.888083 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m23:43:07.888083 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m23:43:07.910924 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m23:43:07.910924 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m23:43:07.957462 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:43:07.960288 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:43:08.061895 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m23:43:08.061895 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:43:08.061895 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m23:43:08.061895 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:09.317576 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-5ba7-10dc-9608-d8d3e5c4ac4d) - Created
[0m23:43:11.871414 [debug] [Thread-3 (]: SQL status: OK in 3.810 seconds
[0m23:43:11.878997 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-5ba7-10dc-9608-d8d3e5c4ac4d, command-id=01f08dce-5bf1-1601-b64c-41d1f6d3919b) - Closing
[0m23:43:11.911419 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:11.948004 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m23:43:11.948004 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-5ba7-10dc-9608-d8d3e5c4ac4d) - Closing
[0m23:43:12.394903 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.50s]
[0m23:43:12.397155 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m23:43:12.398905 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m23:43:12.400914 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:43:12.402254 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m23:43:12.403244 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m23:43:12.404119 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m23:43:12.413287 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m23:43:12.416406 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m23:43:12.457599 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:43:12.476603 [debug] [Thread-3 (]: Dropping relation `dbt-project`.`default`.`bronze_date` because it is of type table
[0m23:43:12.495983 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_date`
[0m23:43:12.511214 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m23:43:12.512198 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */
drop table if exists `dbt-project`.`default`.`bronze_date`
[0m23:43:12.512704 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:13.611721 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-5e50-11c9-a15c-6b1ad4d26a53) - Created
[0m23:43:14.144471 [debug] [Thread-3 (]: SQL status: OK in 1.630 seconds
[0m23:43:14.146476 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-5e50-11c9-a15c-6b1ad4d26a53, command-id=01f08dce-5e7e-1cc1-872f-355ff04569a6) - Closing
[0m23:43:14.155385 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m23:43:14.155385 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m23:43:14.155385 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m23:43:14.155385 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m23:43:15.058449 [debug] [Thread-3 (]: SQL status: OK in 0.890 seconds
[0m23:43:15.060456 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-5e50-11c9-a15c-6b1ad4d26a53, command-id=01f08dce-5ed3-1124-9ead-a0e59ea1f447) - Closing
[0m23:43:15.060456 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:15.060456 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m23:43:15.060456 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-5e50-11c9-a15c-6b1ad4d26a53) - Closing
[0m23:43:15.507667 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 3.11s]
[0m23:43:15.507667 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m23:43:15.507667 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m23:43:15.507667 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m23:43:15.514822 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m23:43:15.514822 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m23:43:15.514822 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m23:43:15.521917 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m23:43:15.521917 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m23:43:15.521917 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:43:15.530783 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m23:43:15.532793 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:43:15.532793 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m23:43:15.535523 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:16.889964 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-6047-128d-b75e-85dc8bf645c1) - Created
[0m23:43:18.961270 [debug] [Thread-3 (]: SQL status: OK in 3.430 seconds
[0m23:43:18.963351 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-6047-128d-b75e-85dc8bf645c1, command-id=01f08dce-6074-12db-9c42-1056d31e9ad4) - Closing
[0m23:43:18.966557 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:18.969868 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m23:43:18.973709 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-6047-128d-b75e-85dc8bf645c1) - Closing
[0m23:43:19.307562 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.80s]
[0m23:43:19.309470 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m23:43:19.310519 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m23:43:19.311101 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m23:43:19.311934 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m23:43:19.312963 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m23:43:19.312963 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m23:43:19.324196 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m23:43:19.325764 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m23:43:19.334670 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:43:19.493058 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m23:43:19.495063 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m23:43:19.496332 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m23:43:19.496332 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m23:43:19.496332 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:20.723872 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-6289-15c5-825c-644026c99413) - Created
[0m23:43:21.774588 [debug] [Thread-3 (]: SQL status: OK in 2.280 seconds
[0m23:43:21.775774 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-6289-15c5-825c-644026c99413, command-id=01f08dce-62bd-19cf-a9b8-9b5213db8539) - Closing
[0m23:43:21.775774 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:21.778383 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m23:43:21.778383 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-6289-15c5-825c-644026c99413) - Closing
[0m23:43:22.217714 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.91s]
[0m23:43:22.220586 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m23:43:22.223628 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m23:43:22.223628 [info ] [Thread-3 (]: 5 of 6 START sql table model default.bronze_sales .............................. [RUN]
[0m23:43:22.226662 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m23:43:22.227408 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m23:43:22.228207 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m23:43:22.243750 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m23:43:22.245963 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m23:43:22.249286 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:43:22.252595 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m23:43:22.256940 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m23:43:22.258398 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_sales`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  
[0m23:43:22.259702 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:23.548839 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-643d-1da9-a9aa-fc7440fac0f9) - Created
[0m23:43:25.691119 [debug] [Thread-3 (]: SQL status: OK in 3.430 seconds
[0m23:43:25.691119 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-643d-1da9-a9aa-fc7440fac0f9, command-id=01f08dce-646b-1628-a07a-9e508e172f8d) - Closing
[0m23:43:25.691119 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:25.691119 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m23:43:25.691119 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-643d-1da9-a9aa-fc7440fac0f9) - Closing
[0m23:43:26.040115 [info ] [Thread-3 (]: 5 of 6 OK created sql table model default.bronze_sales ......................... [[32mOK[0m in 3.81s]
[0m23:43:26.044442 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m23:43:26.044948 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m23:43:26.046038 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m23:43:26.050075 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m23:43:26.051585 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m23:43:26.051585 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m23:43:26.060869 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m23:43:26.060869 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m23:43:26.060869 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:43:26.078370 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m23:43:26.079729 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:43:26.079729 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m23:43:26.079729 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:43:27.953844 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-66ce-1229-abf5-9c04e7e1d042) - Created
[0m23:43:30.062641 [debug] [Thread-3 (]: SQL status: OK in 3.980 seconds
[0m23:43:30.064646 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dce-66ce-1229-abf5-9c04e7e1d042, command-id=01f08dce-6710-1105-85cb-dc296035a0fd) - Closing
[0m23:43:30.064646 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:43:30.066651 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m23:43:30.068657 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dce-66ce-1229-abf5-9c04e7e1d042) - Closing
[0m23:43:30.407708 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.36s]
[0m23:43:30.420766 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m23:43:30.424989 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:43:30.424989 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:43:30.424989 [info ] [MainThread]: 
[0m23:43:30.424989 [info ] [MainThread]: Finished running 4 table models, 2 view models in 0 hours 0 minutes and 26.83 seconds (26.83s).
[0m23:43:30.424989 [debug] [MainThread]: Command end result
[0m23:43:30.512894 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:43:30.517793 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:43:30.525999 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m23:43:30.525999 [info ] [MainThread]: 
[0m23:43:30.525999 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:43:30.525999 [info ] [MainThread]: 
[0m23:43:30.525999 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:43:30.534417 [debug] [MainThread]: Command `dbt build` succeeded at 23:43:30.534417 after 32.03 seconds
[0m23:43:30.534417 [debug] [MainThread]: Flushing usage events
[0m23:54:06.402962 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 23:54:06.531300 | 80f86d47-f92f-4a8a-bdd7-3039d8f8cb2f ==============================
[0m23:54:06.531300 [info ] [MainThread]: Running with dbt=1.10.11
[0m23:54:06.537215 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m23:54:08.292075 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:54:08.292075 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:54:08.292075 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:54:09.916568 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:54:10.600954 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m23:54:10.907112 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m23:54:10.907112 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://models\bronze\bronze_sales.sql
[0m23:54:11.351965 [error] [MainThread]: Encountered an error:
Compilation Error in model bronze_sales (models\bronze\bronze_sales.sql)
  unexpected '}'
    line 1
      {{config(materialized='view')}
[0m23:54:11.354232 [debug] [MainThread]: Command `dbt run` failed at 23:54:11.354232 after 5.06 seconds
[0m23:54:11.354232 [debug] [MainThread]: Flushing usage events
[0m23:54:49.653649 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 23:54:49.753526 | b506a875-1f22-4308-88ae-97f33140bd08 ==============================
[0m23:54:49.753526 [info ] [MainThread]: Running with dbt=1.10.11
[0m23:54:49.753526 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m23:54:51.750816 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:54:51.760863 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:54:51.760863 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:54:53.451520 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:54:54.167672 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m23:54:54.469708 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:54:54.469708 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:54:54.700687 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:54:54.707388 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:54:54.727704 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:54:54.728568 [info ] [MainThread]: 
[0m23:54:54.728568 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:54:54.728568 [info ] [MainThread]: 
[0m23:54:54.735425 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:54:54.738618 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:54:54.754086 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m23:54:54.754086 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m23:54:54.754086 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m23:54:54.760290 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m23:54:54.760290 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:54:56.438284 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-0128-1ddf-99c7-bc3e77e2af4e) - Created
[0m23:54:57.168942 [debug] [ThreadPool]: SQL status: OK in 2.410 seconds
[0m23:54:57.168942 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dd0-0128-1ddf-99c7-bc3e77e2af4e, command-id=01f08dd0-016e-1eb2-a4c3-82e7da3a7050) - Closing
[0m23:54:57.168942 [debug] [ThreadPool]: On list_dbt-project: Close
[0m23:54:57.168942 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-0128-1ddf-99c7-bc3e77e2af4e) - Closing
[0m23:54:57.440531 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m23:54:57.441057 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m23:54:57.472229 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m23:54:57.473651 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m23:54:57.474157 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:54:58.507958 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-0282-1dfc-9e3e-435c9f107104) - Created
[0m23:54:59.043652 [debug] [ThreadPool]: SQL status: OK in 1.570 seconds
[0m23:54:59.055961 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dd0-0282-1dfc-9e3e-435c9f107104, command-id=01f08dd0-02a5-1e34-9a93-eea7f972f6a0) - Closing
[0m23:54:59.055961 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m23:54:59.055961 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-0282-1dfc-9e3e-435c9f107104) - Closing
[0m23:54:59.533561 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m23:54:59.533561 [info ] [Thread-3 (]: 1 of 6 START sql view model default.bronze_customer ............................ [RUN]
[0m23:54:59.533561 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m23:54:59.533561 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m23:54:59.533561 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m23:54:59.555535 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m23:54:59.555535 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m23:54:59.590772 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:54:59.590772 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:54:59.617145 [debug] [Thread-3 (]: Dropping relation `dbt-project`.`default`.`bronze_customer` because it is of type table
[0m23:54:59.642409 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_customer`
[0m23:54:59.651007 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:54:59.654062 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */
drop table if exists `dbt-project`.`default`.`bronze_customer`
[0m23:54:59.655171 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:00.912822 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-03b1-19b5-9121-93eaca884bb9) - Created
[0m23:55:01.926157 [debug] [Thread-3 (]: SQL status: OK in 2.270 seconds
[0m23:55:01.935934 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-03b1-19b5-9121-93eaca884bb9, command-id=01f08dd0-0414-1232-9c60-cfe5dab0b490) - Closing
[0m23:55:01.953506 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_customer`
[0m23:55:01.969472 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m23:55:01.969472 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:55:01.969472 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m23:55:02.657517 [debug] [Thread-3 (]: SQL status: OK in 0.690 seconds
[0m23:55:02.657517 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-03b1-19b5-9121-93eaca884bb9, command-id=01f08dd0-04b8-1ff9-95e5-83ba189c3485) - Closing
[0m23:55:02.678508 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:02.687030 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m23:55:02.687030 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-03b1-19b5-9121-93eaca884bb9) - Closing
[0m23:55:03.173701 [info ] [Thread-3 (]: 1 of 6 OK created sql view model default.bronze_customer ....................... [[32mOK[0m in 3.64s]
[0m23:55:03.173701 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m23:55:03.173701 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m23:55:03.173701 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:55:03.173701 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m23:55:03.173701 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m23:55:03.173701 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m23:55:03.185177 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m23:55:03.186572 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m23:55:03.193306 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:55:03.194854 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m23:55:03.198558 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m23:55:03.200316 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m23:55:03.202351 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m23:55:03.206020 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:04.534249 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0609-10e8-b5b6-58a46bbde781) - Created
[0m23:55:05.518381 [debug] [Thread-3 (]: SQL status: OK in 2.310 seconds
[0m23:55:05.520774 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0609-10e8-b5b6-58a46bbde781, command-id=01f08dd0-063e-1bcb-802b-9b78119e67bb) - Closing
[0m23:55:05.520774 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:05.520774 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m23:55:05.520774 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0609-10e8-b5b6-58a46bbde781) - Closing
[0m23:55:05.772126 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.60s]
[0m23:55:05.772126 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m23:55:05.772126 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m23:55:05.777664 [info ] [Thread-3 (]: 3 of 6 START sql view model default.bronze_dim_product ......................... [RUN]
[0m23:55:05.777664 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m23:55:05.779813 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m23:55:05.779813 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m23:55:05.796113 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m23:55:05.798117 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m23:55:05.808609 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:55:05.808609 [debug] [Thread-3 (]: Dropping relation `dbt-project`.`default`.`bronze_dim_product` because it is of type table
[0m23:55:05.808609 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_dim_product`
[0m23:55:05.820991 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:55:05.820991 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */
drop table if exists `dbt-project`.`default`.`bronze_dim_product`
[0m23:55:05.823325 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:07.205148 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0794-1ddf-8de9-ff1b76c1238d) - Created
[0m23:55:07.965843 [debug] [Thread-3 (]: SQL status: OK in 2.140 seconds
[0m23:55:07.970430 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0794-1ddf-8de9-ff1b76c1238d, command-id=01f08dd0-07d4-178f-8fdb-71df848f3f2a) - Closing
[0m23:55:07.970430 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_dim_product`
[0m23:55:07.970430 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m23:55:07.970430 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:55:07.970430 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_dim_product`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  )

[0m23:55:09.050274 [debug] [Thread-3 (]: SQL status: OK in 1.080 seconds
[0m23:55:09.054565 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0794-1ddf-8de9-ff1b76c1238d, command-id=01f08dd0-084a-1688-b460-5bfc2d8b8845) - Closing
[0m23:55:09.054565 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:09.054565 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m23:55:09.054565 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0794-1ddf-8de9-ff1b76c1238d) - Closing
[0m23:55:09.401777 [info ] [Thread-3 (]: 3 of 6 OK created sql view model default.bronze_dim_product .................... [[32mOK[0m in 3.62s]
[0m23:55:09.409086 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m23:55:09.409086 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m23:55:09.411609 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m23:55:09.412231 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m23:55:09.412231 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m23:55:09.412231 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m23:55:09.419213 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m23:55:09.419213 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m23:55:09.429910 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:55:09.432007 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m23:55:09.435800 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m23:55:09.438398 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m23:55:09.438398 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m23:55:09.441489 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:10.981482 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-09ca-1d3f-a942-0a4d8d8b8eef) - Created
[0m23:55:12.142678 [debug] [Thread-3 (]: SQL status: OK in 2.700 seconds
[0m23:55:12.144685 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-09ca-1d3f-a942-0a4d8d8b8eef, command-id=01f08dd0-0a16-188d-87ac-b4cedc903d1b) - Closing
[0m23:55:12.146692 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:12.148698 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m23:55:12.148698 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-09ca-1d3f-a942-0a4d8d8b8eef) - Closing
[0m23:55:12.480485 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.07s]
[0m23:55:12.487201 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m23:55:12.489216 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m23:55:12.489216 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m23:55:12.489216 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m23:55:12.489216 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m23:55:12.492771 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m23:55:12.502763 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m23:55:12.504784 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m23:55:12.512220 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:55:12.514225 [debug] [Thread-3 (]: Dropping relation `dbt-project`.`default`.`bronze_sales` because it is of type table
[0m23:55:12.525064 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_sales`
[0m23:55:12.525064 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m23:55:12.525064 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */
drop table if exists `dbt-project`.`default`.`bronze_sales`
[0m23:55:12.525064 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:13.584949 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0b79-14e7-b81e-d237c0024656) - Created
[0m23:55:14.237008 [debug] [Thread-3 (]: SQL status: OK in 1.710 seconds
[0m23:55:14.239022 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0b79-14e7-b81e-d237c0024656, command-id=01f08dd0-0ba1-1ced-98de-435ac2a0ecec) - Closing
[0m23:55:14.240771 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m23:55:14.240771 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m23:55:14.240771 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m23:55:14.248831 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m23:55:15.142518 [debug] [Thread-3 (]: SQL status: OK in 0.890 seconds
[0m23:55:15.147600 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0b79-14e7-b81e-d237c0024656, command-id=01f08dd0-0c06-148e-8825-75bd2bfc6f51) - Closing
[0m23:55:15.149146 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:15.152813 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m23:55:15.152813 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0b79-14e7-b81e-d237c0024656) - Closing
[0m23:55:15.511724 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.02s]
[0m23:55:15.518226 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m23:55:15.518226 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m23:55:15.518226 [info ] [Thread-3 (]: 6 of 6 START sql view model default.bronze_store ............................... [RUN]
[0m23:55:15.518226 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m23:55:15.524687 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m23:55:15.524687 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m23:55:15.531292 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m23:55:15.534058 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m23:55:15.537971 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:55:15.542827 [debug] [Thread-3 (]: Dropping relation `dbt-project`.`default`.`bronze_store` because it is of type table
[0m23:55:15.554157 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_store`
[0m23:55:15.557194 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:55:15.557194 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */
drop table if exists `dbt-project`.`default`.`bronze_store`
[0m23:55:15.557194 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:55:18.389472 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0d62-1f25-94e8-7381edde6905) - Created
[0m23:55:18.985520 [debug] [Thread-3 (]: SQL status: OK in 3.430 seconds
[0m23:55:18.985520 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0d62-1f25-94e8-7381edde6905, command-id=01f08dd0-0e82-1f7a-9fa4-18c687bdaf2b) - Closing
[0m23:55:18.985520 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_store`
[0m23:55:18.985520 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m23:55:18.985520 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:55:18.985520 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_store`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  )

[0m23:55:19.705210 [debug] [Thread-3 (]: SQL status: OK in 0.720 seconds
[0m23:55:19.705210 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-0d62-1f25-94e8-7381edde6905, command-id=01f08dd0-0edb-1244-96ef-48c8f378bb57) - Closing
[0m23:55:19.705210 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:55:19.713584 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m23:55:19.713584 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-0d62-1f25-94e8-7381edde6905) - Closing
[0m23:55:19.968719 [info ] [Thread-3 (]: 6 of 6 OK created sql view model default.bronze_store .......................... [[32mOK[0m in 4.45s]
[0m23:55:19.972533 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m23:55:19.976006 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:55:19.977071 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:55:19.978365 [info ] [MainThread]: 
[0m23:55:19.979877 [info ] [MainThread]: Finished running 6 view models in 0 hours 0 minutes and 25.24 seconds (25.24s).
[0m23:55:19.982224 [debug] [MainThread]: Command end result
[0m23:55:20.226677 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:55:20.236057 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:55:20.255442 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m23:55:20.257468 [info ] [MainThread]: 
[0m23:55:20.349023 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:55:20.408379 [info ] [MainThread]: 
[0m23:55:20.414602 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:55:20.415610 [debug] [MainThread]: Command `dbt run` succeeded at 23:55:20.415610 after 30.85 seconds
[0m23:55:20.417671 [debug] [MainThread]: Flushing usage events
[0m23:56:01.500962 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 23:56:01.638163 | 7735f8c7-8624-46a0-819b-936f5df6c8b0 ==============================
[0m23:56:01.638163 [info ] [MainThread]: Running with dbt=1.10.11
[0m23:56:01.638163 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m23:56:03.448734 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m23:56:03.448734 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m23:56:03.448734 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m23:56:05.095214 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m23:56:05.967853 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m23:56:06.248193 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:56:06.248193 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:56:06.477335 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:56:06.489504 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:56:06.507125 [info ] [MainThread]: Found 6 models, 6 sources, 685 macros
[0m23:56:06.511192 [info ] [MainThread]: 
[0m23:56:06.511192 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m23:56:06.516712 [info ] [MainThread]: 
[0m23:56:06.522045 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:56:06.522045 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:56:06.543768 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m23:56:06.543768 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m23:56:06.543768 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m23:56:06.543768 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m23:56:06.548653 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:56:07.537172 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-2ba3-1c24-a47d-4fd0b27227c5) - Created
[0m23:56:08.083479 [debug] [ThreadPool]: SQL status: OK in 1.530 seconds
[0m23:56:08.095805 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dd0-2ba3-1c24-a47d-4fd0b27227c5, command-id=01f08dd0-2bca-1a13-9f14-7355615acbe3) - Closing
[0m23:56:08.096585 [debug] [ThreadPool]: On list_dbt-project: Close
[0m23:56:08.096585 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-2ba3-1c24-a47d-4fd0b27227c5) - Closing
[0m23:56:08.494787 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m23:56:08.496788 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m23:56:08.516775 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m23:56:08.516775 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m23:56:08.516775 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:56:09.333383 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-2cbb-1a1c-9fa7-e00f8674c3b3) - Created
[0m23:56:09.966095 [debug] [ThreadPool]: SQL status: OK in 1.450 seconds
[0m23:56:09.966095 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08dd0-2cbb-1a1c-9fa7-e00f8674c3b3, command-id=01f08dd0-2cdb-1ed3-9ea0-75ad08070745) - Closing
[0m23:56:09.966095 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m23:56:09.966095 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08dd0-2cbb-1a1c-9fa7-e00f8674c3b3) - Closing
[0m23:56:10.231320 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m23:56:10.234223 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m23:56:10.234223 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m23:56:10.234223 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m23:56:10.234223 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m23:56:10.247213 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m23:56:10.249770 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m23:56:10.285950 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:56:10.285950 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m23:56:10.306083 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_customer`
[0m23:56:10.312975 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:56:10.315189 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_customer`
[0m23:56:10.315189 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:11.473370 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-2dea-1da7-8216-6ebb49de115f) - Created
[0m23:56:12.331909 [debug] [Thread-3 (]: SQL status: OK in 2.020 seconds
[0m23:56:12.334019 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-2dea-1da7-8216-6ebb49de115f, command-id=01f08dd0-2e24-15d9-9f43-14ae0300735b) - Closing
[0m23:56:12.423715 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m23:56:12.423715 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m23:56:12.423715 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m23:56:15.467890 [debug] [Thread-3 (]: SQL status: OK in 3.040 seconds
[0m23:56:15.467890 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-2dea-1da7-8216-6ebb49de115f, command-id=01f08dd0-2eb4-1b63-bc1e-deeec015d391) - Closing
[0m23:56:15.499256 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:15.520145 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m23:56:15.520145 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-2dea-1da7-8216-6ebb49de115f) - Closing
[0m23:56:15.971841 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 5.73s]
[0m23:56:15.973848 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m23:56:15.973848 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m23:56:15.973848 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m23:56:15.978331 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m23:56:15.978331 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m23:56:15.980337 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m23:56:15.983437 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m23:56:15.983437 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m23:56:16.024627 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:56:16.048766 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m23:56:16.051540 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m23:56:16.056428 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m23:56:16.056428 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m23:56:16.056428 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:17.157705 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-315e-1c5a-996d-5612a4b2b69f) - Created
[0m23:56:18.119110 [debug] [Thread-3 (]: SQL status: OK in 2.060 seconds
[0m23:56:18.124196 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-315e-1c5a-996d-5612a4b2b69f, command-id=01f08dd0-3187-105e-b16d-1336023eebf5) - Closing
[0m23:56:18.125349 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:18.125349 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m23:56:18.129466 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-315e-1c5a-996d-5612a4b2b69f) - Closing
[0m23:56:18.728769 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.75s]
[0m23:56:18.728769 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m23:56:18.744430 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m23:56:18.744430 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m23:56:18.746441 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m23:56:18.746441 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m23:56:18.746441 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m23:56:18.755933 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m23:56:18.760549 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m23:56:18.763784 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:56:18.770444 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_dim_product`
[0m23:56:18.774596 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:56:18.776604 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_dim_product`
[0m23:56:18.776604 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:20.009246 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-330a-1f04-a163-88783715bc48) - Created
[0m23:56:20.811529 [debug] [Thread-3 (]: SQL status: OK in 2.030 seconds
[0m23:56:20.813535 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-330a-1f04-a163-88783715bc48, command-id=01f08dd0-3339-1db4-a8cc-265c7d21c35c) - Closing
[0m23:56:20.815506 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m23:56:20.815506 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m23:56:20.815506 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m23:56:23.820748 [debug] [Thread-3 (]: SQL status: OK in 3.010 seconds
[0m23:56:23.824523 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-330a-1f04-a163-88783715bc48, command-id=01f08dd0-33b5-1630-a7f2-4eb823267b67) - Closing
[0m23:56:23.825312 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:23.825312 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m23:56:23.825312 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-330a-1f04-a163-88783715bc48) - Closing
[0m23:56:24.367719 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 5.62s]
[0m23:56:24.378304 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m23:56:24.378304 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m23:56:24.378304 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m23:56:24.382956 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m23:56:24.382956 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m23:56:24.382956 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m23:56:24.394026 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m23:56:24.395737 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m23:56:24.402199 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:56:24.405102 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m23:56:24.407237 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m23:56:24.410248 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m23:56:24.410248 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m23:56:24.410248 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:25.800005 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-365e-1a5f-950f-286acfe3fe35) - Created
[0m23:56:26.649611 [debug] [Thread-3 (]: SQL status: OK in 2.240 seconds
[0m23:56:26.649611 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-365e-1a5f-950f-286acfe3fe35, command-id=01f08dd0-36af-130a-a345-7773c1708c53) - Closing
[0m23:56:26.649611 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:26.661682 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m23:56:26.661682 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-365e-1a5f-950f-286acfe3fe35) - Closing
[0m23:56:26.942075 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.55s]
[0m23:56:26.942075 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m23:56:26.942075 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m23:56:26.942075 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m23:56:26.942075 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m23:56:26.942075 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m23:56:26.947191 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m23:56:26.955270 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m23:56:26.957575 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m23:56:26.970554 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m23:56:26.974207 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m23:56:26.975713 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m23:56:26.975713 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m23:56:26.975713 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m23:56:26.980198 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:28.299689 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-37fc-1b2e-abe0-12229fae67ba) - Created
[0m23:56:29.226407 [debug] [Thread-3 (]: SQL status: OK in 2.250 seconds
[0m23:56:29.226407 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-37fc-1b2e-abe0-12229fae67ba, command-id=01f08dd0-382c-14fc-8b14-999cfc66fcfa) - Closing
[0m23:56:29.226407 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:29.226407 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m23:56:29.231591 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-37fc-1b2e-abe0-12229fae67ba) - Closing
[0m23:56:29.720472 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.78s]
[0m23:56:29.723071 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m23:56:29.723071 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m23:56:29.725413 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m23:56:29.726821 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m23:56:29.727337 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m23:56:29.728361 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m23:56:29.736936 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m23:56:29.738520 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m23:56:29.741876 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m23:56:29.753473 [debug] [Thread-3 (]: Applying DROP to: `dbt-project`.`default`.`bronze_store`
[0m23:56:29.756274 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:56:29.756274 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */
DROP VIEW IF EXISTS `dbt-project`.`default`.`bronze_store`
[0m23:56:29.756274 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:56:30.798327 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-3979-1f6d-935a-78f4e4249b27) - Created
[0m23:56:31.458712 [debug] [Thread-3 (]: SQL status: OK in 1.700 seconds
[0m23:56:31.458712 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-3979-1f6d-935a-78f4e4249b27, command-id=01f08dd0-39a8-1521-ae31-b48c3b3c6962) - Closing
[0m23:56:31.462725 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m23:56:31.462725 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m23:56:31.464907 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m23:56:34.222491 [debug] [Thread-3 (]: SQL status: OK in 2.760 seconds
[0m23:56:34.222491 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08dd0-3979-1f6d-935a-78f4e4249b27, command-id=01f08dd0-3a0c-1e77-bbfd-d07cfadc4181) - Closing
[0m23:56:34.222491 [debug] [Thread-3 (]: Applying tags to relation None
[0m23:56:34.234834 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m23:56:34.234834 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08dd0-3979-1f6d-935a-78f4e4249b27) - Closing
[0m23:56:34.482723 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.76s]
[0m23:56:34.482723 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m23:56:34.482723 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m23:56:34.482723 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m23:56:34.489388 [info ] [MainThread]: 
[0m23:56:34.489388 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 27.97 seconds (27.97s).
[0m23:56:34.492488 [debug] [MainThread]: Command end result
[0m23:56:34.677172 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m23:56:34.681328 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m23:56:34.694425 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m23:56:34.694425 [info ] [MainThread]: 
[0m23:56:34.694425 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:56:34.694425 [info ] [MainThread]: 
[0m23:56:34.701063 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m23:56:34.703214 [debug] [MainThread]: Command `dbt run` succeeded at 23:56:34.703214 after 33.33 seconds
[0m23:56:34.703954 [debug] [MainThread]: Flushing usage events
[0m09:42:56.743992 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 09:42:56.901398 | ba2f61fb-ff27-4b43-a785-cc2583f141a0 ==============================
[0m09:42:56.901398 [info ] [MainThread]: Running with dbt=1.10.11
[0m09:42:56.901398 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m09:42:57.623753 [debug] [MainThread]: Command `dbt clean` succeeded at 09:42:57.623753 after 0.98 seconds
[0m09:42:57.623753 [debug] [MainThread]: Flushing usage events
[0m10:06:45.790336 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 10:06:45.909439 | 61dc1471-e89f-49a5-a720-82f9103004c1 ==============================
[0m10:06:45.909439 [info ] [MainThread]: Running with dbt=1.10.11
[0m10:06:45.909439 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m10:06:55.245680 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:06:55.245680 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:06:55.245680 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:07:04.729128 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:07:05.444335 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m10:07:05.694214 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:07:05.694214 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:07:05.871161 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m10:07:05.911012 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m10:07:05.962428 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m10:07:05.962428 [info ] [MainThread]: 
[0m10:07:05.962428 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:07:05.962428 [info ] [MainThread]: 
[0m10:07:05.962428 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:07:05.962428 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:07:05.992912 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m10:07:05.992912 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m10:07:05.993926 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m10:07:05.997928 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m10:07:05.999928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:07:06.944537 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-8613-1cb0-97de-955b9d72cf75) - Created
[0m10:07:07.596023 [debug] [ThreadPool]: SQL status: OK in 1.600 seconds
[0m10:07:07.602535 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e25-8613-1cb0-97de-955b9d72cf75, command-id=01f08e25-8636-155b-9b09-b835d870d1da) - Closing
[0m10:07:07.602535 [debug] [ThreadPool]: On list_dbt-project: Close
[0m10:07:07.602535 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-8613-1cb0-97de-955b9d72cf75) - Closing
[0m10:07:07.871745 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m10:07:07.871745 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m10:07:07.910176 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m10:07:07.910983 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m10:07:07.917071 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:07:08.804391 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-8730-1c2e-9e61-7b91ba7028e3) - Created
[0m10:07:11.025910 [debug] [ThreadPool]: SQL status: OK in 3.110 seconds
[0m10:07:11.076985 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e25-8730-1c2e-9e61-7b91ba7028e3, command-id=01f08e25-8752-11fb-871a-59cc3b561dcc) - Closing
[0m10:07:11.076985 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m10:07:11.076985 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-8730-1c2e-9e61-7b91ba7028e3) - Closing
[0m10:07:11.329131 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m10:07:11.329131 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m10:07:11.329131 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m10:07:11.329131 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m10:07:11.329131 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m10:07:11.351073 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m10:07:11.352311 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m10:07:11.382845 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:07:11.383861 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:07:11.452181 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m10:07:11.456173 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m10:07:11.457174 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m10:07:11.457174 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:12.309641 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-8942-1f7e-a5f5-8a241747b133) - Created
[0m10:07:19.865640 [debug] [Thread-3 (]: SQL status: OK in 8.400 seconds
[0m10:07:19.865640 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-8942-1f7e-a5f5-8a241747b133, command-id=01f08e25-8968-1120-8133-48096a62cf6a) - Closing
[0m10:07:20.327168 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:20.359945 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m10:07:20.359945 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-8942-1f7e-a5f5-8a241747b133) - Closing
[0m10:07:20.610574 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 9.26s]
[0m10:07:20.610574 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m10:07:20.610574 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m10:07:20.610574 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m10:07:20.610574 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m10:07:20.610574 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m10:07:20.626408 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m10:07:20.631131 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m10:07:20.631131 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m10:07:20.648350 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:07:20.671552 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m10:07:20.671552 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m10:07:20.681231 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m10:07:20.682233 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m10:07:20.682233 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:21.694724 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-8edd-1017-8c19-1264a5017cfc) - Created
[0m10:07:22.827380 [debug] [Thread-3 (]: SQL status: OK in 2.150 seconds
[0m10:07:22.827380 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-8edd-1017-8c19-1264a5017cfc, command-id=01f08e25-8eff-1394-8698-7ce8aed09022) - Closing
[0m10:07:22.827380 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:22.827380 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m10:07:22.827380 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-8edd-1017-8c19-1264a5017cfc) - Closing
[0m10:07:23.043817 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.43s]
[0m10:07:23.059525 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m10:07:23.059525 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m10:07:23.059525 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m10:07:23.059525 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m10:07:23.064911 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m10:07:23.064911 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m10:07:23.069021 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m10:07:23.069021 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m10:07:23.076046 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:07:23.080878 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m10:07:23.084238 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m10:07:23.085237 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m10:07:23.085237 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:23.958537 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-9035-1bc9-91fd-3768ec68049c) - Created
[0m10:07:29.260619 [debug] [Thread-3 (]: SQL status: OK in 6.180 seconds
[0m10:07:29.260619 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-9035-1bc9-91fd-3768ec68049c, command-id=01f08e25-905d-1929-8045-0fc182448852) - Closing
[0m10:07:29.260619 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:29.260619 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m10:07:29.260619 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-9035-1bc9-91fd-3768ec68049c) - Closing
[0m10:07:29.495314 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 6.44s]
[0m10:07:29.495314 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m10:07:29.495314 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m10:07:29.495314 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m10:07:29.511589 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m10:07:29.513714 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m10:07:29.513714 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m10:07:29.518669 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m10:07:29.518669 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m10:07:29.518669 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:07:29.518669 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m10:07:29.518669 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m10:07:29.518669 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m10:07:29.527536 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m10:07:29.528941 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:30.305099 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-9401-1f8d-b355-f9e260af1a60) - Created
[0m10:07:31.097658 [debug] [Thread-3 (]: SQL status: OK in 1.570 seconds
[0m10:07:31.097658 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-9401-1f8d-b355-f9e260af1a60, command-id=01f08e25-9420-188e-aa1e-9a502f00810a) - Closing
[0m10:07:31.097658 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:31.097658 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m10:07:31.097658 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-9401-1f8d-b355-f9e260af1a60) - Closing
[0m10:07:31.314102 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.82s]
[0m10:07:31.323078 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m10:07:31.323078 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m10:07:31.323078 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m10:07:31.323078 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m10:07:31.323078 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m10:07:31.323078 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m10:07:31.333701 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m10:07:31.336777 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m10:07:31.336777 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:07:31.336777 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m10:07:31.336777 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m10:07:31.336777 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m10:07:31.336777 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m10:07:31.336777 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:32.195672 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-951e-1c2c-a7c7-1414a88f11a3) - Created
[0m10:07:33.019493 [debug] [Thread-3 (]: SQL status: OK in 1.680 seconds
[0m10:07:33.019493 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-951e-1c2c-a7c7-1414a88f11a3, command-id=01f08e25-9543-113a-b2ed-99a8aeec5425) - Closing
[0m10:07:33.021502 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:33.021502 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m10:07:33.021502 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-951e-1c2c-a7c7-1414a88f11a3) - Closing
[0m10:07:33.276917 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.95s]
[0m10:07:33.276917 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m10:07:33.276917 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m10:07:33.276917 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m10:07:33.276917 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m10:07:33.276917 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m10:07:33.276917 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m10:07:33.276917 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m10:07:33.276917 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m10:07:33.298125 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:07:33.303828 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m10:07:33.304833 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m10:07:33.305830 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m10:07:33.306833 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:07:34.158447 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-964c-129b-ba7d-e3843bfbfdd6) - Created
[0m10:07:37.207843 [debug] [Thread-3 (]: SQL status: OK in 3.900 seconds
[0m10:07:37.210253 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-964c-129b-ba7d-e3843bfbfdd6, command-id=01f08e25-9674-139c-b0e2-d94966e33f3f) - Closing
[0m10:07:37.214272 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:07:37.214272 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m10:07:37.214272 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-964c-129b-ba7d-e3843bfbfdd6) - Closing
[0m10:07:37.443522 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.17s]
[0m10:07:37.443522 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m10:07:37.443522 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:07:37.443522 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:07:37.443522 [info ] [MainThread]: 
[0m10:07:37.443522 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 31.48 seconds (31.48s).
[0m10:07:37.443522 [debug] [MainThread]: Command end result
[0m10:07:37.709110 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m10:07:37.715940 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m10:07:37.723977 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m10:07:37.727197 [info ] [MainThread]: 
[0m10:07:37.729229 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:07:37.733151 [info ] [MainThread]: 
[0m10:07:37.733151 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m10:07:37.733151 [debug] [MainThread]: Command `dbt run` succeeded at 10:07:37.733151 after 52.11 seconds
[0m10:07:37.736704 [debug] [MainThread]: Flushing usage events
[0m10:08:39.275180 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 10:08:39.366784 | db8591b9-a996-494c-a141-758669713dbf ==============================
[0m10:08:39.366784 [info ] [MainThread]: Running with dbt=1.10.11
[0m10:08:39.366784 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_etl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m10:08:40.808145 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:08:40.808145 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:08:40.808145 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:08:42.091700 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:08:42.735537 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m10:08:42.974602 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:08:42.974602 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:08:43.125384 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m10:08:43.125384 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m10:08:43.151680 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m10:08:43.154676 [info ] [MainThread]: 
[0m10:08:43.155676 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:08:43.155676 [info ] [MainThread]: 
[0m10:08:43.156677 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:08:43.158651 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:08:43.166374 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m10:08:43.166374 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m10:08:43.166374 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m10:08:43.166374 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m10:08:43.166374 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:44.059070 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-bff6-1aa5-b51f-49b1c0eb7c9a) - Created
[0m10:08:44.491680 [debug] [ThreadPool]: SQL status: OK in 1.330 seconds
[0m10:08:44.491680 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e25-bff6-1aa5-b51f-49b1c0eb7c9a, command-id=01f08e25-c019-160e-82db-678383374c3e) - Closing
[0m10:08:44.491680 [debug] [ThreadPool]: On list_dbt-project: Close
[0m10:08:44.491680 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-bff6-1aa5-b51f-49b1c0eb7c9a) - Closing
[0m10:08:44.742724 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m10:08:44.742724 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m10:08:44.781886 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m10:08:44.782879 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m10:08:44.783878 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:08:45.607862 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-c0e3-1c1b-81f3-896d9223a50c) - Created
[0m10:08:46.173513 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m10:08:46.189349 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e25-c0e3-1c1b-81f3-896d9223a50c, command-id=01f08e25-c106-14a2-96ab-46ae469b9622) - Closing
[0m10:08:46.189349 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m10:08:46.189349 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e25-c0e3-1c1b-81f3-896d9223a50c) - Closing
[0m10:08:46.426587 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m10:08:46.426587 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m10:08:46.426587 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m10:08:46.426587 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m10:08:46.426587 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m10:08:46.449701 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m10:08:46.449701 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m10:08:46.476833 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:08:46.477771 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:08:46.551882 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m10:08:46.552881 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m10:08:46.553868 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m10:08:46.553868 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:47.374858 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c1f0-1c70-9e0e-f1d2e47aedd8) - Created
[0m10:08:49.581664 [debug] [Thread-3 (]: SQL status: OK in 3.030 seconds
[0m10:08:49.581664 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c1f0-1c70-9e0e-f1d2e47aedd8, command-id=01f08e25-c213-1ab5-be7a-0acc88fcc7f0) - Closing
[0m10:08:49.616538 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:08:49.664033 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m10:08:49.664033 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c1f0-1c70-9e0e-f1d2e47aedd8) - Closing
[0m10:08:49.992235 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 3.57s]
[0m10:08:49.992235 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m10:08:49.992235 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m10:08:49.992235 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m10:08:49.992235 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m10:08:49.992235 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m10:08:49.992235 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m10:08:49.992235 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m10:08:49.992235 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m10:08:50.031520 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:08:50.049479 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m10:08:50.050482 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m10:08:50.051479 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m10:08:50.052479 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m10:08:50.052479 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:50.908166 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c40b-116b-9d3d-2431ce09035c) - Created
[0m10:08:51.723970 [debug] [Thread-3 (]: SQL status: OK in 1.670 seconds
[0m10:08:51.723970 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c40b-116b-9d3d-2431ce09035c, command-id=01f08e25-c42e-127f-9ef2-1848fd549224) - Closing
[0m10:08:51.733209 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:08:51.733209 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m10:08:51.733209 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c40b-116b-9d3d-2431ce09035c) - Closing
[0m10:08:51.972610 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 1.98s]
[0m10:08:51.972610 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m10:08:51.988693 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m10:08:51.988693 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m10:08:51.988693 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m10:08:51.991788 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m10:08:51.991788 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m10:08:51.991788 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m10:08:51.991788 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m10:08:51.991788 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:08:51.991788 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m10:08:51.991788 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m10:08:51.991788 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m10:08:51.991788 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:52.892825 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c539-1475-b395-64e9d83bcbe8) - Created
[0m10:08:54.982737 [debug] [Thread-3 (]: SQL status: OK in 2.990 seconds
[0m10:08:54.984336 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c539-1475-b395-64e9d83bcbe8, command-id=01f08e25-c55c-118a-baa9-d2d03b1a0f58) - Closing
[0m10:08:54.984869 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:08:54.986479 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m10:08:54.987013 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c539-1475-b395-64e9d83bcbe8) - Closing
[0m10:08:55.224028 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.24s]
[0m10:08:55.224028 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m10:08:55.224028 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m10:08:55.224028 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m10:08:55.224028 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m10:08:55.224028 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m10:08:55.224028 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m10:08:55.224028 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m10:08:55.224028 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m10:08:55.239861 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:08:55.241884 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m10:08:55.241884 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m10:08:55.241884 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m10:08:55.241884 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m10:08:55.241884 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:56.122716 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c727-15fb-b261-5275bef9c596) - Created
[0m10:08:56.913121 [debug] [Thread-3 (]: SQL status: OK in 1.670 seconds
[0m10:08:56.914133 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c727-15fb-b261-5275bef9c596, command-id=01f08e25-c748-1db4-9194-bd5df58f85a7) - Closing
[0m10:08:56.915123 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:08:56.916122 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m10:08:56.916122 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c727-15fb-b261-5275bef9c596) - Closing
[0m10:08:57.150841 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.93s]
[0m10:08:57.150841 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m10:08:57.150841 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m10:08:57.150841 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m10:08:57.150841 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m10:08:57.166516 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m10:08:57.166516 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m10:08:57.166516 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m10:08:57.166516 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m10:08:57.178894 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:08:57.181338 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m10:08:57.181338 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m10:08:57.181338 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m10:08:57.181338 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m10:08:57.181338 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:58.041710 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c849-18de-9322-835a42e9ceff) - Created
[0m10:08:58.845878 [debug] [Thread-3 (]: SQL status: OK in 1.660 seconds
[0m10:08:58.845878 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c849-18de-9322-835a42e9ceff, command-id=01f08e25-c86e-1fa5-a591-071611080fd5) - Closing
[0m10:08:58.856366 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:08:58.856366 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m10:08:58.857836 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c849-18de-9322-835a42e9ceff) - Closing
[0m10:08:59.090091 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.94s]
[0m10:08:59.090091 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m10:08:59.090091 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m10:08:59.090091 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m10:08:59.090091 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m10:08:59.090091 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m10:08:59.090091 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m10:08:59.105772 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m10:08:59.109248 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m10:08:59.115263 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:08:59.117261 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m10:08:59.118262 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m10:08:59.119262 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m10:08:59.119262 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:08:59.946625 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c96d-173d-a14d-984dfff8a5d5) - Created
[0m10:09:01.916291 [debug] [Thread-3 (]: SQL status: OK in 2.800 seconds
[0m10:09:01.917999 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e25-c96d-173d-a14d-984dfff8a5d5, command-id=01f08e25-c991-1494-bb67-9c5f51c1fd0a) - Closing
[0m10:09:01.918986 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:09:01.921009 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m10:09:01.921009 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e25-c96d-173d-a14d-984dfff8a5d5) - Closing
[0m10:09:02.165591 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.07s]
[0m10:09:02.167352 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m10:09:02.169365 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:09:02.171377 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:09:02.171377 [info ] [MainThread]: 
[0m10:09:02.175400 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 19.01 seconds (19.01s).
[0m10:09:02.183972 [debug] [MainThread]: Command end result
[0m10:09:02.449140 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\manifest.json
[0m10:09:02.454517 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\semantic_manifest.json
[0m10:09:02.470687 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_etl\target\run_results.json
[0m10:09:02.471696 [info ] [MainThread]: 
[0m10:09:02.480753 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:09:02.482762 [info ] [MainThread]: 
[0m10:09:02.486655 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m10:09:02.503825 [debug] [MainThread]: Command `dbt run` succeeded at 10:09:02.503825 after 23.30 seconds
[0m10:09:02.503825 [debug] [MainThread]: Flushing usage events
[0m10:12:35.617619 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 10:12:35.742155 | 03068529-e28c-49cc-b3ee-8047c625db7f ==============================
[0m10:12:35.742155 [info ] [MainThread]: Running with dbt=1.10.11
[0m10:12:35.745215 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m10:12:37.592846 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:12:37.592846 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:12:37.592846 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:12:39.255516 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:12:39.988537 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m10:12:40.339603 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:12:40.339603 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:12:40.586538 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m10:12:40.596802 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m10:12:40.617943 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m10:12:40.625701 [info ] [MainThread]: 
[0m10:12:40.626234 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:12:40.626234 [info ] [MainThread]: 
[0m10:12:40.629253 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:12:40.629784 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:12:40.646389 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m10:12:40.646903 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m10:12:40.647939 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m10:12:40.648784 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m10:12:40.649288 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:12:42.486222 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-4e12-17d1-b2e1-6a0a1d670b2a) - Created
[0m10:12:43.036430 [debug] [ThreadPool]: SQL status: OK in 2.390 seconds
[0m10:12:43.036430 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-4e12-17d1-b2e1-6a0a1d670b2a, command-id=01f08e26-4e39-15d7-8f3f-f2d6c482de81) - Closing
[0m10:12:43.036430 [debug] [ThreadPool]: On list_dbt-project: Close
[0m10:12:43.036430 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-4e12-17d1-b2e1-6a0a1d670b2a) - Closing
[0m10:12:43.280208 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m10:12:43.280208 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m10:12:43.310148 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m10:12:43.310148 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m10:12:43.311888 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:12:44.181968 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-4f15-1c16-9516-5c867badc7c2) - Created
[0m10:12:44.827673 [debug] [ThreadPool]: SQL status: OK in 1.510 seconds
[0m10:12:44.837890 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-4f15-1c16-9516-5c867badc7c2, command-id=01f08e26-4f3e-1aae-883a-cf8a5ed6d27d) - Closing
[0m10:12:44.840679 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m10:12:44.841198 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-4f15-1c16-9516-5c867badc7c2) - Closing
[0m10:12:45.100268 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_customer
[0m10:12:45.101340 [info ] [Thread-3 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m10:12:45.103049 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m10:12:45.103580 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m10:12:45.104169 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m10:12:45.118396 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m10:12:45.120572 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_customer
[0m10:12:45.160388 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:12:45.160388 [warn ] [Thread-3 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:12:45.264415 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m10:12:45.265960 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m10:12:45.266486 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m10:12:45.267006 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:46.058484 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5032-145d-b023-0c3012c25b71) - Created
[0m10:12:48.351951 [debug] [Thread-3 (]: SQL status: OK in 3.080 seconds
[0m10:12:48.356995 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-5032-145d-b023-0c3012c25b71, command-id=01f08e26-5053-1127-b85d-b4a8f4d930c5) - Closing
[0m10:12:48.378570 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:12:48.413520 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_customer: Close
[0m10:12:48.413520 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5032-145d-b023-0c3012c25b71) - Closing
[0m10:12:48.647473 [info ] [Thread-3 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 3.53s]
[0m10:12:48.649481 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_customer
[0m10:12:48.649481 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_date
[0m10:12:48.649481 [info ] [Thread-3 (]: 2 of 6 START sql view model default.bronze_date ................................ [RUN]
[0m10:12:48.654447 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m10:12:48.656670 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m10:12:48.657716 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_date
[0m10:12:48.660390 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m10:12:48.664950 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_date
[0m10:12:48.701541 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:12:48.722199 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_date`
[0m10:12:48.722199 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m10:12:48.722199 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m10:12:48.722199 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m10:12:48.722199 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:49.588562 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-524e-150a-9e08-4512f8a8bbf3) - Created
[0m10:12:50.425012 [debug] [Thread-3 (]: SQL status: OK in 1.700 seconds
[0m10:12:50.426758 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-524e-150a-9e08-4512f8a8bbf3, command-id=01f08e26-5278-1c9c-851b-4f489c9179cb) - Closing
[0m10:12:50.428069 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:12:50.428069 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_date: Close
[0m10:12:50.428069 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-524e-150a-9e08-4512f8a8bbf3) - Closing
[0m10:12:50.661340 [info ] [Thread-3 (]: 2 of 6 OK created sql view model default.bronze_date ........................... [[32mOK[0m in 2.01s]
[0m10:12:50.662384 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_date
[0m10:12:50.663624 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m10:12:50.664583 [info ] [Thread-3 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m10:12:50.666146 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m10:12:50.666670 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m10:12:50.667198 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m10:12:50.674717 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m10:12:50.676332 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m10:12:50.680687 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:12:50.683275 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m10:12:50.686491 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m10:12:50.689069 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m10:12:50.689822 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:51.490699 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-536f-1c93-aa33-b2e042b07e26) - Created
[0m10:12:53.468301 [debug] [Thread-3 (]: SQL status: OK in 2.780 seconds
[0m10:12:53.470313 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-536f-1c93-aa33-b2e042b07e26, command-id=01f08e26-5390-154e-a6ac-8bf990d9238e) - Closing
[0m10:12:53.472320 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:12:53.474551 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m10:12:53.477531 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-536f-1c93-aa33-b2e042b07e26) - Closing
[0m10:12:53.692082 [info ] [Thread-3 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.03s]
[0m10:12:53.692082 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m10:12:53.692082 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_returns
[0m10:12:53.692082 [info ] [Thread-3 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m10:12:53.700444 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m10:12:53.701431 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m10:12:53.701431 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m10:12:53.705464 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m10:12:53.705464 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_returns
[0m10:12:53.716816 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:12:53.720700 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m10:12:53.723834 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m10:12:53.724853 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m10:12:53.724853 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m10:12:53.724853 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:54.538176 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5541-1995-bab5-566f539afbb2) - Created
[0m10:12:55.320562 [debug] [Thread-3 (]: SQL status: OK in 1.600 seconds
[0m10:12:55.320562 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-5541-1995-bab5-566f539afbb2, command-id=01f08e26-5561-1cc9-81e0-d8616ef45116) - Closing
[0m10:12:55.333736 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:12:55.338857 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_returns: Close
[0m10:12:55.338857 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5541-1995-bab5-566f539afbb2) - Closing
[0m10:12:55.552849 [info ] [Thread-3 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.86s]
[0m10:12:55.561364 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_returns
[0m10:12:55.561364 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_sales
[0m10:12:55.561364 [info ] [Thread-3 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m10:12:55.561364 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m10:12:55.565222 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m10:12:55.565222 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m10:12:55.571975 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m10:12:55.571975 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_sales
[0m10:12:55.582884 [debug] [Thread-3 (]: MATERIALIZING VIEW
[0m10:12:55.584679 [debug] [Thread-3 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m10:12:55.585707 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m10:12:55.589284 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m10:12:55.589284 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m10:12:55.591569 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:56.563848 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5665-1a5f-9a40-fee42bf44932) - Created
[0m10:12:57.369442 [debug] [Thread-3 (]: SQL status: OK in 1.780 seconds
[0m10:12:57.369442 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-5665-1a5f-9a40-fee42bf44932, command-id=01f08e26-5698-1c37-9ba3-caadddd910cf) - Closing
[0m10:12:57.369442 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:12:57.369442 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_sales: Close
[0m10:12:57.369442 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5665-1a5f-9a40-fee42bf44932) - Closing
[0m10:12:57.628444 [info ] [Thread-3 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.07s]
[0m10:12:57.633155 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_sales
[0m10:12:57.635361 [debug] [Thread-3 (]: Began running node model.dbt_eTl.bronze_store
[0m10:12:57.636760 [info ] [Thread-3 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m10:12:57.639000 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m10:12:57.639000 [debug] [Thread-3 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m10:12:57.641672 [debug] [Thread-3 (]: Began compiling node model.dbt_eTl.bronze_store
[0m10:12:57.651939 [debug] [Thread-3 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m10:12:57.657404 [debug] [Thread-3 (]: Began executing node model.dbt_eTl.bronze_store
[0m10:12:57.664981 [debug] [Thread-3 (]: MATERIALIZING TABLE
[0m10:12:57.672024 [debug] [Thread-3 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m10:12:57.675870 [debug] [Thread-3 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m10:12:57.675870 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m10:12:57.677877 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m10:12:58.475813 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5799-1000-92d2-ada5b26b837f) - Created
[0m10:13:00.365431 [debug] [Thread-3 (]: SQL status: OK in 2.690 seconds
[0m10:13:00.365431 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e26-5799-1000-92d2-ada5b26b837f, command-id=01f08e26-57ba-1db8-8f78-ef459dab3295) - Closing
[0m10:13:00.367959 [debug] [Thread-3 (]: Applying tags to relation None
[0m10:13:00.370113 [debug] [Thread-3 (]: On model.dbt_eTl.bronze_store: Close
[0m10:13:00.370113 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e26-5799-1000-92d2-ada5b26b837f) - Closing
[0m10:13:00.611148 [info ] [Thread-3 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 2.97s]
[0m10:13:00.612938 [debug] [Thread-3 (]: Finished running node model.dbt_eTl.bronze_store
[0m10:13:00.614693 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:13:00.615798 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:13:00.616852 [info ] [MainThread]: 
[0m10:13:00.617370 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 19.99 seconds (19.99s).
[0m10:13:00.622413 [debug] [MainThread]: Command end result
[0m10:13:00.838323 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m10:13:00.851339 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m10:13:00.851339 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m10:13:00.851339 [info ] [MainThread]: 
[0m10:13:00.863265 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:13:00.863265 [info ] [MainThread]: 
[0m10:13:00.863265 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m10:13:00.863265 [debug] [MainThread]: Command `dbt run` succeeded at 10:13:00.863265 after 25.36 seconds
[0m10:13:00.863265 [debug] [MainThread]: Flushing usage events
[0m10:16:09.531139 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 10:16:09.652150 | 5a2d731e-7f12-459d-b343-b92e77d669f3 ==============================
[0m10:16:09.652150 [info ] [MainThread]: Running with dbt=1.10.11
[0m10:16:09.654049 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m10:16:11.379412 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m10:16:11.379412 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m10:16:11.379412 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m10:16:13.054465 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m10:16:13.751117 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m10:16:14.196161 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m10:16:14.196161 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m10:16:14.381516 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m10:16:14.381516 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m10:16:14.416757 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m10:16:14.416757 [info ] [MainThread]: 
[0m10:16:14.416757 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m10:16:14.416757 [info ] [MainThread]: 
[0m10:16:14.416757 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:16:14.416757 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:16:14.451891 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m10:16:14.451891 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m10:16:14.453898 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m10:16:14.453898 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m10:16:14.453898 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:15.372952 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-ccf6-13df-89d5-13eb5f237c57) - Created
[0m10:16:15.828838 [debug] [ThreadPool]: SQL status: OK in 1.370 seconds
[0m10:16:15.836461 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-ccf6-13df-89d5-13eb5f237c57, command-id=01f08e26-cd1b-1192-94a0-8fde06eea3b1) - Closing
[0m10:16:15.837529 [debug] [ThreadPool]: On list_dbt-project: Close
[0m10:16:15.838629 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-ccf6-13df-89d5-13eb5f237c57) - Closing
[0m10:16:16.076481 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m10:16:16.076481 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m10:16:16.079332 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m10:16:16.079332 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m10:16:16.083055 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:17.054727 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cdf6-1153-a675-2378940031a3) - Created
[0m10:16:17.447016 [debug] [ThreadPool]: SQL status: OK in 1.360 seconds
[0m10:16:17.448035 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-cdf6-1153-a675-2378940031a3, command-id=01f08e26-ce19-1943-92a0-c512c945720c) - Closing
[0m10:16:17.448035 [debug] [ThreadPool]: On list_dbt-project: Close
[0m10:16:17.448035 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cdf6-1153-a675-2378940031a3) - Closing
[0m10:16:17.712528 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_bronze) - Creating connection
[0m10:16:17.720216 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_bronze'
[0m10:16:17.720216 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "bronze"
"
[0m10:16:17.745965 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_bronze"
[0m10:16:17.748045 [debug] [ThreadPool]: On create_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_bronze"} */
create schema if not exists `dbt-project`.`bronze`
  
[0m10:16:17.750301 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:18.615941 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cee4-149d-becf-cd349b488c01) - Created
[0m10:16:19.329200 [debug] [ThreadPool]: SQL status: OK in 1.580 seconds
[0m10:16:19.329200 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-cee4-149d-becf-cd349b488c01, command-id=01f08e26-cf09-1689-893c-f10330ea98ea) - Closing
[0m10:16:19.329200 [debug] [ThreadPool]: On create_dbt-project_bronze: Close
[0m10:16:19.329200 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cee4-149d-becf-cd349b488c01) - Closing
[0m10:16:19.571281 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m10:16:19.579739 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m10:16:19.595850 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m10:16:19.595850 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m10:16:19.595850 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:20.436931 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cffd-1dba-a930-bc90c09e9ea3) - Created
[0m10:16:21.096224 [debug] [ThreadPool]: SQL status: OK in 1.500 seconds
[0m10:16:21.106388 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-cffd-1dba-a930-bc90c09e9ea3, command-id=01f08e26-d024-10a3-832c-f3a5766bb929) - Closing
[0m10:16:21.108125 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m10:16:21.108125 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-cffd-1dba-a930-bc90c09e9ea3) - Closing
[0m10:16:21.354769 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m10:16:21.362093 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m10:16:21.366444 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m10:16:21.366444 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m10:16:21.370540 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m10:16:22.218682 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-d10a-16b4-a8b0-e128d41c6d46) - Created
[0m10:16:22.776370 [debug] [ThreadPool]: SQL status: OK in 1.410 seconds
[0m10:16:22.780386 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e26-d10a-16b4-a8b0-e128d41c6d46, command-id=01f08e26-d12d-134d-89e8-5572a06d4ca7) - Closing
[0m10:16:22.780386 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m10:16:22.780386 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e26-d10a-16b4-a8b0-e128d41c6d46) - Closing
[0m10:16:23.033609 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_customer
[0m10:16:23.034672 [info ] [Thread-6 (]: 1 of 6 START sql view model bronze.bronze_customer ............................. [RUN]
[0m10:16:23.035717 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m10:16:23.036295 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m10:16:23.036820 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m10:16:23.055507 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m10:16:23.057741 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_customer
[0m10:16:23.088152 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m10:16:23.102287 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m10:16:23.120305 [debug] [Thread-6 (]: Creating view `dbt-project`.`bronze`.`bronze_customer`
[0m10:16:23.148288 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m10:16:23.148288 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m10:16:23.148288 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m10:16:23.148288 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:24.127991 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d221-19fe-a470-5e1b9f746bf3) - Created
[0m10:16:24.839899 [debug] [Thread-6 (]: SQL status: OK in 1.690 seconds
[0m10:16:24.840965 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d221-19fe-a470-5e1b9f746bf3, command-id=01f08e26-d251-1c22-9a2d-4438e58fe193) - Closing
[0m10:16:24.853469 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:24.853469 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: Close
[0m10:16:24.853469 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d221-19fe-a470-5e1b9f746bf3) - Closing
[0m10:16:25.110907 [info ] [Thread-6 (]: 1 of 6 OK created sql view model bronze.bronze_customer ........................ [[32mOK[0m in 2.07s]
[0m10:16:25.112341 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_customer
[0m10:16:25.116506 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_date
[0m10:16:25.116506 [info ] [Thread-6 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m10:16:25.119308 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m10:16:25.120353 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m10:16:25.120980 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_date
[0m10:16:25.120980 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m10:16:25.129101 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_date
[0m10:16:25.141291 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m10:16:25.145013 [debug] [Thread-6 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m10:16:25.149085 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m10:16:25.151642 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m10:16:25.151642 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m10:16:25.151642 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:26.288927 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d372-1a8d-a66e-67051ff69714) - Created
[0m10:16:26.950784 [debug] [Thread-6 (]: SQL status: OK in 1.800 seconds
[0m10:16:26.950784 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d372-1a8d-a66e-67051ff69714, command-id=01f08e26-d39a-137e-86a9-39b8c2e75b59) - Closing
[0m10:16:26.950784 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:26.950784 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: Close
[0m10:16:26.950784 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d372-1a8d-a66e-67051ff69714) - Closing
[0m10:16:27.333768 [info ] [Thread-6 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.22s]
[0m10:16:27.333768 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_date
[0m10:16:27.333768 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m10:16:27.333768 [info ] [Thread-6 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m10:16:27.333768 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m10:16:27.333768 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m10:16:27.333768 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m10:16:27.352362 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m10:16:27.353361 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m10:16:27.392312 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m10:16:27.449932 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m10:16:27.449932 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m10:16:27.449932 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m10:16:27.449932 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:28.525359 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d4c9-15c8-a1a7-17cfd2ddaa3b) - Created
[0m10:16:30.612288 [debug] [Thread-6 (]: SQL status: OK in 3.160 seconds
[0m10:16:30.614328 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d4c9-15c8-a1a7-17cfd2ddaa3b, command-id=01f08e26-d4ec-1932-9357-aa36ced6618e) - Closing
[0m10:16:30.623959 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:30.647236 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m10:16:30.647236 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d4c9-15c8-a1a7-17cfd2ddaa3b) - Closing
[0m10:16:30.897238 [info ] [Thread-6 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.56s]
[0m10:16:30.897238 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m10:16:30.903534 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_returns
[0m10:16:30.904362 [info ] [Thread-6 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m10:16:30.906005 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m10:16:30.907045 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m10:16:30.907579 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m10:16:30.911842 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m10:16:30.914920 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_returns
[0m10:16:30.918891 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m10:16:30.920611 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m10:16:30.922974 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m10:16:30.924002 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m10:16:30.924002 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m10:16:30.926118 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:31.808204 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d6c2-1f0f-a2d3-df8d4daa9e75) - Created
[0m10:16:32.606049 [debug] [Thread-6 (]: SQL status: OK in 1.680 seconds
[0m10:16:32.613573 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d6c2-1f0f-a2d3-df8d4daa9e75, command-id=01f08e26-d6e7-1866-ab61-d001908e7f40) - Closing
[0m10:16:32.616412 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:32.616412 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: Close
[0m10:16:32.616412 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d6c2-1f0f-a2d3-df8d4daa9e75) - Closing
[0m10:16:32.862187 [info ] [Thread-6 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.95s]
[0m10:16:32.865519 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_returns
[0m10:16:32.867531 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_sales
[0m10:16:32.867531 [info ] [Thread-6 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m10:16:32.867531 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m10:16:32.867531 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m10:16:32.867531 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m10:16:32.867531 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m10:16:32.882145 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_sales
[0m10:16:32.890730 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m10:16:32.895472 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m10:16:32.901782 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m10:16:32.905826 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m10:16:32.907835 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m10:16:32.907835 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:33.835783 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d7f6-1ff5-804d-40d8f5ca32b1) - Created
[0m10:16:34.641445 [debug] [Thread-6 (]: SQL status: OK in 1.730 seconds
[0m10:16:34.641445 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d7f6-1ff5-804d-40d8f5ca32b1, command-id=01f08e26-d81a-15cb-81fa-33c6febc5b80) - Closing
[0m10:16:34.641445 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:34.641445 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: Close
[0m10:16:34.641445 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d7f6-1ff5-804d-40d8f5ca32b1) - Closing
[0m10:16:34.896820 [info ] [Thread-6 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.03s]
[0m10:16:34.900918 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_sales
[0m10:16:34.900918 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_store
[0m10:16:34.902928 [info ] [Thread-6 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m10:16:34.904939 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m10:16:34.904939 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m10:16:34.904939 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_store
[0m10:16:34.918485 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m10:16:34.919857 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_store
[0m10:16:34.923905 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m10:16:34.932515 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m10:16:34.936380 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m10:16:34.936380 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m10:16:34.936380 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m10:16:35.734219 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d918-12f2-b745-e3b963debce6) - Created
[0m10:16:37.687430 [debug] [Thread-6 (]: SQL status: OK in 2.750 seconds
[0m10:16:37.689439 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e26-d918-12f2-b745-e3b963debce6, command-id=01f08e26-d938-1940-ab10-c8a7b9c3b89f) - Closing
[0m10:16:37.689439 [debug] [Thread-6 (]: Applying tags to relation None
[0m10:16:37.691449 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: Close
[0m10:16:37.691449 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e26-d918-12f2-b745-e3b963debce6) - Closing
[0m10:16:37.912226 [info ] [Thread-6 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.01s]
[0m10:16:37.912226 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_store
[0m10:16:37.912226 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m10:16:37.912226 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m10:16:37.912226 [info ] [MainThread]: 
[0m10:16:37.912226 [info ] [MainThread]: Finished running 2 table models, 4 view models in 0 hours 0 minutes and 23.50 seconds (23.50s).
[0m10:16:37.912226 [debug] [MainThread]: Command end result
[0m10:16:38.116003 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m10:16:38.116003 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m10:16:38.132171 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m10:16:38.134198 [info ] [MainThread]: 
[0m10:16:38.134198 [info ] [MainThread]: [32mCompleted successfully[0m
[0m10:16:38.134198 [info ] [MainThread]: 
[0m10:16:38.137430 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m10:16:38.139441 [debug] [MainThread]: Command `dbt run` succeeded at 10:16:38.139441 after 28.72 seconds
[0m10:16:38.139441 [debug] [MainThread]: Flushing usage events
[0m12:57:42.272186 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 12:57:42.399988 | 27401d10-417a-456a-beec-accfc2bf67ea ==============================
[0m12:57:42.399988 [info ] [MainThread]: Running with dbt=1.10.11
[0m12:57:42.399988 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m12:57:44.482115 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:57:44.482115 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:57:44.482115 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:57:47.198397 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:57:47.956510 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m12:57:48.263392 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:57:48.263392 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:57:48.471602 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m12:57:48.481286 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m12:57:48.514782 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m12:57:48.518902 [info ] [MainThread]: 
[0m12:57:48.522697 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:57:48.522697 [info ] [MainThread]: 
[0m12:57:48.524711 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:57:48.524711 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:57:48.553542 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m12:57:48.553542 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m12:57:48.555551 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m12:57:48.555551 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m12:57:48.555551 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:49.937241 [error] [ThreadPool]: databricks-sql-connector adapter: ThriftBackend.attempt_request: Exception: %s
[0m12:57:49.985362 [error] [ThreadPool]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server: BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.. BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.
Error properties: attempt=1/30, bounded-retry-delay=None, elapsed-seconds=1.2550947666168213/900.0, error-message=BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account., http-code=400, method=OpenSession, no-retry-reason=non-retryable error, original-exception=BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account., query-id=None, session-id=None
[0m12:57:49.987374 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
GetSchemas(database=dbt-project, schema=None)
: Database Error
  Error during request to server: BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.. BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.
[0m12:57:49.987374 [debug] [ThreadPool]: On list_dbt-project: No close available on handle
[0m12:57:49.993021 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m12:57:49.998958 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m12:57:49.998958 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m12:57:50.000974 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m12:57:50.001634 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:57:50.939715 [error] [ThreadPool]: databricks-sql-connector adapter: ThriftBackend.attempt_request: Exception: %s
[0m12:57:50.941399 [error] [ThreadPool]: Databricks adapter: Connection(session-id=Unknown) - Exception while trying to create connection: Error during request to server: BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.. BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.
Error properties: attempt=1/30, bounded-retry-delay=None, elapsed-seconds=0.8207886219024658/900.0, error-message=BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account., http-code=400, method=OpenSession, no-retry-reason=non-retryable error, original-exception=BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account., query-id=None, session-id=None
[0m12:57:50.942905 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
GetSchemas(database=dbt-project, schema=None)
: Database Error
  Error during request to server: BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.. BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.
[0m12:57:50.943966 [debug] [ThreadPool]: On list_dbt-project: No close available on handle
[0m12:57:50.945541 [info ] [MainThread]: 
[0m12:57:50.949034 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 2.42 seconds (2.42s).
[0m12:57:50.954813 [error] [MainThread]: Encountered an error:
Database Error
  Database Error
    Error during request to server: BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.. BAD_REQUEST: Sorry, cannot run the resource because you've exhausted your available credits. Please add a payment method to upgrade your account.
[0m12:57:50.956835 [debug] [MainThread]: Command `dbt run` failed at 12:57:50.954813 after 8.80 seconds
[0m12:57:50.957140 [debug] [MainThread]: Flushing usage events
[0m13:21:53.277265 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:21:53.412564 | 4d881834-3692-4545-8e40-223b47abc89f ==============================
[0m13:21:53.412564 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:21:53.412564 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m13:21:55.197975 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:21:55.198690 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:21:55.198690 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:21:56.730707 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:21:57.454550 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m13:21:57.741188 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:21:57.741188 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:21:57.973416 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m13:21:57.979824 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m13:21:57.995708 [info ] [MainThread]: Found 6 models, 6 sources, 686 macros
[0m13:21:58.004769 [info ] [MainThread]: 
[0m13:21:58.010165 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:21:58.010165 [info ] [MainThread]: 
[0m13:21:58.013153 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:21:58.013153 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:21:58.028367 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m13:21:58.028367 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m13:21:58.028367 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m13:21:58.028367 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m13:21:58.028367 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:21:58.696545 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-bee6-1fe5-b069-4bcb5b41b3b7) - Created
[0m13:21:59.309397 [debug] [ThreadPool]: SQL status: OK in 1.280 seconds
[0m13:21:59.311404 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e40-bee6-1fe5-b069-4bcb5b41b3b7, command-id=01f08e40-beff-1d33-9a8b-30eda440c611) - Closing
[0m13:21:59.311404 [debug] [ThreadPool]: On list_dbt-project: Close
[0m13:21:59.313412 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-bee6-1fe5-b069-4bcb5b41b3b7) - Closing
[0m13:21:59.487609 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m13:21:59.491866 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m13:21:59.491866 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m13:21:59.493876 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m13:21:59.493876 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:22:00.068037 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-bfb8-1eb3-818a-fc64a29de6f5) - Created
[0m13:22:00.380848 [debug] [ThreadPool]: SQL status: OK in 0.890 seconds
[0m13:22:00.380848 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e40-bfb8-1eb3-818a-fc64a29de6f5, command-id=01f08e40-bfd8-1445-985a-9ceb7769145f) - Closing
[0m13:22:00.385984 [debug] [ThreadPool]: On list_dbt-project: Close
[0m13:22:00.385984 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-bfb8-1eb3-818a-fc64a29de6f5) - Closing
[0m13:22:00.567001 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_bronze) - Creating connection
[0m13:22:00.567001 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_bronze'
[0m13:22:00.570513 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "bronze"
"
[0m13:22:00.589458 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_bronze"
[0m13:22:00.598582 [debug] [ThreadPool]: On create_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_bronze"} */
create schema if not exists `dbt-project`.`bronze`
  
[0m13:22:00.598582 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:22:01.176434 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c062-194f-aa24-433a047833d2) - Created
[0m13:22:01.706898 [debug] [ThreadPool]: SQL status: OK in 1.110 seconds
[0m13:22:01.708911 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e40-c062-194f-aa24-433a047833d2, command-id=01f08e40-c07a-1746-a68d-bf3fa2a7ea0a) - Closing
[0m13:22:01.710917 [debug] [ThreadPool]: On create_dbt-project_bronze: Close
[0m13:22:01.710917 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c062-194f-aa24-433a047833d2) - Closing
[0m13:22:01.950666 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m13:22:01.950666 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m13:22:01.974276 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m13:22:01.974276 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m13:22:01.976893 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:22:04.723030 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c280-1994-ada1-8eed6fb5c9e8) - Created
[0m13:22:05.424280 [debug] [ThreadPool]: SQL status: OK in 3.450 seconds
[0m13:22:05.454306 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e40-c280-1994-ada1-8eed6fb5c9e8, command-id=01f08e40-c297-1c25-80ca-8edce001ab8f) - Closing
[0m13:22:05.454306 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m13:22:05.454306 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c280-1994-ada1-8eed6fb5c9e8) - Closing
[0m13:22:05.605588 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m13:22:05.612810 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m13:22:05.612810 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m13:22:05.612810 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m13:22:05.612810 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:22:06.169624 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c35d-176b-9326-069d65282115) - Created
[0m13:22:06.573435 [debug] [ThreadPool]: SQL status: OK in 0.960 seconds
[0m13:22:06.581298 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e40-c35d-176b-9326-069d65282115, command-id=01f08e40-c373-195e-8419-2dec6a5c9b9b) - Closing
[0m13:22:06.581298 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m13:22:06.581298 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e40-c35d-176b-9326-069d65282115) - Closing
[0m13:22:06.807148 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_customer
[0m13:22:06.807148 [info ] [Thread-6 (]: 1 of 6 START sql view model bronze.bronze_customer ............................. [RUN]
[0m13:22:06.812759 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m13:22:06.812759 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m13:22:06.812759 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m13:22:06.829104 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m13:22:06.832206 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_customer
[0m13:22:06.861814 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m13:22:06.867845 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m13:22:06.895104 [debug] [Thread-6 (]: Creating view `dbt-project`.`bronze`.`bronze_customer`
[0m13:22:06.916214 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m13:22:06.916214 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m13:22:06.918221 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_customer`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  )

[0m13:22:06.918221 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:07.474226 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c425-114e-a3fe-da1ad9724d74) - Created
[0m13:22:08.058532 [debug] [Thread-6 (]: SQL status: OK in 1.140 seconds
[0m13:22:08.060543 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c425-114e-a3fe-da1ad9724d74, command-id=01f08e40-c43c-119d-9f4c-745be169572e) - Closing
[0m13:22:08.085465 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:08.095390 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: Close
[0m13:22:08.097396 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c425-114e-a3fe-da1ad9724d74) - Closing
[0m13:22:08.270796 [info ] [Thread-6 (]: 1 of 6 OK created sql view model bronze.bronze_customer ........................ [[32mOK[0m in 1.45s]
[0m13:22:08.273127 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_customer
[0m13:22:08.273127 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_date
[0m13:22:08.273127 [info ] [Thread-6 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m13:22:08.273127 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m13:22:08.273127 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m13:22:08.273127 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_date
[0m13:22:08.273127 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m13:22:08.287517 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_date
[0m13:22:08.293459 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m13:22:08.293459 [debug] [Thread-6 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m13:22:08.303102 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m13:22:08.306274 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m13:22:08.308315 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m13:22:08.310325 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:08.901390 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c4fd-12de-bf8f-7afab24682d8) - Created
[0m13:22:09.394651 [debug] [Thread-6 (]: SQL status: OK in 1.080 seconds
[0m13:22:09.396656 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c4fd-12de-bf8f-7afab24682d8, command-id=01f08e40-c514-1fd5-a0d5-8093580f9be8) - Closing
[0m13:22:09.396656 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:09.398662 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: Close
[0m13:22:09.398662 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c4fd-12de-bf8f-7afab24682d8) - Closing
[0m13:22:09.572154 [info ] [Thread-6 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.30s]
[0m13:22:09.580155 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_date
[0m13:22:09.580155 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m13:22:09.582038 [info ] [Thread-6 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m13:22:09.582038 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m13:22:09.582038 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m13:22:09.582038 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m13:22:09.592132 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m13:22:09.592132 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m13:22:09.622532 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m13:22:09.703590 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m13:22:09.708396 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m13:22:09.709176 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m13:22:09.709176 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:10.238877 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c5c9-1de8-aa90-500e0dc3e9e4) - Created
[0m13:22:13.332694 [debug] [Thread-6 (]: SQL status: OK in 3.620 seconds
[0m13:22:13.334476 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c5c9-1de8-aa90-500e0dc3e9e4, command-id=01f08e40-c5e0-164c-93db-50fe706c7a54) - Closing
[0m13:22:13.334476 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:13.376876 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m13:22:13.376876 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c5c9-1de8-aa90-500e0dc3e9e4) - Closing
[0m13:22:13.537350 [info ] [Thread-6 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.96s]
[0m13:22:13.549473 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m13:22:13.549473 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_returns
[0m13:22:13.551993 [info ] [Thread-6 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m13:22:13.552354 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m13:22:13.553923 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m13:22:13.553923 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m13:22:13.565752 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m13:22:13.568654 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_returns
[0m13:22:13.576821 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m13:22:13.581286 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m13:22:13.581286 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m13:22:13.581286 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m13:22:13.581286 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m13:22:13.581286 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:14.211708 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c828-1e58-9922-1ad99f096fc5) - Created
[0m13:22:14.679831 [debug] [Thread-6 (]: SQL status: OK in 1.100 seconds
[0m13:22:14.679831 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c828-1e58-9922-1ad99f096fc5, command-id=01f08e40-c83f-182d-8335-064c64cacc07) - Closing
[0m13:22:14.679831 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:14.689654 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: Close
[0m13:22:14.689654 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c828-1e58-9922-1ad99f096fc5) - Closing
[0m13:22:14.847966 [info ] [Thread-6 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.30s]
[0m13:22:14.847966 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_returns
[0m13:22:14.853960 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_sales
[0m13:22:14.856985 [info ] [Thread-6 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m13:22:14.856985 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m13:22:14.860136 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m13:22:14.860136 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m13:22:14.870581 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m13:22:14.874557 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_sales
[0m13:22:14.880904 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m13:22:14.886164 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m13:22:14.886164 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m13:22:14.890735 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m13:22:14.893325 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m13:22:14.893325 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:15.525675 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c8e8-18c0-97ed-b6da319314c9) - Created
[0m13:22:16.001717 [debug] [Thread-6 (]: SQL status: OK in 1.110 seconds
[0m13:22:16.004003 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c8e8-18c0-97ed-b6da319314c9, command-id=01f08e40-c908-145f-91b4-cf10b5bd7ee3) - Closing
[0m13:22:16.006201 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:16.006201 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: Close
[0m13:22:16.006201 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c8e8-18c0-97ed-b6da319314c9) - Closing
[0m13:22:16.187486 [info ] [Thread-6 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.33s]
[0m13:22:16.188941 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_sales
[0m13:22:16.188941 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_store
[0m13:22:16.188941 [info ] [Thread-6 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m13:22:16.195284 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m13:22:16.195284 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m13:22:16.196480 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_store
[0m13:22:16.210271 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m13:22:16.210271 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_store
[0m13:22:16.217865 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m13:22:16.219635 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m13:22:16.223008 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m13:22:16.225023 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m13:22:16.227034 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m13:22:16.820743 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c9b7-15fb-a224-4712de0f9368) - Created
[0m13:22:19.190926 [debug] [Thread-6 (]: SQL status: OK in 2.960 seconds
[0m13:22:19.192937 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08e40-c9b7-15fb-a224-4712de0f9368, command-id=01f08e40-c9cd-18e6-a312-8510f4ac4ff4) - Closing
[0m13:22:19.192937 [debug] [Thread-6 (]: Applying tags to relation None
[0m13:22:19.192937 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: Close
[0m13:22:19.192937 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08e40-c9b7-15fb-a224-4712de0f9368) - Closing
[0m13:22:19.358676 [info ] [Thread-6 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.17s]
[0m13:22:19.370512 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_store
[0m13:22:19.371195 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:22:19.371195 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:22:19.371195 [info ] [MainThread]: 
[0m13:22:19.371195 [info ] [MainThread]: Finished running 2 table models, 4 view models in 0 hours 0 minutes and 21.36 seconds (21.36s).
[0m13:22:19.380402 [debug] [MainThread]: Command end result
[0m13:22:19.587097 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m13:22:19.594068 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m13:22:19.605948 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m13:22:19.605948 [info ] [MainThread]: 
[0m13:22:19.609618 [info ] [MainThread]: [32mCompleted successfully[0m
[0m13:22:19.609618 [info ] [MainThread]: 
[0m13:22:19.609618 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m13:22:19.609618 [debug] [MainThread]: Command `dbt run` succeeded at 13:22:19.609618 after 26.43 seconds
[0m13:22:19.609618 [debug] [MainThread]: Flushing usage events
[0m13:51:15.256471 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:51:15.377290 | 4a9c743b-8d49-4f6a-97fe-136537700d2d ==============================
[0m13:51:15.377290 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:51:15.377290 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m13:51:17.091421 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:51:17.091421 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:51:17.091421 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:51:18.792622 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:51:19.539638 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m13:51:19.926208 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:51:19.926208 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://models\bronze\properties.yml
[0m13:51:20.446430 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models\bronze\properties.yml:
  	test arguments must be a dict, got <class 'list'> (value ['MegaMart Toronto', 'MegaMart San Jose', 'MegaMart Austin', 'MegaMart Brooklyn', 'MegaMart Los Angeles', 'MegaMart Manhattan'])
  	@: UnparsedModelUpdate(original_file_path='mode...ne)
[0m13:51:20.446430 [debug] [MainThread]: Command `dbt run` failed at 13:51:20.446430 after 5.29 seconds
[0m13:51:20.457853 [debug] [MainThread]: Flushing usage events
[0m13:53:39.894179 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:53:40.027249 | 5c082568-d054-4c38-bdf2-2c51b4d7c298 ==============================
[0m13:53:40.027249 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:53:40.029258 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m13:53:41.808056 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:53:41.808056 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:53:41.808056 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:53:43.512979 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:53:44.363763 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m13:53:44.734097 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m13:53:44.734097 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://models\bronze\properties.yml
[0m13:53:45.287730 [error] [MainThread]: Encountered an error:
Parsing Error
  Invalid test config given in models\bronze\properties.yml:
  	test definition dictionary must have exactly one key, got [('accepted values', None), ('arguments', {'values': ['MegaMart Toronto', 'MegaMart San Jose', 'MegaMart Austin', 'MegaMart Brooklyn', 'MegaMart Los Angeles', 'MegaMart Manhattan']})] instead (2 keys)
  	@: UnparsedModelUpdate(original_file_path='mode...ne)
[0m13:53:45.287730 [debug] [MainThread]: Command `dbt test` failed at 13:53:45.287730 after 5.50 seconds
[0m13:53:45.287730 [debug] [MainThread]: Flushing usage events
[0m13:54:56.968924 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:54:57.079950 | c4d8102f-046d-4e65-8243-c6af77ed9308 ==============================
[0m13:54:57.079950 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:54:57.079950 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m13:54:58.764188 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:54:58.764188 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:54:58.770170 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:55:00.398540 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:55:01.102164 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m13:55:01.418437 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:55:01.418437 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:55:01.653555 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m13:55:01.653555 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m13:55:01.745763 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 686 macros
[0m13:55:01.750583 [info ] [MainThread]: 
[0m13:55:01.750583 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:55:01.755697 [info ] [MainThread]: 
[0m13:55:01.756972 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:55:01.756972 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:55:01.775141 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m13:55:01.777726 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m13:55:01.805972 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m13:55:01.814840 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m13:55:01.814840 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:55:02.590644 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e45-5d66-139d-8e0b-408e7783e223) - Created
[0m13:55:04.170100 [debug] [ThreadPool]: SQL status: OK in 2.360 seconds
[0m13:55:04.180693 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e45-5d66-139d-8e0b-408e7783e223, command-id=01f08e45-5d85-1e28-a514-273b007d3cec) - Closing
[0m13:55:04.180693 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m13:55:04.182700 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e45-5d66-139d-8e0b-408e7783e223) - Closing
[0m13:55:04.402067 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m13:55:04.403227 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m13:55:04.410525 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m13:55:04.411054 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m13:55:04.411054 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:55:05.003353 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e45-5ed6-1460-90cd-7b09d1e95bcd) - Created
[0m13:55:05.707632 [debug] [ThreadPool]: SQL status: OK in 1.300 seconds
[0m13:55:05.713248 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e45-5ed6-1460-90cd-7b09d1e95bcd, command-id=01f08e45-5eef-1a06-b192-1bb144dc8fa4) - Closing
[0m13:55:05.714299 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m13:55:05.714882 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e45-5ed6-1460-90cd-7b09d1e95bcd) - Closing
[0m13:55:05.880097 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m13:55:05.880097 [info ] [Thread-3 (]: 1 of 4 START test not_null_bronze_customer_customer_id ......................... [RUN]
[0m13:55:05.885129 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352) - Creating connection
[0m13:55:05.887157 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352'
[0m13:55:05.887157 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m13:55:05.941053 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m13:55:05.941053 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m13:55:05.972650 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m13:55:05.976172 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m13:55:05.976172 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from `dbt-project`.`default`.`bronze_customer`
where customer_id is null



  
  
      
    ) dbt_internal_test
[0m13:55:05.976172 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:55:06.550197 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-5fc0-1f88-ab65-ef4b5d37361e) - Created
[0m13:55:07.104016 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from `dbt-project`.`default`.`bronze_customer`
where customer_id is null



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f08e45-5fda-172d-abe4-c346e1be3918
[0m13:55:07.115123 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352: Close
[0m13:55:07.115123 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-5fc0-1f88-ab65-ef4b5d37361e) - Closing
[0m13:55:07.289488 [debug] [Thread-3 (]: Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m13:55:07.289488 [error] [Thread-3 (]: 1 of 4 ERROR not_null_bronze_customer_customer_id .............................. [[31mERROR[0m in 1.41s]
[0m13:55:07.289488 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m13:55:07.289488 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:55:07.289488 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352' to be skipped because of status 'error'.  Reason: Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql.
[0m13:55:07.289488 [info ] [Thread-3 (]: 2 of 4 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m13:55:07.289488 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m13:55:07.301985 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m13:55:07.305464 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:55:07.315440 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:55:07.316125 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:55:07.326061 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:55:07.330671 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m13:55:07.330671 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m13:55:07.330671 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:55:07.922694 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-6093-15b4-8515-9ef09c85b1e0) - Created
[0m13:55:09.524452 [debug] [Thread-3 (]: SQL status: OK in 2.190 seconds
[0m13:55:09.529253 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e45-6093-15b4-8515-9ef09c85b1e0, command-id=01f08e45-60ab-10f8-8795-705ac9c86f06) - Closing
[0m13:55:09.536611 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m13:55:09.536611 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-6093-15b4-8515-9ef09c85b1e0) - Closing
[0m13:55:09.719738 [info ] [Thread-3 (]: 2 of 4 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.42s]
[0m13:55:09.722609 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m13:55:09.724526 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m13:55:09.724526 [info ] [Thread-3 (]: 3 of 4 START test unique_bronze_customer_customer_id ........................... [RUN]
[0m13:55:09.724526 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa) - Creating connection
[0m13:55:09.724526 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa'
[0m13:55:09.724526 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m13:55:09.743766 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m13:55:09.745243 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m13:55:09.759639 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m13:55:09.763675 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m13:55:09.766306 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_id is not null
group by customer_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:55:09.767473 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:55:10.361103 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-6207-1c04-be8d-db391b23f987) - Created
[0m13:55:10.753239 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_id is not null
group by customer_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [TABLE_OR_VIEW_NOT_FOUND] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f08e45-621f-1afa-8512-b9ade3eb025e
[0m13:55:10.763464 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa: Close
[0m13:55:10.764680 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-6207-1c04-be8d-db391b23f987) - Closing
[0m13:55:10.956160 [debug] [Thread-3 (]: Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m13:55:10.956160 [error] [Thread-3 (]: 3 of 4 ERROR unique_bronze_customer_customer_id ................................ [[31mERROR[0m in 1.23s]
[0m13:55:10.956160 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m13:55:10.956160 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m13:55:10.956160 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa' to be skipped because of status 'error'.  Reason: Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql.
[0m13:55:10.956160 [info ] [Thread-3 (]: 4 of 4 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m13:55:10.956160 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m13:55:10.956160 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m13:55:10.956160 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m13:55:10.976616 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:55:10.979182 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m13:55:10.993071 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:55:10.993071 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m13:55:10.993071 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m13:55:11.001701 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m13:55:11.573577 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-62c0-1f7b-950a-65d7f6571aaf) - Created
[0m13:55:12.801183 [debug] [Thread-3 (]: SQL status: OK in 1.800 seconds
[0m13:55:12.807520 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e45-62c0-1f7b-950a-65d7f6571aaf, command-id=01f08e45-62d8-160e-a71b-89888145007a) - Closing
[0m13:55:12.809527 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m13:55:12.809527 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e45-62c0-1f7b-950a-65d7f6571aaf) - Closing
[0m13:55:12.984097 [info ] [Thread-3 (]: 4 of 4 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 2.03s]
[0m13:55:12.986581 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m13:55:12.986581 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:55:12.986581 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:55:12.986581 [info ] [MainThread]: 
[0m13:55:12.986581 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 11.23 seconds (11.23s).
[0m13:55:12.996977 [debug] [MainThread]: Command end result
[0m13:55:13.227515 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m13:55:13.231454 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m13:55:13.242397 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m13:55:13.242397 [info ] [MainThread]: 
[0m13:55:13.245484 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m13:55:13.246243 [info ] [MainThread]: 
[0m13:55:13.246243 [error] [MainThread]: [31mFailure in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)[0m
[0m13:55:13.246243 [error] [MainThread]:   Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 17 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m13:55:13.246243 [info ] [MainThread]: 
[0m13:55:13.253987 [info ] [MainThread]:   compiled code at target\compiled\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m13:55:13.253987 [info ] [MainThread]: 
[0m13:55:13.253987 [error] [MainThread]: [31mFailure in test unique_bronze_customer_customer_id (models\bronze\properties.yml)[0m
[0m13:55:13.253987 [error] [MainThread]:   Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [TABLE_OR_VIEW_NOT_FOUND] The table or view `dbt-project`.`default`.`bronze_customer` cannot be found. Verify the spelling and correctness of the schema and catalog.
  If you did not qualify the name with a schema, verify the current_schema() output, or qualify the name with the correct schema and catalog.
  To tolerate the error on drop use DROP VIEW IF EXISTS or DROP TABLE IF EXISTS. SQLSTATE: 42P01; line 18 pos 5
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m13:55:13.253987 [info ] [MainThread]: 
[0m13:55:13.253987 [info ] [MainThread]:   compiled code at target\compiled\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m13:55:13.253987 [info ] [MainThread]: 
[0m13:55:13.261517 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=4
[0m13:55:13.261517 [debug] [MainThread]: Command `dbt test` failed at 13:55:13.261517 after 16.39 seconds
[0m13:55:13.261517 [debug] [MainThread]: Flushing usage events
[0m13:59:38.569455 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:59:38.711613 | 2387daab-3c3b-457f-8c18-f9d843124eaa ==============================
[0m13:59:38.711613 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:59:38.715653 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt ', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m13:59:39.277974 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:59:39.282683 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m13:59:39.286443 [debug] [MainThread]: Command `cli deps` succeeded at 13:59:39.284692 after 0.85 seconds
[0m13:59:39.286443 [debug] [MainThread]: Flushing usage events
[0m14:19:01.322106 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:19:01.447556 | 8358e513-c2fb-4eb6-9aa7-d8c49bc09155 ==============================
[0m14:19:01.447556 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:19:01.447556 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:19:03.495736 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:19:03.495736 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:19:03.504645 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:19:05.632018 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:19:06.875962 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:19:07.483546 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:19:07.483546 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:19:08.009049 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:19:08.017960 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:19:08.040481 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 686 macros
[0m14:19:08.044570 [info ] [MainThread]: 
[0m14:19:08.049858 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:19:08.051131 [info ] [MainThread]: 
[0m14:19:08.053402 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:19:08.053946 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:19:08.076009 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:19:08.076551 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:19:08.077089 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:19:08.077650 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:19:08.077650 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:11.921354 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-bd16-1d70-b1d0-6faab85c30db) - Created
[0m14:20:13.641708 [debug] [ThreadPool]: SQL status: OK in 65.560 seconds
[0m14:20:13.645545 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-bd16-1d70-b1d0-6faab85c30db, command-id=01f08e48-e144-157d-8d38-a7468924bf6b) - Closing
[0m14:20:13.645545 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:20:13.645545 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-bd16-1d70-b1d0-6faab85c30db) - Closing
[0m14:20:13.815903 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:20:13.815903 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:20:13.815903 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:20:13.815903 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:20:13.815903 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:14.452099 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e287-1728-8814-e1fae833dffd) - Created
[0m14:20:14.723489 [debug] [ThreadPool]: SQL status: OK in 0.910 seconds
[0m14:20:14.730448 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-e287-1728-8814-e1fae833dffd, command-id=01f08e48-e29f-115f-a170-1148780eb575) - Closing
[0m14:20:14.730448 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:20:14.730448 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e287-1728-8814-e1fae833dffd) - Closing
[0m14:20:14.932663 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:20:14.932663 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:20:14.974267 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:20:14.974267 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:20:14.976278 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:15.615515 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e338-1dc0-9e4e-8f26bc28c0ef) - Created
[0m14:20:19.051425 [debug] [ThreadPool]: SQL status: OK in 4.080 seconds
[0m14:20:19.063585 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-e338-1dc0-9e4e-8f26bc28c0ef, command-id=01f08e48-e352-1908-a0a2-f842edfc79f0) - Closing
[0m14:20:19.065605 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:20:19.065605 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e338-1dc0-9e4e-8f26bc28c0ef) - Closing
[0m14:20:19.235100 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:20:19.241766 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:20:19.245798 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:20:19.249023 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:20:19.250132 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:19.852189 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e5be-1094-8c30-5cec345380d3) - Created
[0m14:20:20.785341 [debug] [ThreadPool]: SQL status: OK in 1.540 seconds
[0m14:20:20.787347 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-e5be-1094-8c30-5cec345380d3, command-id=01f08e48-e5d8-16bc-b52b-02384e7f2435) - Closing
[0m14:20:20.787347 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:20:20.787347 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-e5be-1094-8c30-5cec345380d3) - Closing
[0m14:20:20.983714 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:20:20.983714 [info ] [Thread-5 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m14:20:20.983714 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:20:20.983714 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:20:20.983714 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:20:21.006937 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:20:21.011558 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:20:21.060724 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:20:21.064768 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:20:21.202524 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:20:21.202524 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:20:21.202524 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:20:21.208639 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:21.817561 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-e6ea-1c4e-b099-3363dcdf090d) - Created
[0m14:20:30.778309 [debug] [Thread-5 (]: SQL status: OK in 9.560 seconds
[0m14:20:30.779469 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-e6ea-1c4e-b099-3363dcdf090d, command-id=01f08e48-e704-1b3d-b97a-366b1539359b) - Closing
[0m14:20:31.052400 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:31.110874 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:20:31.126058 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-e6ea-1c4e-b099-3363dcdf090d) - Closing
[0m14:20:31.290479 [info ] [Thread-5 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 10.30s]
[0m14:20:31.290479 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:20:31.295107 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:20:31.295107 [info ] [Thread-5 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:20:31.301992 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:20:31.304816 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:20:31.304816 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:20:31.314142 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:20:31.320960 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:20:31.351986 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:20:31.360035 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:20:31.376003 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:20:31.376963 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:20:31.376963 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:20:31.376963 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:32.048952 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ed05-1bc4-b817-e6de8b6d2757) - Created
[0m14:20:33.004672 [debug] [Thread-5 (]: SQL status: OK in 1.630 seconds
[0m14:20:33.013933 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-ed05-1bc4-b817-e6de8b6d2757, command-id=01f08e48-ed1f-11a1-aa60-e4e6b00a4d08) - Closing
[0m14:20:33.016620 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:33.019885 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:20:33.019885 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ed05-1bc4-b817-e6de8b6d2757) - Closing
[0m14:20:33.204808 [info ] [Thread-5 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.91s]
[0m14:20:33.204808 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:20:33.213098 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:20:33.216501 [info ] [Thread-5 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:20:33.216501 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:20:33.222243 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:20:33.222243 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:20:33.238422 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:20:33.238422 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:20:33.249398 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:20:33.255640 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:20:33.265716 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:20:33.270130 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:20:33.271870 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:34.066250 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ee3a-119d-9317-fa170d705a0b) - Created
[0m14:20:37.215009 [debug] [Thread-5 (]: SQL status: OK in 3.940 seconds
[0m14:20:37.215009 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-ee3a-119d-9317-fa170d705a0b, command-id=01f08e48-ee51-11c7-80d5-f5b2044585a6) - Closing
[0m14:20:37.234041 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:37.238075 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:20:37.241386 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ee3a-119d-9317-fa170d705a0b) - Closing
[0m14:20:37.442475 [info ] [Thread-5 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 4.23s]
[0m14:20:37.446836 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:20:37.448846 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:20:37.448846 [info ] [Thread-5 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m14:20:37.450946 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:20:37.450946 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:20:37.450946 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:20:37.467752 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:20:37.469154 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:20:37.469154 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:20:37.477486 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:20:37.481435 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:20:37.483446 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:20:37.483446 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:20:37.488323 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:38.646837 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f0e9-131d-8f39-b6b8b56bccaa) - Created
[0m14:20:39.357370 [debug] [Thread-5 (]: SQL status: OK in 1.870 seconds
[0m14:20:39.359375 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-f0e9-131d-8f39-b6b8b56bccaa, command-id=01f08e48-f10d-1253-8aed-259f069cfb99) - Closing
[0m14:20:39.361384 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:39.365621 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:20:39.365621 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f0e9-131d-8f39-b6b8b56bccaa) - Closing
[0m14:20:39.579734 [info ] [Thread-5 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.13s]
[0m14:20:39.579734 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:20:39.584840 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:20:39.584840 [info ] [Thread-5 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m14:20:39.584840 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:20:39.584840 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:20:39.584840 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:20:39.603797 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:20:39.609903 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:20:39.617965 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:20:39.617965 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:20:39.617965 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:20:39.625986 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:20:39.627103 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:20:39.631622 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:40.699717 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f220-115d-b70d-5f7c6fa054bb) - Created
[0m14:20:41.437670 [debug] [Thread-5 (]: SQL status: OK in 1.810 seconds
[0m14:20:41.437670 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-f220-115d-b70d-5f7c6fa054bb, command-id=01f08e48-f246-1bbc-97a2-ba75c8084561) - Closing
[0m14:20:41.437670 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:41.437670 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:20:41.437670 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f220-115d-b70d-5f7c6fa054bb) - Closing
[0m14:20:41.687618 [info ] [Thread-5 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.10s]
[0m14:20:41.691397 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:20:41.691397 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:20:41.697502 [info ] [Thread-5 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m14:20:41.699555 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:20:41.701544 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:20:41.703241 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:20:41.712282 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:20:41.714211 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:20:41.719437 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:20:41.719437 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:20:41.728332 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:20:41.729645 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:20:41.729645 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:42.887713 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f36e-1896-82ac-440d7f1ca8b9) - Created
[0m14:20:43.263082 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:20:43.389130 | 08095e70-3802-48bf-99c6-d7f84df8b8fc ==============================
[0m14:20:43.389130 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:20:43.389130 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:20:45.514523 [debug] [Thread-5 (]: SQL status: OK in 3.780 seconds
[0m14:20:45.514523 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-f36e-1896-82ac-440d7f1ca8b9, command-id=01f08e48-f39b-1b4f-a02b-536e81dc67ba) - Closing
[0m14:20:45.514523 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:45.514523 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:20:45.514523 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-f36e-1896-82ac-440d7f1ca8b9) - Closing
[0m14:20:45.562876 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:20:45.562876 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:20:45.562876 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:20:45.700591 [info ] [Thread-5 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.00s]
[0m14:20:45.702606 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:20:45.717745 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:20:45.719755 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:20:45.722133 [info ] [MainThread]: 
[0m14:20:45.806280 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 1 minutes and 37.67 seconds (97.67s).
[0m14:20:45.866220 [debug] [MainThread]: Command end result
[0m14:20:46.288243 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:20:46.301305 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:20:46.369944 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:20:46.371697 [info ] [MainThread]: 
[0m14:20:46.446386 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:20:46.482456 [info ] [MainThread]: 
[0m14:20:46.524245 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m14:20:46.565442 [debug] [MainThread]: Command `dbt run` succeeded at 14:20:46.565442 after 105.38 seconds
[0m14:20:46.565442 [debug] [MainThread]: Flushing usage events
[0m14:20:48.719166 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:20:50.231671 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:20:50.681771 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:20:50.683456 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:20:51.040155 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:20:51.040155 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:20:51.062842 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 686 macros
[0m14:20:51.072056 [info ] [MainThread]: 
[0m14:20:51.072056 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:20:51.074075 [info ] [MainThread]: 
[0m14:20:51.076246 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:20:51.077027 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:20:51.100181 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:20:51.102201 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:20:51.102201 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:20:51.102201 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:20:51.102201 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:52.174872 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-f904-1162-9ced-ba68d34a0635) - Created
[0m14:20:52.428357 [debug] [ThreadPool]: SQL status: OK in 1.330 seconds
[0m14:20:52.428357 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-f904-1162-9ced-ba68d34a0635, command-id=01f08e48-f91e-1115-876b-149671c2441e) - Closing
[0m14:20:52.436059 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:20:52.436584 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-f904-1162-9ced-ba68d34a0635) - Closing
[0m14:20:52.644530 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:20:52.650008 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:20:52.650008 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:20:52.650008 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:20:52.652020 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:53.803817 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-f9f2-142d-8e9f-7b45fbf16de9) - Created
[0m14:20:54.088074 [debug] [ThreadPool]: SQL status: OK in 1.440 seconds
[0m14:20:54.089584 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-f9f2-142d-8e9f-7b45fbf16de9, command-id=01f08e48-fa15-196e-9e59-e7425c4600be) - Closing
[0m14:20:54.089584 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:20:54.094361 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-f9f2-142d-8e9f-7b45fbf16de9) - Closing
[0m14:20:54.522154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:20:54.526671 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:20:54.584571 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:20:54.584571 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:20:54.584571 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:55.411927 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-faf1-1d18-ba6b-3a656c66b6eb) - Created
[0m14:20:55.839324 [debug] [ThreadPool]: SQL status: OK in 1.250 seconds
[0m14:20:55.853115 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-faf1-1d18-ba6b-3a656c66b6eb, command-id=01f08e48-fb0a-1f8a-9a3e-144ab3abf72e) - Closing
[0m14:20:55.853115 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:20:55.853115 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-faf1-1d18-ba6b-3a656c66b6eb) - Closing
[0m14:20:56.020454 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:20:56.020454 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:20:56.033145 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:20:56.033145 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:20:56.036238 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:20:56.646980 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-fbae-1af6-b862-1392cc8f307f) - Created
[0m14:20:57.135778 [debug] [ThreadPool]: SQL status: OK in 1.100 seconds
[0m14:20:57.143362 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e48-fbae-1af6-b862-1392cc8f307f, command-id=01f08e48-fbc7-1ac1-b636-6a22ebb42a16) - Closing
[0m14:20:57.145386 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:20:57.145386 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e48-fbae-1af6-b862-1392cc8f307f) - Closing
[0m14:20:57.347761 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:20:57.347761 [info ] [Thread-5 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m14:20:57.352517 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:20:57.352517 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:20:57.352517 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:20:57.371530 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:20:57.372843 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:20:57.417485 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:20:57.417485 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:20:57.498596 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:20:57.498596 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:20:57.498596 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:20:57.498596 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:20:58.086102 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-fc8b-1b25-beb3-86660eb1ec0d) - Created
[0m14:20:59.945322 [debug] [Thread-5 (]: SQL status: OK in 2.450 seconds
[0m14:20:59.945322 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-fc8b-1b25-beb3-86660eb1ec0d, command-id=01f08e48-fca2-1dc9-9ab7-bfb7ddce6855) - Closing
[0m14:20:59.973971 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:20:59.994692 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:20:59.994692 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-fc8b-1b25-beb3-86660eb1ec0d) - Closing
[0m14:21:00.179872 [info ] [Thread-5 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 2.83s]
[0m14:21:00.182023 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:21:00.182023 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:21:00.182023 [info ] [Thread-5 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:21:00.185271 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:21:00.185271 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:21:00.187721 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:21:00.197048 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:21:00.199999 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:21:00.235275 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:21:00.269254 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:21:00.270762 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:21:00.272922 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:21:00.273450 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:21:00.274467 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:00.865481 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-fe32-17b1-bcf2-ee73d531361f) - Created
[0m14:21:01.426089 [debug] [Thread-5 (]: SQL status: OK in 1.150 seconds
[0m14:21:01.430316 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-fe32-17b1-bcf2-ee73d531361f, command-id=01f08e48-fe4a-1ae2-a0c5-b0b5545154c0) - Closing
[0m14:21:01.432071 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:01.434211 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:21:01.434211 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-fe32-17b1-bcf2-ee73d531361f) - Closing
[0m14:21:01.612452 [info ] [Thread-5 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 1.43s]
[0m14:21:01.612452 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:21:01.612452 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:21:01.612452 [info ] [Thread-5 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:21:01.612452 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:21:01.625609 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:21:01.629295 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:21:01.644028 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:21:01.649604 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:21:01.661587 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:21:01.670101 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:21:01.671496 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:21:01.674991 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:21:01.677435 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:02.249129 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ff06-1c8c-a15c-09c5c63c51b1) - Created
[0m14:21:03.940911 [debug] [Thread-5 (]: SQL status: OK in 2.250 seconds
[0m14:21:03.945105 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e48-ff06-1c8c-a15c-09c5c63c51b1, command-id=01f08e48-ff1d-17ac-a682-6225c367ebaf) - Closing
[0m14:21:03.948045 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:03.948045 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:21:03.948045 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e48-ff06-1c8c-a15c-09c5c63c51b1) - Closing
[0m14:21:04.110084 [info ] [Thread-5 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 2.50s]
[0m14:21:04.119820 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:21:04.123059 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:21:04.123059 [info ] [Thread-5 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m14:21:04.126935 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:21:04.130497 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:21:04.131508 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:21:04.139427 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:21:04.145194 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:21:04.151666 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:21:04.151666 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:21:04.151666 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:21:04.151666 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:21:04.160164 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:21:04.162176 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:04.719783 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0080-12d4-abdd-0cd54109165d) - Created
[0m14:21:05.365768 [debug] [Thread-5 (]: SQL status: OK in 1.210 seconds
[0m14:21:05.374150 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e49-0080-12d4-abdd-0cd54109165d, command-id=01f08e49-0097-102b-9e61-121fb339c514) - Closing
[0m14:21:05.376977 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:05.381116 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:21:05.381116 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0080-12d4-abdd-0cd54109165d) - Closing
[0m14:21:05.550916 [info ] [Thread-5 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.42s]
[0m14:21:05.551927 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:21:05.554325 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:21:05.554325 [info ] [Thread-5 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m14:21:05.559576 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:21:05.562631 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:21:05.564069 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:21:05.588056 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:21:05.589769 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:21:05.598947 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:21:05.598947 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:21:05.598947 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:21:05.598947 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:21:05.598947 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:21:05.598947 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:06.328272 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0173-1ea8-8f09-8852905d0e5e) - Created
[0m14:21:06.978990 [debug] [Thread-5 (]: SQL status: OK in 1.380 seconds
[0m14:21:06.982122 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e49-0173-1ea8-8f09-8852905d0e5e, command-id=01f08e49-018e-1850-8a98-ea040e2c3ff3) - Closing
[0m14:21:06.982122 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:06.982122 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:21:06.988621 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0173-1ea8-8f09-8852905d0e5e) - Closing
[0m14:21:07.168463 [info ] [Thread-5 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.61s]
[0m14:21:07.170475 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:21:07.172033 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:21:07.172033 [info ] [Thread-5 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m14:21:07.179322 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:21:07.182925 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:21:07.184566 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:21:07.204070 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:21:07.206244 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:21:07.217293 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:21:07.229495 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:21:07.231614 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:21:07.234903 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:21:07.234903 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:07.897937 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0264-1852-9627-17fd8ed6c7f7) - Created
[0m14:21:10.468483 [debug] [Thread-5 (]: SQL status: OK in 3.230 seconds
[0m14:21:10.470500 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e49-0264-1852-9627-17fd8ed6c7f7, command-id=01f08e49-027c-113e-9c2f-5bd1f7e4541f) - Closing
[0m14:21:10.470500 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:10.470500 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:21:10.470500 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e49-0264-1852-9627-17fd8ed6c7f7) - Closing
[0m14:21:10.645519 [info ] [Thread-5 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.47s]
[0m14:21:10.655688 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:21:10.660384 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:21:10.663397 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:21:10.663397 [info ] [MainThread]: 
[0m14:21:10.663397 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 19.59 seconds (19.59s).
[0m14:21:10.670325 [debug] [MainThread]: Command end result
[0m14:21:10.921438 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:21:10.929942 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:21:10.944038 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:21:10.949997 [info ] [MainThread]: 
[0m14:21:10.952015 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:21:10.952015 [info ] [MainThread]: 
[0m14:21:10.952015 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m14:21:10.958516 [debug] [MainThread]: Command `dbt run` succeeded at 14:21:10.952015 after 27.94 seconds
[0m14:21:10.959028 [debug] [MainThread]: Flushing usage events
[0m14:21:24.394425 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:21:24.545626 | b2791bdf-ddf5-419a-bde6-c8fd1dabdd32 ==============================
[0m14:21:24.545626 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:21:24.545626 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:21:26.769097 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:21:26.771105 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:21:26.771105 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:21:29.302734 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:21:30.702452 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:21:31.273357 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:21:31.276601 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:21:31.656779 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:21:31.663955 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:21:31.702413 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 686 macros
[0m14:21:31.704454 [info ] [MainThread]: 
[0m14:21:31.709027 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:21:31.714183 [info ] [MainThread]: 
[0m14:21:31.715055 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:21:31.715055 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:21:31.735244 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:21:31.737272 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:21:31.768409 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:21:31.768409 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:21:31.768409 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:33.091357 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-115d-1efc-8182-3ca79cddea1d) - Created
[0m14:21:33.502691 [debug] [ThreadPool]: SQL status: OK in 1.730 seconds
[0m14:21:33.524562 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e49-115d-1efc-8182-3ca79cddea1d, command-id=01f08e49-1181-1990-a9c2-ae9f20a30f63) - Closing
[0m14:21:33.527856 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:21:33.527856 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-115d-1efc-8182-3ca79cddea1d) - Closing
[0m14:21:33.703182 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:21:33.705197 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:21:33.711132 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:21:33.711132 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:21:33.711132 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:34.347209 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-1226-1573-8866-5b50e8cbf974) - Created
[0m14:21:34.907573 [debug] [ThreadPool]: SQL status: OK in 1.200 seconds
[0m14:21:34.916219 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e49-1226-1573-8866-5b50e8cbf974, command-id=01f08e49-1241-174b-8307-70afd06a23e7) - Closing
[0m14:21:34.917810 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:21:34.919358 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-1226-1573-8866-5b50e8cbf974) - Closing
[0m14:21:35.143564 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m14:21:35.155677 [info ] [Thread-3 (]: 1 of 4 START test not_null_bronze_customer_customer_id ......................... [RUN]
[0m14:21:35.162630 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352) - Creating connection
[0m14:21:35.162630 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352'
[0m14:21:35.162630 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m14:21:35.242489 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m14:21:35.248990 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m14:21:35.297432 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m14:21:35.305164 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"
[0m14:21:35.305164 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from `dbt-project`.`default`.`bronze_customer`
where customer_id is null



  
  
      
    ) dbt_internal_test
[0m14:21:35.308757 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:21:35.908071 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-1316-1185-bacc-1f9e6bc159ec) - Created
[0m14:21:36.449900 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_id
from `dbt-project`.`default`.`bronze_customer`
where customer_id is null



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f08e49-132d-16ea-b909-5199fc189c14
[0m14:21:36.449900 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352: Close
[0m14:21:36.449900 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-1316-1185-bacc-1f9e6bc159ec) - Closing
[0m14:21:36.644140 [debug] [Thread-3 (]: Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m14:21:36.644140 [error] [Thread-3 (]: 1 of 4 ERROR not_null_bronze_customer_customer_id .............................. [[31mERROR[0m in 1.49s]
[0m14:21:36.644140 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352
[0m14:21:36.651627 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:21:36.651627 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.not_null_bronze_customer_customer_id.b472f71352' to be skipped because of status 'error'.  Reason: Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql.
[0m14:21:36.651627 [info ] [Thread-3 (]: 2 of 4 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m14:21:36.657682 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m14:21:36.661736 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m14:21:36.661736 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:21:36.679287 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:21:36.684167 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:21:36.692983 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:21:36.700921 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:21:36.702941 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m14:21:36.702941 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:21:37.406580 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-13f9-1e38-955a-f3a8d057291d) - Created
[0m14:21:38.380629 [debug] [Thread-3 (]: SQL status: OK in 1.680 seconds
[0m14:21:38.394151 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-13f9-1e38-955a-f3a8d057291d, command-id=01f08e49-1412-1ae3-b207-056f5980a752) - Closing
[0m14:21:38.409294 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m14:21:38.411058 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-13f9-1e38-955a-f3a8d057291d) - Closing
[0m14:21:38.592228 [info ] [Thread-3 (]: 2 of 4 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.93s]
[0m14:21:38.592228 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:21:38.599575 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m14:21:38.601590 [info ] [Thread-3 (]: 3 of 4 START test unique_bronze_customer_customer_id ........................... [RUN]
[0m14:21:38.601590 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa) - Creating connection
[0m14:21:38.601590 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa'
[0m14:21:38.601590 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m14:21:38.642609 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m14:21:38.644635 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m14:21:38.668283 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m14:21:38.670833 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"
[0m14:21:38.672000 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_id is not null
group by customer_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:21:38.675839 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:21:39.325687 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-1521-1d5c-9e80-71522c283a09) - Created
[0m14:21:39.799503 [debug] [Thread-3 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_id is not null
group by customer_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:997)
	... 53 more
, operation-id=01f08e49-1537-1aac-8a9f-6edd091e0251
[0m14:21:39.807688 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa: Close
[0m14:21:39.809711 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-1521-1d5c-9e80-71522c283a09) - Closing
[0m14:21:39.981985 [debug] [Thread-3 (]: Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m14:21:39.981985 [error] [Thread-3 (]: 3 of 4 ERROR unique_bronze_customer_customer_id ................................ [[31mERROR[0m in 1.38s]
[0m14:21:39.981985 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa
[0m14:21:39.981985 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:21:39.981985 [info ] [Thread-3 (]: 4 of 4 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m14:21:39.981985 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.unique_bronze_customer_customer_id.eda88a83aa' to be skipped because of status 'error'.  Reason: Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql.
[0m14:21:39.991241 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m14:21:39.994587 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m14:21:39.994587 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:21:39.996887 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:21:39.996887 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:21:40.014702 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:21:40.019866 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:21:40.020212 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:21:40.022958 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:21:40.576394 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-15df-1817-8c12-62521f308d22) - Created
[0m14:21:41.213996 [debug] [Thread-3 (]: SQL status: OK in 1.190 seconds
[0m14:21:41.219988 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-15df-1817-8c12-62521f308d22, command-id=01f08e49-15f6-1595-a8eb-d84052d0f42c) - Closing
[0m14:21:41.219988 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m14:21:41.222535 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-15df-1817-8c12-62521f308d22) - Closing
[0m14:21:41.385790 [info ] [Thread-3 (]: 4 of 4 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.39s]
[0m14:21:41.391643 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:21:41.397344 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:21:41.399870 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:21:41.399870 [info ] [MainThread]: 
[0m14:21:41.399870 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 9.68 seconds (9.68s).
[0m14:21:41.405746 [debug] [MainThread]: Command end result
[0m14:21:41.670432 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:21:41.679907 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:21:41.695053 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:21:41.701833 [info ] [MainThread]: 
[0m14:21:41.703845 [info ] [MainThread]: [31mCompleted with 2 errors, 0 partial successes, and 0 warnings:[0m
[0m14:21:41.705858 [info ] [MainThread]: 
[0m14:21:41.705858 [error] [MainThread]: [31mFailure in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)[0m
[0m14:21:41.708789 [error] [MainThread]:   Database Error in test not_null_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 18 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m14:21:41.713285 [info ] [MainThread]: 
[0m14:21:41.716172 [info ] [MainThread]:   compiled code at target\compiled\dbt_eTl\models\bronze\properties.yml\not_null_bronze_customer_customer_id.sql
[0m14:21:41.716172 [info ] [MainThread]: 
[0m14:21:41.716172 [error] [MainThread]: [31mFailure in test unique_bronze_customer_customer_id (models\bronze\properties.yml)[0m
[0m14:21:41.716172 [error] [MainThread]:   Database Error in test unique_bronze_customer_customer_id (models\bronze\properties.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `customer_id` cannot be resolved. Did you mean one of the following? [`customer_sk`, `customer_code`, `gender`, `phone`, `email`]. SQLSTATE: 42703; line 19 pos 6
  compiled code at target\run\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m14:21:41.716172 [info ] [MainThread]: 
[0m14:21:41.716172 [info ] [MainThread]:   compiled code at target\compiled\dbt_eTl\models\bronze\properties.yml\unique_bronze_customer_customer_id.sql
[0m14:21:41.723994 [info ] [MainThread]: 
[0m14:21:41.726900 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=2 SKIP=0 NO-OP=0 TOTAL=4
[0m14:21:41.730991 [debug] [MainThread]: Command `dbt test` failed at 14:21:41.730991 after 17.46 seconds
[0m14:21:41.730991 [debug] [MainThread]: Flushing usage events
[0m14:23:59.974252 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:24:00.096943 | 1be8a8cd-31bd-42d7-a447-343f42875c87 ==============================
[0m14:24:00.096943 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:24:00.096943 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m14:24:02.417341 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:24:02.417341 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:24:02.422617 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:24:04.388877 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:24:05.183091 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:24:05.808742 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:24:05.808742 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:24:06.178368 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:24:06.186062 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:24:06.229930 [info ] [MainThread]: Found 6 models, 4 data tests, 6 sources, 686 macros
[0m14:24:06.229930 [info ] [MainThread]: 
[0m14:24:06.229930 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:06.229930 [info ] [MainThread]: 
[0m14:24:06.238198 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:24:06.241463 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:24:06.264170 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:24:06.264170 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:24:06.312626 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:24:06.322721 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:24:06.325193 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:07.041130 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-6d29-1cf3-9ddd-bdc8d8af10d2) - Created
[0m14:24:07.465588 [debug] [ThreadPool]: SQL status: OK in 1.140 seconds
[0m14:24:07.482230 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e49-6d29-1cf3-9ddd-bdc8d8af10d2, command-id=01f08e49-6d42-1160-8c1e-fce38ac0ed4d) - Closing
[0m14:24:07.483606 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:24:07.485362 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-6d29-1cf3-9ddd-bdc8d8af10d2) - Closing
[0m14:24:07.660516 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:24:07.664543 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:24:07.671005 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:24:07.674744 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:24:07.674744 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:08.351804 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-6df2-172a-b951-c80c47b30d1e) - Created
[0m14:24:08.806790 [debug] [ThreadPool]: SQL status: OK in 1.130 seconds
[0m14:24:08.814464 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e49-6df2-172a-b951-c80c47b30d1e, command-id=01f08e49-6e0b-1db1-b66a-5547313c7ff5) - Closing
[0m14:24:08.814464 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:24:08.814464 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e49-6df2-172a-b951-c80c47b30d1e) - Closing
[0m14:24:09.030460 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:24:09.032409 [info ] [Thread-3 (]: 1 of 4 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m14:24:09.041493 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m14:24:09.043519 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m14:24:09.043519 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:24:09.127488 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:24:09.131515 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:24:09.192847 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:24:09.192847 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:24:09.192847 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m14:24:09.197564 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:24:09.912609 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-6ee1-14a0-98c8-bc07995c081c) - Created
[0m14:24:10.623839 [debug] [Thread-3 (]: SQL status: OK in 1.430 seconds
[0m14:24:10.629989 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-6ee1-14a0-98c8-bc07995c081c, command-id=01f08e49-6ef8-1f47-bad7-7cf1547d0b7c) - Closing
[0m14:24:10.634236 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m14:24:10.634236 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-6ee1-14a0-98c8-bc07995c081c) - Closing
[0m14:24:10.810035 [info ] [Thread-3 (]: 1 of 4 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.78s]
[0m14:24:10.810035 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:24:10.814284 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:24:10.814284 [info ] [Thread-3 (]: 2 of 4 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m14:24:10.816296 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m14:24:10.816296 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m14:24:10.816296 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:24:10.828453 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:24:10.828453 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:24:10.845009 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:24:10.845009 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:24:10.845009 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m14:24:10.845009 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:24:13.655224 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-711c-189f-8738-7b4f447f3b29) - Created
[0m14:24:13.991859 [debug] [Thread-3 (]: SQL status: OK in 3.150 seconds
[0m14:24:13.993380 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-711c-189f-8738-7b4f447f3b29, command-id=01f08e49-7134-1fed-a15f-ca3433488df4) - Closing
[0m14:24:13.993380 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m14:24:14.002562 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-711c-189f-8738-7b4f447f3b29) - Closing
[0m14:24:14.172554 [info ] [Thread-3 (]: 2 of 4 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 3.36s]
[0m14:24:14.172554 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:24:14.181073 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:24:14.183090 [info ] [Thread-3 (]: 3 of 4 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m14:24:14.183090 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m14:24:14.187521 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m14:24:14.190060 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:24:14.213433 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:24:14.224331 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:24:14.238998 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:24:14.243112 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:24:14.243112 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:24:14.251373 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:24:14.915308 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-71dd-1691-a95c-63dffa27d8bb) - Created
[0m14:24:16.034276 [debug] [Thread-3 (]: SQL status: OK in 1.780 seconds
[0m14:24:16.041966 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-71dd-1691-a95c-63dffa27d8bb, command-id=01f08e49-71f7-1721-937a-5868894188a2) - Closing
[0m14:24:16.041966 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m14:24:16.041966 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-71dd-1691-a95c-63dffa27d8bb) - Closing
[0m14:24:16.230495 [info ] [Thread-3 (]: 3 of 4 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 2.04s]
[0m14:24:16.230495 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:24:16.230495 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:24:16.230495 [info ] [Thread-3 (]: 4 of 4 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m14:24:16.243516 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m14:24:16.244786 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m14:24:16.246799 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:24:16.275325 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:24:16.278157 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:24:16.294399 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:24:16.301402 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:24:16.302238 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:24:16.307534 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m14:24:16.911071 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-730e-10ea-b086-1f00fd887683) - Created
[0m14:24:17.195420 [debug] [Thread-3 (]: SQL status: OK in 0.890 seconds
[0m14:24:17.204240 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e49-730e-10ea-b086-1f00fd887683, command-id=01f08e49-7324-1658-8ea7-a37db895840f) - Closing
[0m14:24:17.204240 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m14:24:17.204240 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e49-730e-10ea-b086-1f00fd887683) - Closing
[0m14:24:17.379927 [info ] [Thread-3 (]: 4 of 4 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.14s]
[0m14:24:17.381943 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:24:17.386161 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:24:17.388176 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:24:17.392209 [info ] [MainThread]: 
[0m14:24:17.394228 [info ] [MainThread]: Finished running 4 data tests in 0 hours 0 minutes and 11.16 seconds (11.16s).
[0m14:24:17.400642 [debug] [MainThread]: Command end result
[0m14:24:17.696012 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:24:17.708514 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:24:17.723410 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:24:17.728964 [info ] [MainThread]: 
[0m14:24:17.728964 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:24:17.731330 [info ] [MainThread]: 
[0m14:24:17.733434 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=4
[0m14:24:17.735449 [debug] [MainThread]: Command `dbt test` succeeded at 14:24:17.735449 after 17.87 seconds
[0m14:24:17.735449 [debug] [MainThread]: Flushing usage events
[0m15:33:30.363638 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:33:30.426878 | b217b36f-f5ba-436e-b0d7-11b1cee0330e ==============================
[0m15:33:30.426878 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:33:30.426878 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt ', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m15:33:30.618074 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:33:30.618074 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m15:33:30.626376 [debug] [MainThread]: Command `cli deps` succeeded at 15:33:30.626376 after 0.33 seconds
[0m15:33:30.627548 [debug] [MainThread]: Flushing usage events
[0m15:36:39.343097 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:36:39.422619 | 2eec270a-1634-4b7d-8986-13609eca6246 ==============================
[0m15:36:39.422619 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:36:39.435314 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'None', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m15:36:40.431810 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:36:40.431810 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:36:40.431810 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:36:41.492849 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:36:41.976887 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m15:36:42.245807 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:36:42.246883 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:36:42.398485 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:36:42.405080 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:36:42.429833 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m15:36:42.429833 [info ] [MainThread]: 
[0m15:36:42.429833 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:36:42.438358 [info ] [MainThread]: 
[0m15:36:42.438358 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:36:42.438358 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:36:42.446289 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m15:36:42.446289 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m15:36:42.464659 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m15:36:42.464659 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m15:36:42.464659 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:43.894165 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e53-9177-19b7-9a25-76d8c2c314ee) - Created
[0m15:37:01.097220 [debug] [ThreadPool]: SQL status: OK in 18.630 seconds
[0m15:37:01.117740 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e53-9177-19b7-9a25-76d8c2c314ee, command-id=01f08e53-91ef-16db-bee3-db8ddd787f5a) - Closing
[0m15:37:01.358235 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m15:37:01.358235 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e53-9177-19b7-9a25-76d8c2c314ee) - Closing
[0m15:37:01.535485 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m15:37:01.537485 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m15:37:01.539492 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m15:37:01.540898 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m15:37:01.541905 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:37:02.116670 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e53-9c88-1732-a4b9-c912fcc19bee) - Created
[0m15:37:03.380274 [debug] [ThreadPool]: SQL status: OK in 1.840 seconds
[0m15:37:03.383241 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e53-9c88-1732-a4b9-c912fcc19bee, command-id=01f08e53-9ca2-1478-8c85-d60d32d45243) - Closing
[0m15:37:03.384326 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m15:37:03.384927 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e53-9c88-1732-a4b9-c912fcc19bee) - Closing
[0m15:37:03.569266 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee
[0m15:37:03.570327 [info ] [Thread-3 (]: 1 of 5 START test accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan  [RUN]
[0m15:37:03.579339 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee) - Creating connection
[0m15:37:03.581347 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee'
[0m15:37:03.582350 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee
[0m15:37:03.655202 [debug] [Thread-3 (]: Compilation Error in test accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:37:03.658300 [error] [Thread-3 (]: 1 of 5 ERROR accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan  [[31mERROR[0m in 0.09s]
[0m15:37:03.660284 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee
[0m15:37:03.661284 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:37:03.662296 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.9fb61e9aee' to be skipped because of status 'error'.  Reason: Compilation Error in test accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:37:03.664198 [info ] [Thread-3 (]: 2 of 5 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m15:37:03.666509 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m15:37:03.667515 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m15:37:03.668511 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:37:03.694661 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:37:03.695660 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:37:03.731459 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:37:03.733466 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:37:03.733466 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m15:37:03.734476 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:37:04.319156 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-9dd8-1163-ab40-9a70b2f52979) - Created
[0m15:37:08.217081 [debug] [Thread-3 (]: SQL status: OK in 4.480 seconds
[0m15:37:08.221752 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e53-9dd8-1163-ab40-9a70b2f52979, command-id=01f08e53-9df2-1abd-b4e4-22241adffc24) - Closing
[0m15:37:08.238703 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m15:37:08.238703 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-9dd8-1163-ab40-9a70b2f52979) - Closing
[0m15:37:08.408639 [info ] [Thread-3 (]: 2 of 5 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 4.73s]
[0m15:37:08.408639 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:37:08.412078 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:37:08.412078 [info ] [Thread-3 (]: 3 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:37:08.415322 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:37:08.415322 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:37:08.415322 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:37:08.428112 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:37:08.438729 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:37:08.438729 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:37:08.438729 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:37:08.438729 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:37:08.438729 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:37:09.016040 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a0a9-124b-93e5-1f32d58caedb) - Created
[0m15:37:10.290426 [debug] [Thread-3 (]: SQL status: OK in 1.850 seconds
[0m15:37:10.290426 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e53-a0a9-124b-93e5-1f32d58caedb, command-id=01f08e53-a0bf-10ec-beef-5bea10e9605b) - Closing
[0m15:37:10.290426 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:37:10.290426 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a0a9-124b-93e5-1f32d58caedb) - Closing
[0m15:37:10.450205 [info ] [Thread-3 (]: 3 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.03s]
[0m15:37:10.450205 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:37:10.450205 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:37:10.450205 [info ] [Thread-3 (]: 4 of 5 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m15:37:10.450205 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m15:37:10.465985 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m15:37:10.465985 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:37:10.481885 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:37:10.483159 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:37:10.490507 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:37:10.490507 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:37:10.490507 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:37:10.490507 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:37:11.031202 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a1db-1a9a-a5f3-df73db1c9b26) - Created
[0m15:37:12.053071 [debug] [Thread-3 (]: SQL status: OK in 1.560 seconds
[0m15:37:12.055079 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e53-a1db-1a9a-a5f3-df73db1c9b26, command-id=01f08e53-a1f3-1354-8bb1-cf649dbc0a3a) - Closing
[0m15:37:12.055079 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m15:37:12.055079 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a1db-1a9a-a5f3-df73db1c9b26) - Closing
[0m15:37:12.228380 [info ] [Thread-3 (]: 4 of 5 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.78s]
[0m15:37:12.229438 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:37:12.229438 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:37:12.229438 [info ] [Thread-3 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:37:12.230868 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:37:12.230868 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:37:12.230868 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:37:12.240072 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:37:12.242068 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:37:12.338384 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:37:12.338384 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:37:12.338384 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:37:12.338384 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:37:12.890576 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a2f4-1e06-b935-ac136b4452c1) - Created
[0m15:37:13.647408 [debug] [Thread-3 (]: SQL status: OK in 1.310 seconds
[0m15:37:13.647408 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e53-a2f4-1e06-b935-ac136b4452c1, command-id=01f08e53-a30e-1a67-891a-fed4b2316f0b) - Closing
[0m15:37:13.647408 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:37:13.647408 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e53-a2f4-1e06-b935-ac136b4452c1) - Closing
[0m15:37:13.823437 [info ] [Thread-3 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.59s]
[0m15:37:13.823437 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:37:13.823437 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:37:13.823437 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:37:13.823437 [info ] [MainThread]: 
[0m15:37:13.823437 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 31.39 seconds (31.39s).
[0m15:37:13.823437 [debug] [MainThread]: Command end result
[0m15:37:13.874675 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:37:13.874675 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:37:13.889823 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m15:37:13.890488 [info ] [MainThread]: 
[0m15:37:13.890488 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:37:13.892497 [info ] [MainThread]: 
[0m15:37:13.892497 [error] [MainThread]: [31mFailure in test accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)[0m
[0m15:37:13.892497 [error] [MainThread]:   Compilation Error in test accepted_bronze_store_store_sk__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:37:13.892497 [info ] [MainThread]: 
[0m15:37:13.892497 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m15:37:13.892497 [debug] [MainThread]: Command `dbt test` failed at 15:37:13.892497 after 34.60 seconds
[0m15:37:13.897220 [debug] [MainThread]: Flushing usage events
[0m15:43:47.847852 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:43:47.918119 | 15d355f5-97a6-438d-a54a-542f5ad0397c ==============================
[0m15:43:47.918119 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:43:47.918119 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m15:43:49.193630 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:43:49.193630 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:43:49.193630 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:43:50.556247 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:43:51.047450 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m15:43:51.243022 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:43:51.243022 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:43:51.438130 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:43:51.442617 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:43:51.470144 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m15:43:51.470144 [info ] [MainThread]: 
[0m15:43:51.473434 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:43:51.473434 [info ] [MainThread]: 
[0m15:43:51.475172 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:43:51.475172 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:43:51.481859 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m15:43:51.481859 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m15:43:51.501750 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m15:43:51.501750 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m15:43:51.501750 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:52.151785 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e54-90f1-1cda-b194-b385942f9a50) - Created
[0m15:43:52.715605 [debug] [ThreadPool]: SQL status: OK in 1.210 seconds
[0m15:43:52.731439 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e54-90f1-1cda-b194-b385942f9a50, command-id=01f08e54-910a-17af-8681-852dbc4c3179) - Closing
[0m15:43:52.731439 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m15:43:52.731439 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e54-90f1-1cda-b194-b385942f9a50) - Closing
[0m15:43:52.905467 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m15:43:52.905467 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m15:43:52.905467 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m15:43:52.905467 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m15:43:52.905467 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:43:53.421249 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e54-91b3-183e-ac83-f672939684a4) - Created
[0m15:43:53.974694 [debug] [ThreadPool]: SQL status: OK in 1.070 seconds
[0m15:43:53.974694 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e54-91b3-183e-ac83-f672939684a4, command-id=01f08e54-91ca-13e4-9945-719d39e0e3f4) - Closing
[0m15:43:53.974694 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m15:43:53.974694 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e54-91b3-183e-ac83-f672939684a4) - Closing
[0m15:43:54.172902 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434
[0m15:43:54.173440 [info ] [Thread-3 (]: 1 of 5 START test accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan  [RUN]
[0m15:43:54.178320 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434) - Creating connection
[0m15:43:54.178902 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434'
[0m15:43:54.178902 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434
[0m15:43:54.211266 [debug] [Thread-3 (]: Compilation Error in test accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:43:54.211876 [error] [Thread-3 (]: 1 of 5 ERROR accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan  [[31mERROR[0m in 0.04s]
[0m15:43:54.213070 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434
[0m15:43:54.213711 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:43:54.213711 [info ] [Thread-3 (]: 2 of 5 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m15:43:54.214454 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan.c326c3e434' to be skipped because of status 'error'.  Reason: Compilation Error in test accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:43:54.215670 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m15:43:54.216937 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m15:43:54.217614 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:43:54.228678 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:43:54.229668 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:43:54.250343 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:43:54.250343 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:43:54.250343 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m15:43:54.250343 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:43:54.776792 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-9282-1fc7-9a94-877593822a5a) - Created
[0m15:43:55.102114 [debug] [Thread-3 (]: SQL status: OK in 0.850 seconds
[0m15:43:55.117838 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e54-9282-1fc7-9a94-877593822a5a, command-id=01f08e54-9299-1301-9b87-857269bc20f2) - Closing
[0m15:43:55.117838 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m15:43:55.117838 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-9282-1fc7-9a94-877593822a5a) - Closing
[0m15:43:55.302568 [info ] [Thread-3 (]: 2 of 5 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.07s]
[0m15:43:55.302568 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:43:55.305626 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:43:55.305626 [info ] [Thread-3 (]: 3 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:43:55.307641 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:43:55.310067 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:43:55.310578 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:43:55.315640 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:43:55.315640 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:43:55.315640 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:43:55.315640 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:43:55.315640 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:43:55.315640 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:43:55.846715 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-9325-1d45-a8d5-c8f26a840ad0) - Created
[0m15:43:56.167657 [debug] [Thread-3 (]: SQL status: OK in 0.850 seconds
[0m15:43:56.167657 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e54-9325-1d45-a8d5-c8f26a840ad0, command-id=01f08e54-933d-1de0-be64-93fa9adb95d3) - Closing
[0m15:43:56.170684 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:43:56.170684 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-9325-1d45-a8d5-c8f26a840ad0) - Closing
[0m15:43:56.339886 [info ] [Thread-3 (]: 3 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.03s]
[0m15:43:56.339886 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:43:56.339886 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:43:56.339886 [info ] [Thread-3 (]: 4 of 5 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m15:43:56.339886 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m15:43:56.339886 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m15:43:56.339886 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:43:56.362275 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:43:56.365284 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:43:56.366353 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:43:56.366353 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:43:56.366353 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:43:56.366353 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:43:56.901343 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-93c4-1fdd-bdb8-da8847eb340c) - Created
[0m15:43:57.242698 [debug] [Thread-3 (]: SQL status: OK in 0.880 seconds
[0m15:43:57.246204 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e54-93c4-1fdd-bdb8-da8847eb340c, command-id=01f08e54-93dd-18de-87c1-23911fe8baf6) - Closing
[0m15:43:57.246204 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m15:43:57.246204 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-93c4-1fdd-bdb8-da8847eb340c) - Closing
[0m15:43:57.425941 [info ] [Thread-3 (]: 4 of 5 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.09s]
[0m15:43:57.425941 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:43:57.425941 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:43:57.425941 [info ] [Thread-3 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:43:57.437032 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:43:57.438916 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:43:57.440017 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:43:57.447123 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:43:57.447123 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:43:57.543822 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:43:57.545280 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:43:57.545280 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:43:57.546560 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:43:58.060722 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-947a-118d-842e-0c6c48b51dd9) - Created
[0m15:43:58.454882 [debug] [Thread-3 (]: SQL status: OK in 0.910 seconds
[0m15:43:58.454882 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e54-947a-118d-842e-0c6c48b51dd9, command-id=01f08e54-9490-187b-bffd-a71b582beae6) - Closing
[0m15:43:58.454882 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:43:58.454882 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e54-947a-118d-842e-0c6c48b51dd9) - Closing
[0m15:43:58.630845 [info ] [Thread-3 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.20s]
[0m15:43:58.630845 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:43:58.634622 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:43:58.638408 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:43:58.638408 [info ] [MainThread]: 
[0m15:43:58.638408 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 7.16 seconds (7.16s).
[0m15:43:58.641943 [debug] [MainThread]: Command end result
[0m15:43:58.663780 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:43:58.678405 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:43:58.678405 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m15:43:58.678405 [info ] [MainThread]: 
[0m15:43:58.678405 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:43:58.678405 [info ] [MainThread]: 
[0m15:43:58.678405 [error] [MainThread]: [31mFailure in test accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)[0m
[0m15:43:58.678405 [error] [MainThread]:   Compilation Error in test accepted_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Los_Angeles__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:43:58.692185 [info ] [MainThread]: 
[0m15:43:58.692687 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m15:43:58.693497 [debug] [MainThread]: Command `dbt test` failed at 15:43:58.693497 after 10.91 seconds
[0m15:43:58.693497 [debug] [MainThread]: Flushing usage events
[0m15:48:54.773987 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:48:54.838719 | af41b3b1-812d-4664-a860-2addc5619e39 ==============================
[0m15:48:54.838719 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:48:54.853589 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m15:48:55.708474 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:48:55.708474 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:48:55.708474 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:48:56.514854 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:48:56.833656 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m15:48:56.993716 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:48:56.993716 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:48:57.118673 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:48:57.135464 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:48:57.150721 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m15:48:57.150721 [info ] [MainThread]: 
[0m15:48:57.150721 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:48:57.150721 [info ] [MainThread]: 
[0m15:48:57.150721 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:48:57.150721 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:48:57.173219 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m15:48:57.174218 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m15:48:57.187217 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m15:48:57.187217 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m15:48:57.188216 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:48:58.354288 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-4768-176c-bda1-9f85f10f8340) - Created
[0m15:48:59.028023 [debug] [ThreadPool]: SQL status: OK in 1.840 seconds
[0m15:48:59.035025 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-4768-176c-bda1-9f85f10f8340, command-id=01f08e55-478b-19c3-b0a7-ca99a02ff136) - Closing
[0m15:48:59.035025 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m15:48:59.036020 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-4768-176c-bda1-9f85f10f8340) - Closing
[0m15:48:59.257993 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m15:48:59.261091 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m15:48:59.266130 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m15:48:59.266130 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m15:48:59.266130 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:49:00.635162 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-48bd-1e70-af18-bd5430842988) - Created
[0m15:49:01.120764 [debug] [ThreadPool]: SQL status: OK in 1.850 seconds
[0m15:49:01.138492 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-48bd-1e70-af18-bd5430842988, command-id=01f08e55-48eb-108d-b4a4-ef21e02495ac) - Closing
[0m15:49:01.139499 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m15:49:01.140496 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-48bd-1e70-af18-bd5430842988) - Closing
[0m15:49:01.384797 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:49:01.384797 [info ] [Thread-3 (]: 1 of 5 START test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m15:49:01.395489 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42) - Creating connection
[0m15:49:01.397494 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42'
[0m15:49:01.397494 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:49:01.416538 [debug] [Thread-3 (]: Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:49:01.417514 [error] [Thread-3 (]: 1 of 5 ERROR accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[31mERROR[0m in 0.03s]
[0m15:49:01.418459 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:49:01.419496 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:49:01.419496 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42' to be skipped because of status 'error'.  Reason: Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:49:01.419496 [info ] [Thread-3 (]: 2 of 5 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m15:49:01.419496 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m15:49:01.419496 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m15:49:01.419496 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:49:01.419496 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:49:01.419496 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:49:01.440238 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:49:01.440238 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:49:01.440238 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m15:49:01.451603 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:49:02.011189 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-49a1-1a3e-8dfd-fc6cb5573e60) - Created
[0m15:49:02.335440 [debug] [Thread-3 (]: SQL status: OK in 0.880 seconds
[0m15:49:02.338406 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-49a1-1a3e-8dfd-fc6cb5573e60, command-id=01f08e55-49ba-1030-885c-c7792410686b) - Closing
[0m15:49:02.341412 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m15:49:02.341412 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-49a1-1a3e-8dfd-fc6cb5573e60) - Closing
[0m15:49:02.501706 [info ] [Thread-3 (]: 2 of 5 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.08s]
[0m15:49:02.517068 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:49:02.517068 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:49:02.517068 [info ] [Thread-3 (]: 3 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:49:02.517068 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:49:02.517068 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:49:02.517068 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:49:02.517068 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:49:02.517068 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:49:02.517068 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:49:02.532862 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:49:02.534089 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:49:02.535098 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:49:03.151685 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4a50-130a-9566-7128ad9b9cdd) - Created
[0m15:49:03.732412 [debug] [Thread-3 (]: SQL status: OK in 1.200 seconds
[0m15:49:03.732412 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-4a50-130a-9566-7128ad9b9cdd, command-id=01f08e55-4a69-12cf-8201-bd5e47ac8155) - Closing
[0m15:49:03.732412 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:49:03.732412 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4a50-130a-9566-7128ad9b9cdd) - Closing
[0m15:49:03.903550 [info ] [Thread-3 (]: 3 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.39s]
[0m15:49:03.904103 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:49:03.904632 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:49:03.905238 [info ] [Thread-3 (]: 4 of 5 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m15:49:03.905832 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m15:49:03.906441 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m15:49:03.906441 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:49:03.914341 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:49:03.915399 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:49:03.922376 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:49:03.923653 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:49:03.924766 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:49:03.925283 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:49:04.462545 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4b17-1f98-9553-567990c371da) - Created
[0m15:49:05.010628 [debug] [Thread-3 (]: SQL status: OK in 1.090 seconds
[0m15:49:05.010628 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-4b17-1f98-9553-567990c371da, command-id=01f08e55-4b2f-16f9-8f5c-b40f45d74113) - Closing
[0m15:49:05.010628 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m15:49:05.010628 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4b17-1f98-9553-567990c371da) - Closing
[0m15:49:05.197394 [info ] [Thread-3 (]: 4 of 5 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.29s]
[0m15:49:05.200482 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:49:05.201480 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:49:05.202473 [info ] [Thread-3 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:49:05.203448 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:49:05.204468 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:49:05.204468 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:49:05.211484 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:49:05.212440 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:49:05.302296 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:49:05.302296 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:49:05.302296 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:49:05.302296 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:49:05.837263 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4beb-1472-aacd-98a0f29e35bf) - Created
[0m15:49:06.290404 [debug] [Thread-3 (]: SQL status: OK in 0.990 seconds
[0m15:49:06.290404 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-4beb-1472-aacd-98a0f29e35bf, command-id=01f08e55-4c02-14e6-9ce6-b974f3e2411e) - Closing
[0m15:49:06.290404 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:49:06.290404 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-4beb-1472-aacd-98a0f29e35bf) - Closing
[0m15:49:06.463990 [info ] [Thread-3 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.24s]
[0m15:49:06.463990 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:49:06.463990 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:49:06.463990 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:49:06.463990 [info ] [MainThread]: 
[0m15:49:06.463990 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 9.31 seconds (9.31s).
[0m15:49:06.463990 [debug] [MainThread]: Command end result
[0m15:49:06.507773 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:49:06.507773 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:49:06.517658 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m15:49:06.517658 [info ] [MainThread]: 
[0m15:49:06.519016 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:49:06.519016 [info ] [MainThread]: 
[0m15:49:06.519016 [error] [MainThread]: [31mFailure in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)[0m
[0m15:49:06.519016 [error] [MainThread]:   Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:49:06.519016 [info ] [MainThread]: 
[0m15:49:06.519016 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m15:49:06.519016 [debug] [MainThread]: Command `dbt test` failed at 15:49:06.519016 after 11.81 seconds
[0m15:49:06.519016 [debug] [MainThread]: Flushing usage events
[0m15:50:46.776637 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:50:46.853058 | 3b84574c-5c26-4b62-9f91-c91fd06af863 ==============================
[0m15:50:46.853058 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:50:46.853058 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'empty': 'None', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m15:50:47.726229 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:50:47.726229 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:50:47.727229 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:50:48.494205 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:50:48.808238 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m15:50:48.962531 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:50:48.962531 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:50:49.071704 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:50:49.071704 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:50:49.103394 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m15:50:49.103394 [info ] [MainThread]: 
[0m15:50:49.103394 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:50:49.103394 [info ] [MainThread]: 
[0m15:50:49.103394 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:50:49.103394 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:50:49.103394 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m15:50:49.103394 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m15:50:49.132751 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m15:50:49.133751 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m15:50:49.135901 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:50:49.697264 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-89d2-1b30-8a0a-56917abf90b1) - Created
[0m15:50:50.298302 [debug] [ThreadPool]: SQL status: OK in 1.160 seconds
[0m15:50:50.298302 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-89d2-1b30-8a0a-56917abf90b1, command-id=01f08e55-89ea-15ea-befc-b5c55723b13f) - Closing
[0m15:50:50.298302 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m15:50:50.298302 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-89d2-1b30-8a0a-56917abf90b1) - Closing
[0m15:50:50.463106 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m15:50:50.463106 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m15:50:50.481031 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m15:50:50.481031 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m15:50:50.481031 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:50:51.024576 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-8a9b-18e1-ac0e-ce548eb84d8b) - Created
[0m15:50:51.462446 [debug] [ThreadPool]: SQL status: OK in 0.980 seconds
[0m15:50:51.478338 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-8a9b-18e1-ac0e-ce548eb84d8b, command-id=01f08e55-8ab4-1de4-b405-24bacbe5f855) - Closing
[0m15:50:51.478338 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m15:50:51.478338 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-8a9b-18e1-ac0e-ce548eb84d8b) - Closing
[0m15:50:51.657034 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:50:51.658086 [info ] [Thread-3 (]: 1 of 5 START test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m15:50:51.663067 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42) - Creating connection
[0m15:50:51.663067 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42'
[0m15:50:51.664029 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:50:51.685123 [debug] [Thread-3 (]: Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:50:51.686160 [error] [Thread-3 (]: 1 of 5 ERROR accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[31mERROR[0m in 0.03s]
[0m15:50:51.686160 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42
[0m15:50:51.687168 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:50:51.688168 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.34bf091d42' to be skipped because of status 'error'.  Reason: Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m15:50:51.688168 [info ] [Thread-3 (]: 2 of 5 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m15:50:51.690562 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m15:50:51.690562 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m15:50:51.690562 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:50:51.701033 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:50:51.702182 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:50:51.723555 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:50:51.724808 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:50:51.725344 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m15:50:51.725344 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:50:52.665853 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8b91-15f0-a6ad-e0a7c79061f8) - Created
[0m15:50:53.136745 [debug] [Thread-3 (]: SQL status: OK in 1.410 seconds
[0m15:50:53.153346 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-8b91-15f0-a6ad-e0a7c79061f8, command-id=01f08e55-8bb0-14b6-ab46-00622dd4e96c) - Closing
[0m15:50:53.155858 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m15:50:53.156858 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8b91-15f0-a6ad-e0a7c79061f8) - Closing
[0m15:50:53.389186 [info ] [Thread-3 (]: 2 of 5 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.70s]
[0m15:50:53.391157 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:50:53.392189 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:50:53.393193 [info ] [Thread-3 (]: 3 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:50:53.395153 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:50:53.395153 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:50:53.396194 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:50:53.399340 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:50:53.399340 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:50:53.399340 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:50:53.399340 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:50:53.399340 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:50:53.399340 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:50:54.306792 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8c89-1a61-9652-a1acef83c664) - Created
[0m15:50:54.776053 [debug] [Thread-3 (]: SQL status: OK in 1.380 seconds
[0m15:50:54.776053 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-8c89-1a61-9652-a1acef83c664, command-id=01f08e55-8ca8-1c10-ba8b-beb7ee8b5ac0) - Closing
[0m15:50:54.776053 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:50:54.776053 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8c89-1a61-9652-a1acef83c664) - Closing
[0m15:50:54.960092 [info ] [Thread-3 (]: 3 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.57s]
[0m15:50:54.963079 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:50:54.963079 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:50:54.963079 [info ] [Thread-3 (]: 4 of 5 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m15:50:54.965172 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m15:50:54.965172 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m15:50:54.966276 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:50:54.974248 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:50:54.975160 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:50:54.978160 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:50:54.982159 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:50:54.982159 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:50:54.983165 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:50:55.881721 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8d77-1bae-8af2-15153d2b9a2e) - Created
[0m15:50:56.369463 [debug] [Thread-3 (]: SQL status: OK in 1.390 seconds
[0m15:50:56.371469 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-8d77-1bae-8af2-15153d2b9a2e, command-id=01f08e55-8d9b-15bb-a5fe-a62e69c8efbf) - Closing
[0m15:50:56.371469 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m15:50:56.371469 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8d77-1bae-8af2-15153d2b9a2e) - Closing
[0m15:50:56.598820 [info ] [Thread-3 (]: 4 of 5 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.63s]
[0m15:50:56.598820 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:50:56.598820 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:50:56.598820 [info ] [Thread-3 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:50:56.603965 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:50:56.603965 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:50:56.603965 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:50:56.609984 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:50:56.611989 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:50:56.697596 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:50:56.697596 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:50:56.697596 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:50:56.697596 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:50:57.772341 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8e97-122e-8c32-0ec60cd5b8ab) - Created
[0m15:50:58.069178 [debug] [Thread-3 (]: SQL status: OK in 1.370 seconds
[0m15:50:58.071121 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-8e97-122e-8c32-0ec60cd5b8ab, command-id=01f08e55-8eb9-1c14-b95b-9f7ec031aaaf) - Closing
[0m15:50:58.071121 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:50:58.071121 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-8e97-122e-8c32-0ec60cd5b8ab) - Closing
[0m15:50:58.261553 [info ] [Thread-3 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.66s]
[0m15:50:58.262636 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:50:58.263791 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:50:58.264330 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:50:58.264871 [info ] [MainThread]: 
[0m15:50:58.265385 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 9.16 seconds (9.16s).
[0m15:50:58.267081 [debug] [MainThread]: Command end result
[0m15:50:58.306786 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:50:58.309912 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:50:58.318601 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m15:50:58.319180 [info ] [MainThread]: 
[0m15:50:58.319705 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m15:50:58.320758 [info ] [MainThread]: 
[0m15:50:58.321342 [error] [MainThread]: [31mFailure in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)[0m
[0m15:50:58.321881 [error] [MainThread]:   Compilation Error in test accepted_bronze_store_store___MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan (models\bronze\properties.yml)
  'test_accepted' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m15:50:58.322426 [info ] [MainThread]: 
[0m15:50:58.322957 [info ] [MainThread]: Done. PASS=4 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=5
[0m15:50:58.324616 [debug] [MainThread]: Command `dbt test` failed at 15:50:58.324035 after 11.59 seconds
[0m15:50:58.324616 [debug] [MainThread]: Flushing usage events
[0m15:53:23.753743 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 15:53:23.822841 | e9179c7d-39c2-45cf-a2e1-b905c88ff6a8 ==============================
[0m15:53:23.822841 [info ] [MainThread]: Running with dbt=1.10.11
[0m15:53:23.822841 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m15:53:24.643728 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m15:53:24.643728 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m15:53:24.644726 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m15:53:25.425705 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m15:53:25.806879 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m15:53:25.962488 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:53:25.962488 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:53:26.091617 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:53:26.094638 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:53:26.114488 [info ] [MainThread]: Found 6 models, 5 data tests, 6 sources, 686 macros
[0m15:53:26.117581 [info ] [MainThread]: 
[0m15:53:26.117581 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m15:53:26.118531 [info ] [MainThread]: 
[0m15:53:26.119490 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:53:26.119490 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:53:26.119490 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m15:53:26.119490 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m15:53:26.139732 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m15:53:26.139732 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m15:53:26.140732 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:53:26.727652 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-e76b-111a-acc4-7e53dec46e4e) - Created
[0m15:53:27.575103 [debug] [ThreadPool]: SQL status: OK in 1.430 seconds
[0m15:53:27.578244 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-e76b-111a-acc4-7e53dec46e4e, command-id=01f08e55-e786-1ba7-a66c-0084b67e71ee) - Closing
[0m15:53:27.578244 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m15:53:27.578244 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-e76b-111a-acc4-7e53dec46e4e) - Closing
[0m15:53:27.744322 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m15:53:27.744322 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m15:53:27.747524 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m15:53:27.747524 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m15:53:27.747524 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:53:28.299205 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-e85a-1415-9587-41a3839578b6) - Created
[0m15:53:28.828130 [debug] [ThreadPool]: SQL status: OK in 1.080 seconds
[0m15:53:28.828130 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e55-e85a-1415-9587-41a3839578b6, command-id=01f08e55-e874-1741-8650-5523674e09a4) - Closing
[0m15:53:28.828130 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m15:53:28.828130 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e55-e85a-1415-9587-41a3839578b6) - Closing
[0m15:53:29.000269 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m15:53:29.000269 [info ] [Thread-3 (]: 1 of 5 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m15:53:29.000269 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m15:53:29.000269 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m15:53:29.000269 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m15:53:29.029230 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m15:53:29.029230 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m15:53:29.053846 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m15:53:29.055850 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m15:53:29.055850 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m15:53:29.056856 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:53:29.573868 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-e91e-1f7d-b045-9fb6848e6971) - Created
[0m15:53:30.934899 [debug] [Thread-3 (]: SQL status: OK in 1.880 seconds
[0m15:53:30.934899 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-e91e-1f7d-b045-9fb6848e6971, command-id=01f08e55-e936-1bc0-906c-ea37f293069d) - Closing
[0m15:53:30.934899 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m15:53:30.934899 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-e91e-1f7d-b045-9fb6848e6971) - Closing
[0m15:53:31.118935 [info ] [Thread-3 (]: 1 of 5 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 2.12s]
[0m15:53:31.120855 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m15:53:31.122939 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:53:31.123940 [info ] [Thread-3 (]: 2 of 5 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m15:53:31.125904 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m15:53:31.126847 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m15:53:31.126847 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:53:31.134955 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:53:31.134955 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:53:31.134955 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:53:31.134955 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m15:53:31.134955 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m15:53:31.134955 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:53:31.677088 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-ea5f-193f-8bb0-8b361c0829ee) - Created
[0m15:53:31.976536 [debug] [Thread-3 (]: SQL status: OK in 0.840 seconds
[0m15:53:31.979058 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-ea5f-193f-8bb0-8b361c0829ee, command-id=01f08e55-ea76-1097-a15c-80221ae7a24b) - Closing
[0m15:53:31.979803 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m15:53:31.980551 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-ea5f-193f-8bb0-8b361c0829ee) - Closing
[0m15:53:32.151772 [info ] [Thread-3 (]: 2 of 5 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.03s]
[0m15:53:32.151772 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m15:53:32.156425 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:53:32.158437 [info ] [Thread-3 (]: 3 of 5 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m15:53:32.158437 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m15:53:32.160981 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m15:53:32.160981 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:53:32.166739 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:53:32.166739 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:53:32.171689 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:53:32.173699 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m15:53:32.173699 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m15:53:32.173699 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:53:32.691590 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-eaf8-1e12-8fef-77ac2203b7df) - Created
[0m15:53:32.998831 [debug] [Thread-3 (]: SQL status: OK in 0.830 seconds
[0m15:53:32.998831 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-eaf8-1e12-8fef-77ac2203b7df, command-id=01f08e55-eb0f-1c74-adc0-98a1a7948b39) - Closing
[0m15:53:32.998831 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m15:53:32.998831 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-eaf8-1e12-8fef-77ac2203b7df) - Closing
[0m15:53:33.178958 [info ] [Thread-3 (]: 3 of 5 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.02s]
[0m15:53:33.180873 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m15:53:33.180873 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:53:33.180873 [info ] [Thread-3 (]: 4 of 5 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m15:53:33.180873 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m15:53:33.180873 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m15:53:33.180873 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:53:33.180873 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:53:33.180873 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:53:33.198982 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:53:33.198982 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m15:53:33.202475 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:53:33.202892 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:53:33.774945 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-eba0-1038-bde7-cc342047a300) - Created
[0m15:53:34.135835 [debug] [Thread-3 (]: SQL status: OK in 0.930 seconds
[0m15:53:34.138655 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-eba0-1038-bde7-cc342047a300, command-id=01f08e55-ebb7-1292-9222-d9a76f6e28d5) - Closing
[0m15:53:34.139295 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m15:53:34.139930 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-eba0-1038-bde7-cc342047a300) - Closing
[0m15:53:34.306865 [info ] [Thread-3 (]: 4 of 5 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.13s]
[0m15:53:34.306865 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m15:53:34.322590 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:53:34.324608 [info ] [Thread-3 (]: 5 of 5 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m15:53:34.324608 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m15:53:34.327278 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m15:53:34.328134 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:53:34.333113 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:53:34.333113 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:53:34.333113 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:53:34.333113 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m15:53:34.333113 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m15:53:34.333113 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m15:53:34.908163 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-ec49-1a30-b90c-d67620549377) - Created
[0m15:53:35.422441 [debug] [Thread-3 (]: SQL status: OK in 1.090 seconds
[0m15:53:35.427432 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e55-ec49-1a30-b90c-d67620549377, command-id=01f08e55-ec62-1570-9234-fc633aa455ef) - Closing
[0m15:53:35.428439 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m15:53:35.428439 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e55-ec49-1a30-b90c-d67620549377) - Closing
[0m15:53:35.602897 [info ] [Thread-3 (]: 5 of 5 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.28s]
[0m15:53:35.602897 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m15:53:35.605889 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m15:53:35.605889 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m15:53:35.609217 [info ] [MainThread]: 
[0m15:53:35.609217 [info ] [MainThread]: Finished running 5 data tests in 0 hours 0 minutes and 9.49 seconds (9.49s).
[0m15:53:35.613162 [debug] [MainThread]: Command end result
[0m15:53:35.644839 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m15:53:35.650392 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m15:53:35.656376 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m15:53:35.657311 [info ] [MainThread]: 
[0m15:53:35.657311 [info ] [MainThread]: [32mCompleted successfully[0m
[0m15:53:35.658343 [info ] [MainThread]: 
[0m15:53:35.658343 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=5
[0m15:53:35.660311 [debug] [MainThread]: Command `dbt test` succeeded at 15:53:35.660311 after 11.96 seconds
[0m15:53:35.661310 [debug] [MainThread]: Flushing usage events
[0m16:48:01.387695 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:48:01.466881 | 7cb93d7f-8ae2-449b-9c64-ed627fa83121 ==============================
[0m16:48:01.466881 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:48:01.466881 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'quiet': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:48:07.752395 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:48:07.764519 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:48:07.764519 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:48:17.888130 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:48:18.245421 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:48:18.348001 [error] [MainThread]: Encountered an error:
Parsing Error
  Error reading dbt_eTl: bronze\properties.yml - Runtime Error
    Syntax error near line 26
    ------------------------------
    23 |         data_tests:
    24 |           - non_negative_test
    25 |            
    26 |               column_name: gross_amount
    27 |   - name: bronze_customer #  Must match the filename of a model -- including case sensitivity.
    28 |     columns:
    29 |       - name: customer_sk
    
    Raw Error:
    ------------------------------
    mapping values are not allowed in this context
      in "<unicode string>", line 26, column 26
[0m16:48:18.348001 [debug] [MainThread]: Command `dbt test` failed at 16:48:18.348001 after 17.01 seconds
[0m16:48:18.348001 [debug] [MainThread]: Flushing usage events
[0m16:50:32.033322 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:50:32.132293 | a9f3b6af-e24d-407b-b9ca-756d0a7e90f4 ==============================
[0m16:50:32.132293 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:50:32.132293 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:50:33.202724 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:50:33.202724 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:50:33.202724 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:50:34.215448 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:50:34.594844 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:50:34.790918 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:34.790918 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:34.912731 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:50:34.945003 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:50:35.008804 [info ] [MainThread]: Found 6 models, 7 data tests, 6 sources, 687 macros
[0m16:50:35.008804 [info ] [MainThread]: 
[0m16:50:35.008804 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:50:35.008804 [info ] [MainThread]: 
[0m16:50:35.008804 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:50:35.008804 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:50:35.008804 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:50:35.025151 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:50:35.080178 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:50:35.081461 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:50:35.081461 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:38.285600 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5d-e4ad-177c-894d-5465579909e0) - Created
[0m16:50:55.158644 [debug] [ThreadPool]: SQL status: OK in 20.080 seconds
[0m16:50:55.206411 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5d-e4ad-177c-894d-5465579909e0, command-id=01f08e5d-e4e9-18a8-be8c-582cb0a51f4a) - Closing
[0m16:50:55.622017 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:50:55.622017 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5d-e4ad-177c-894d-5465579909e0) - Closing
[0m16:50:55.831952 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:50:55.831952 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:50:55.846849 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:50:55.846849 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:50:55.846849 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:57.405330 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5d-f022-1544-bff6-6b47284093f4) - Created
[0m16:50:58.568698 [debug] [ThreadPool]: SQL status: OK in 2.720 seconds
[0m16:50:58.571851 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5d-f022-1544-bff6-6b47284093f4, command-id=01f08e5d-f044-1866-90cf-f1cfd16bd857) - Closing
[0m16:50:58.572856 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:50:58.573855 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5d-f022-1544-bff6-6b47284093f4) - Closing
[0m16:50:58.798437 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:50:58.798437 [info ] [Thread-3 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:50:58.798437 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:50:58.798437 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:50:58.798437 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:50:58.838971 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:50:58.838971 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:50:58.863957 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:50:58.863957 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:50:58.863957 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:50:58.863957 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:03.100500 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f38d-11fe-b73f-b46f3ae4a2e8) - Created
[0m16:51:06.657813 [debug] [Thread-3 (]: SQL status: OK in 7.790 seconds
[0m16:51:06.662657 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-f38d-11fe-b73f-b46f3ae4a2e8, command-id=01f08e5d-f3a8-1988-a9cb-83ce16a7ad56) - Closing
[0m16:51:06.662657 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:51:06.662657 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f38d-11fe-b73f-b46f3ae4a2e8) - Closing
[0m16:51:06.862708 [info ] [Thread-3 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 8.06s]
[0m16:51:06.862708 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:51:06.862708 [debug] [Thread-3 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:06.866257 [info ] [Thread-3 (]: 2 of 7 START test non_negative_test_bronze_sales_gross_amount .................. [RUN]
[0m16:51:06.866257 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m16:51:06.866257 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m16:51:06.866257 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:06.887230 [debug] [Thread-3 (]: Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:51:06.888232 [error] [Thread-3 (]: 2 of 7 ERROR non_negative_test_bronze_sales_gross_amount ....................... [[31mERROR[0m in 0.02s]
[0m16:51:06.889234 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:06.890121 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:06.890121 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d' to be skipped because of status 'error'.  Reason: Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m16:51:06.891268 [info ] [Thread-3 (]: 3 of 7 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m16:51:06.892274 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:51:06.893268 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:51:06.893268 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:06.901306 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:06.902210 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:06.905209 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:06.907327 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:06.908323 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:51:06.909322 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:08.006681 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f675-1a31-8efd-2c31f61f9374) - Created
[0m16:51:09.134939 [debug] [Thread-3 (]: SQL status: OK in 2.230 seconds
[0m16:51:09.134939 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-f675-1a31-8efd-2c31f61f9374, command-id=01f08e5d-f69a-1aaf-bbbf-5a0fce02ff03) - Closing
[0m16:51:09.150227 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:51:09.150227 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f675-1a31-8efd-2c31f61f9374) - Closing
[0m16:51:09.379619 [info ] [Thread-3 (]: 3 of 7 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.49s]
[0m16:51:09.379619 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:09.379619 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:09.379619 [info ] [Thread-3 (]: 4 of 7 START test not_null_bronze_sales_gross_amount ........................... [RUN]
[0m16:51:09.379619 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m16:51:09.379619 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m16:51:09.379619 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:09.379619 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:09.379619 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:09.398778 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:09.399784 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:09.400778 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m16:51:09.400778 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:10.287751 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f7d2-1274-950c-70a355c1558d) - Created
[0m16:51:12.048240 [debug] [Thread-3 (]: SQL status: OK in 2.650 seconds
[0m16:51:12.048240 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-f7d2-1274-950c-70a355c1558d, command-id=01f08e5d-f7f2-1a08-b6fe-997d70835645) - Closing
[0m16:51:12.048240 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m16:51:12.048240 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f7d2-1274-950c-70a355c1558d) - Closing
[0m16:51:12.226203 [info ] [Thread-3 (]: 4 of 7 PASS not_null_bronze_sales_gross_amount ................................. [[32mPASS[0m in 2.85s]
[0m16:51:12.226203 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:12.226203 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:12.226203 [info ] [Thread-3 (]: 5 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:51:12.226203 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:51:12.226203 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:51:12.226203 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:12.311078 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:12.311078 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:12.311078 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:12.311078 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:12.311078 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:51:12.311078 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:12.850146 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f962-191a-96de-20ea82aa58e9) - Created
[0m16:51:13.501102 [debug] [Thread-3 (]: SQL status: OK in 1.190 seconds
[0m16:51:13.503111 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-f962-191a-96de-20ea82aa58e9, command-id=01f08e5d-f97a-10ef-8977-95a517db08ea) - Closing
[0m16:51:13.503111 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:51:13.503111 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-f962-191a-96de-20ea82aa58e9) - Closing
[0m16:51:13.690866 [info ] [Thread-3 (]: 5 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.46s]
[0m16:51:13.691864 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:13.692947 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:13.692947 [info ] [Thread-3 (]: 6 of 7 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m16:51:13.694865 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:51:13.695868 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:51:13.696241 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:13.702402 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:13.703394 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:13.706399 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:13.707311 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:13.707311 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:51:13.708316 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:14.237137 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-fa35-10ed-83ab-8af7f8a7a56d) - Created
[0m16:51:14.816006 [debug] [Thread-3 (]: SQL status: OK in 1.110 seconds
[0m16:51:14.816006 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-fa35-10ed-83ab-8af7f8a7a56d, command-id=01f08e5d-fa4b-1ad9-a0bb-c84166f4d7ce) - Closing
[0m16:51:14.816006 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:51:14.816006 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-fa35-10ed-83ab-8af7f8a7a56d) - Closing
[0m16:51:15.012756 [info ] [Thread-3 (]: 6 of 7 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.32s]
[0m16:51:15.012756 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:15.012756 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:15.012756 [info ] [Thread-3 (]: 7 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:51:15.012756 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:51:15.022539 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:51:15.022871 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:15.030255 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:15.031304 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:15.033295 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:15.034301 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:15.035211 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:51:15.035211 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:16.800904 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-fbb9-107b-bcc2-82fb4ee27564) - Created
[0m16:51:18.027569 [debug] [Thread-3 (]: SQL status: OK in 2.990 seconds
[0m16:51:18.032145 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5d-fbb9-107b-bcc2-82fb4ee27564, command-id=01f08e5d-fbd3-168a-a01f-8d601d657084) - Closing
[0m16:51:18.032145 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:51:18.032145 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5d-fbb9-107b-bcc2-82fb4ee27564) - Closing
[0m16:51:19.270416 [info ] [Thread-3 (]: 7 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 4.26s]
[0m16:51:19.275886 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:19.275886 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:51:19.275886 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:51:19.275886 [info ] [MainThread]: 
[0m16:51:19.275886 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 44.27 seconds (44.27s).
[0m16:51:19.282910 [debug] [MainThread]: Command end result
[0m16:51:19.313485 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:51:19.316381 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:51:19.322393 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:51:19.323384 [info ] [MainThread]: 
[0m16:51:19.323384 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:51:19.324391 [info ] [MainThread]: 
[0m16:51:19.325388 [error] [MainThread]: [31mFailure in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)[0m
[0m16:51:19.325388 [error] [MainThread]:   Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:51:19.326388 [info ] [MainThread]: 
[0m16:51:19.327387 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=7
[0m16:51:19.328380 [debug] [MainThread]: Command `dbt test` failed at 16:51:19.328380 after 47.37 seconds
[0m16:51:19.328380 [debug] [MainThread]: Flushing usage events
[0m16:51:24.198234 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:51:24.263831 | a405542d-c602-4ab2-b756-e78c2f7b702e ==============================
[0m16:51:24.263831 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:51:24.263831 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m16:51:25.109181 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:51:25.109181 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:51:25.110191 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:51:25.941194 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:51:26.261267 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:51:26.425704 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:51:26.425704 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:51:26.559874 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:51:26.564733 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:51:26.579746 [info ] [MainThread]: Found 6 models, 7 data tests, 6 sources, 687 macros
[0m16:51:26.579746 [info ] [MainThread]: 
[0m16:51:26.579746 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:51:26.579746 [info ] [MainThread]: 
[0m16:51:26.579746 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:51:26.579746 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:51:26.600149 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:51:26.600149 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:51:26.613331 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:51:26.613331 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:51:26.615340 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:51:27.196156 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-01eb-108d-9eef-5df8ee1ebfa7) - Created
[0m16:51:27.781155 [debug] [ThreadPool]: SQL status: OK in 1.170 seconds
[0m16:51:27.781155 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5e-01eb-108d-9eef-5df8ee1ebfa7, command-id=01f08e5e-0206-1969-9cf9-9ddf4c79ad4a) - Closing
[0m16:51:27.781155 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:51:27.781155 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-01eb-108d-9eef-5df8ee1ebfa7) - Closing
[0m16:51:27.951467 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:51:27.951467 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:51:27.962945 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:51:27.964049 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:51:27.964049 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:51:28.485978 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-02b3-1a68-80d8-78cc5133b5ab) - Created
[0m16:51:28.969191 [debug] [ThreadPool]: SQL status: OK in 1.000 seconds
[0m16:51:28.972314 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5e-02b3-1a68-80d8-78cc5133b5ab, command-id=01f08e5e-02ce-1013-96c2-16eb0f4a7457) - Closing
[0m16:51:28.972922 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:51:28.973526 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-02b3-1a68-80d8-78cc5133b5ab) - Closing
[0m16:51:29.126018 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:51:29.126018 [info ] [Thread-3 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:51:29.126018 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:51:29.126018 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:51:29.126018 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:51:29.161466 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:51:29.162003 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:51:29.178924 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:51:29.178924 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:51:29.178924 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:51:29.178924 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:29.747135 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-0374-173b-9bcf-e608dca3cdf2) - Created
[0m16:51:30.147914 [debug] [Thread-3 (]: SQL status: OK in 0.970 seconds
[0m16:51:30.147914 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-0374-173b-9bcf-e608dca3cdf2, command-id=01f08e5e-038b-11aa-95fa-6c6a2ee71dcc) - Closing
[0m16:51:30.147914 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:51:30.147914 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-0374-173b-9bcf-e608dca3cdf2) - Closing
[0m16:51:30.330565 [info ] [Thread-3 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 1.20s]
[0m16:51:30.330565 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:51:30.330565 [debug] [Thread-3 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:30.330565 [info ] [Thread-3 (]: 2 of 7 START test non_negative_test_bronze_sales_gross_amount .................. [RUN]
[0m16:51:30.330565 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m16:51:30.330565 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m16:51:30.330565 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:30.347991 [debug] [Thread-3 (]: Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:51:30.349009 [error] [Thread-3 (]: 2 of 7 ERROR non_negative_test_bronze_sales_gross_amount ....................... [[31mERROR[0m in 0.02s]
[0m16:51:30.349998 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:51:30.349998 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:30.351041 [debug] [Thread-6 (]: Marking all children of 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d' to be skipped because of status 'error'.  Reason: Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps"..
[0m16:51:30.351041 [info ] [Thread-3 (]: 3 of 7 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m16:51:30.353038 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:51:30.353038 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:51:30.353038 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:30.353038 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:30.353038 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:30.365499 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:30.366591 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:51:30.367528 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:51:30.367528 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:31.842669 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-04b5-1aae-a621-f2b498923aa6) - Created
[0m16:51:32.201266 [debug] [Thread-3 (]: SQL status: OK in 1.830 seconds
[0m16:51:32.201266 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-04b5-1aae-a621-f2b498923aa6, command-id=01f08e5e-04cb-1b04-8dd7-347a0e9d047e) - Closing
[0m16:51:32.201266 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:51:32.201266 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-04b5-1aae-a621-f2b498923aa6) - Closing
[0m16:51:32.377603 [info ] [Thread-3 (]: 3 of 7 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.03s]
[0m16:51:32.377603 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:51:32.377603 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:32.377603 [info ] [Thread-3 (]: 4 of 7 START test not_null_bronze_sales_gross_amount ........................... [RUN]
[0m16:51:32.377603 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m16:51:32.377603 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m16:51:32.392980 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:32.399414 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:32.401419 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:32.403496 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:32.404500 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:51:32.405425 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m16:51:32.405425 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:32.960240 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-055e-19df-a4ce-cb1314e65da0) - Created
[0m16:51:33.285174 [debug] [Thread-3 (]: SQL status: OK in 0.880 seconds
[0m16:51:33.288805 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-055e-19df-a4ce-cb1314e65da0, command-id=01f08e5e-0575-1cb7-b124-47c6ebb7c3cd) - Closing
[0m16:51:33.289335 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m16:51:33.289883 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-055e-19df-a4ce-cb1314e65da0) - Closing
[0m16:51:33.462655 [info ] [Thread-3 (]: 4 of 7 PASS not_null_bronze_sales_gross_amount ................................. [[32mPASS[0m in 1.09s]
[0m16:51:33.462655 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:51:33.462655 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:33.462655 [info ] [Thread-3 (]: 5 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:51:33.462655 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:51:33.462655 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:51:33.462655 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:33.562440 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:33.562440 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:33.562440 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:33.562440 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:51:33.562440 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:51:33.562440 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:34.080519 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-060a-1712-86dc-5394ac47f240) - Created
[0m16:51:34.396640 [debug] [Thread-3 (]: SQL status: OK in 0.830 seconds
[0m16:51:34.396640 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-060a-1712-86dc-5394ac47f240, command-id=01f08e5e-061f-16d0-9376-50144ec2ada3) - Closing
[0m16:51:34.405962 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:51:34.405962 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-060a-1712-86dc-5394ac47f240) - Closing
[0m16:51:34.781578 [info ] [Thread-3 (]: 5 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.32s]
[0m16:51:34.781578 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:51:34.781578 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:34.781578 [info ] [Thread-3 (]: 6 of 7 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m16:51:34.781578 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:51:34.781578 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:51:34.781578 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:34.800683 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:34.801685 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:34.802581 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:34.802581 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:51:34.802581 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:51:34.802581 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:35.362586 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-06cc-1be0-b655-71007319986e) - Created
[0m16:51:35.646811 [debug] [Thread-3 (]: SQL status: OK in 0.840 seconds
[0m16:51:35.646811 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-06cc-1be0-b655-71007319986e, command-id=01f08e5e-06e5-1271-8ecb-fd313cbe3172) - Closing
[0m16:51:35.646811 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:51:35.646811 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-06cc-1be0-b655-71007319986e) - Closing
[0m16:51:35.813670 [info ] [Thread-3 (]: 6 of 7 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.03s]
[0m16:51:35.825035 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:51:35.825035 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:35.825035 [info ] [Thread-3 (]: 7 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:51:35.829399 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:51:35.830646 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:51:35.831297 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:35.836398 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:35.836398 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:35.836398 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:35.836398 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:51:35.836398 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:51:35.836398 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:51:36.403054 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-076a-1a35-9015-86a9ab886da6) - Created
[0m16:51:36.736793 [debug] [Thread-3 (]: SQL status: OK in 0.900 seconds
[0m16:51:36.737096 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-076a-1a35-9015-86a9ab886da6, command-id=01f08e5e-0783-10f5-8718-f233e24fcff3) - Closing
[0m16:51:36.737096 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:51:36.737096 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-076a-1a35-9015-86a9ab886da6) - Closing
[0m16:51:36.897634 [info ] [Thread-3 (]: 7 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.07s]
[0m16:51:36.915626 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:51:36.915626 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:51:36.915626 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:51:36.915626 [info ] [MainThread]: 
[0m16:51:36.915626 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 10.34 seconds (10.34s).
[0m16:51:36.929955 [debug] [MainThread]: Command end result
[0m16:51:36.965126 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:51:36.965126 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:51:36.980593 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:51:36.980593 [info ] [MainThread]: 
[0m16:51:36.980593 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:51:36.980593 [info ] [MainThread]: 
[0m16:51:36.980593 [error] [MainThread]: [31mFailure in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)[0m
[0m16:51:36.980593 [error] [MainThread]:   Compilation Error in test non_negative_test_bronze_sales_gross_amount (models\bronze\properties.yml)
  'test_non_negative_test' is undefined. This can happen when calling a macro that does not exist. Check for typos and/or install package dependencies with "dbt deps".
[0m16:51:36.980593 [info ] [MainThread]: 
[0m16:51:36.980593 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=7
[0m16:51:36.980593 [debug] [MainThread]: Command `dbt test` failed at 16:51:36.980593 after 12.84 seconds
[0m16:51:36.980593 [debug] [MainThread]: Flushing usage events
[0m16:52:31.067481 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:52:31.145560 | b8aa0053-b738-4c98-be3a-18ada440ae08 ==============================
[0m16:52:31.145560 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:52:31.145560 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'None', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m16:52:32.062580 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:52:32.064585 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:52:32.064585 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:52:32.898099 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:52:33.306680 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:52:33.474418 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:52:33.474418 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://tests\generic\non_negative_test.sql
[0m16:52:33.638754 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:52:33.638754 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:52:33.654606 [info ] [MainThread]: Found 6 models, 7 data tests, 6 sources, 687 macros
[0m16:52:33.670552 [info ] [MainThread]: 
[0m16:52:33.670552 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:52:33.670552 [info ] [MainThread]: 
[0m16:52:33.670552 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:52:33.670552 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:52:33.678090 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:52:33.678090 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:52:33.690893 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:52:33.692320 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:52:33.692629 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:52:34.478530 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-2a06-18fe-aa15-5856f3b15b17) - Created
[0m16:52:34.929588 [debug] [ThreadPool]: SQL status: OK in 1.240 seconds
[0m16:52:34.945424 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5e-2a06-18fe-aa15-5856f3b15b17, command-id=01f08e5e-2a23-17e3-8ad6-29e5c6945eba) - Closing
[0m16:52:34.945424 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:52:34.945424 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-2a06-18fe-aa15-5856f3b15b17) - Closing
[0m16:52:35.122683 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:52:35.122683 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:52:35.130729 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:52:35.131728 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:52:35.131728 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:52:35.634823 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-2abb-17d4-8214-c016e5fb0eff) - Created
[0m16:52:36.174902 [debug] [ThreadPool]: SQL status: OK in 1.040 seconds
[0m16:52:36.188064 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e5e-2abb-17d4-8214-c016e5fb0eff, command-id=01f08e5e-2ad2-11e9-bd0d-cbccb370d5ac) - Closing
[0m16:52:36.188064 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:52:36.188064 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e5e-2abb-17d4-8214-c016e5fb0eff) - Closing
[0m16:52:36.369241 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:52:36.369241 [info ] [Thread-3 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:52:36.369241 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:52:36.369241 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:52:36.369241 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:52:36.395687 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:52:36.395687 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:52:36.419443 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:52:36.420539 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:52:36.420539 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:52:36.421450 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:36.990652 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2b84-10e4-a5c8-a5dd2b7795fe) - Created
[0m16:52:37.441982 [debug] [Thread-3 (]: SQL status: OK in 1.020 seconds
[0m16:52:37.460059 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-2b84-10e4-a5c8-a5dd2b7795fe, command-id=01f08e5e-2b9f-1bc6-a429-e89aea1757b4) - Closing
[0m16:52:37.462064 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:52:37.464069 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2b84-10e4-a5c8-a5dd2b7795fe) - Closing
[0m16:52:37.623173 [info ] [Thread-3 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 1.25s]
[0m16:52:37.638487 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:52:37.638487 [debug] [Thread-3 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:52:37.638487 [info ] [Thread-3 (]: 2 of 7 START test non_negative_test_bronze_sales_gross_amount .................. [RUN]
[0m16:52:37.638487 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m16:52:37.638487 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m16:52:37.638487 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:52:37.740308 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m16:52:37.742231 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:52:37.745259 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m16:52:37.746162 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m16:52:37.747168 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
  SELECT 
    *
  FROM `dbt-project`.`default`.`bronze_sales`
  WHERE gross_amount < 0

  
  
      
    ) dbt_internal_test
[0m16:52:37.747168 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:40.485628 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2d9c-1217-960d-cca2d8c17778) - Created
[0m16:52:41.249339 [debug] [Thread-3 (]: SQL status: OK in 3.500 seconds
[0m16:52:41.249339 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-2d9c-1217-960d-cca2d8c17778, command-id=01f08e5e-2db4-10a2-aa9a-0d89f60a3354) - Closing
[0m16:52:41.249339 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: Close
[0m16:52:41.249339 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2d9c-1217-960d-cca2d8c17778) - Closing
[0m16:52:41.424900 [info ] [Thread-3 (]: 2 of 7 PASS non_negative_test_bronze_sales_gross_amount ........................ [[32mPASS[0m in 3.79s]
[0m16:52:41.424900 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m16:52:41.424900 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:52:41.424900 [info ] [Thread-3 (]: 3 of 7 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m16:52:41.440855 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:52:41.440855 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:52:41.440855 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:52:41.450158 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:52:41.450158 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:52:41.450158 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:52:41.450158 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:52:41.450158 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:52:41.456944 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:42.005742 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2e85-1321-9ac4-0a596a543c02) - Created
[0m16:52:42.299523 [debug] [Thread-3 (]: SQL status: OK in 0.840 seconds
[0m16:52:42.299523 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-2e85-1321-9ac4-0a596a543c02, command-id=01f08e5e-2e9d-10bc-8e3b-04997fe04440) - Closing
[0m16:52:42.299523 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:52:42.299523 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2e85-1321-9ac4-0a596a543c02) - Closing
[0m16:52:42.482772 [info ] [Thread-3 (]: 3 of 7 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.04s]
[0m16:52:42.484604 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:52:42.484604 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:52:42.485221 [info ] [Thread-3 (]: 4 of 7 START test not_null_bronze_sales_gross_amount ........................... [RUN]
[0m16:52:42.486326 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m16:52:42.486326 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m16:52:42.486850 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:52:42.493972 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:52:42.496287 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:52:42.500307 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:52:42.501564 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m16:52:42.502745 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m16:52:42.502745 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:43.076366 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2f27-1e49-9b55-439c593a0081) - Created
[0m16:52:43.412725 [debug] [Thread-3 (]: SQL status: OK in 0.910 seconds
[0m16:52:43.412725 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-2f27-1e49-9b55-439c593a0081, command-id=01f08e5e-2f40-1f8c-bf46-384eae4848ef) - Closing
[0m16:52:43.412725 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m16:52:43.428746 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2f27-1e49-9b55-439c593a0081) - Closing
[0m16:52:43.589448 [info ] [Thread-3 (]: 4 of 7 PASS not_null_bronze_sales_gross_amount ................................. [[32mPASS[0m in 1.10s]
[0m16:52:43.589448 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m16:52:43.606588 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:52:43.607550 [info ] [Thread-3 (]: 5 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m16:52:43.607550 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m16:52:43.610493 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m16:52:43.611701 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:52:43.616367 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:52:43.616367 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:52:43.626169 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:52:43.627176 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m16:52:43.627176 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m16:52:43.630797 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:44.176578 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2fce-1a70-9b4b-83b74fe46ea3) - Created
[0m16:52:44.479279 [debug] [Thread-3 (]: SQL status: OK in 0.850 seconds
[0m16:52:44.479279 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-2fce-1a70-9b4b-83b74fe46ea3, command-id=01f08e5e-2fe8-16c5-b24c-d158461e28f7) - Closing
[0m16:52:44.479279 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m16:52:44.479279 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-2fce-1a70-9b4b-83b74fe46ea3) - Closing
[0m16:52:44.653834 [info ] [Thread-3 (]: 5 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.05s]
[0m16:52:44.655052 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m16:52:44.655052 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:52:44.655646 [info ] [Thread-3 (]: 6 of 7 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m16:52:44.657422 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:52:44.657422 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:52:44.657945 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:52:44.666378 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:52:44.667566 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:52:44.671448 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:52:44.672095 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:52:44.672688 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:52:44.673226 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:45.205160 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-306d-167e-b814-112c098a7cef) - Created
[0m16:52:45.482035 [debug] [Thread-3 (]: SQL status: OK in 0.810 seconds
[0m16:52:45.497932 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-306d-167e-b814-112c098a7cef, command-id=01f08e5e-3085-10a3-b828-f0305e91a5cd) - Closing
[0m16:52:45.497932 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:52:45.499941 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-306d-167e-b814-112c098a7cef) - Closing
[0m16:52:45.674579 [info ] [Thread-3 (]: 6 of 7 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.02s]
[0m16:52:45.674579 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:52:45.674579 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:52:45.674579 [info ] [Thread-3 (]: 7 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m16:52:45.674579 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m16:52:45.674579 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m16:52:45.674579 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:52:45.674579 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:52:45.674579 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:52:45.674579 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:52:45.674579 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m16:52:45.690513 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:52:45.692269 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m16:52:46.872567 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-3161-170a-afdf-3d869e04d707) - Created
[0m16:52:47.360448 [debug] [Thread-3 (]: SQL status: OK in 1.670 seconds
[0m16:52:47.360448 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08e5e-3161-170a-afdf-3d869e04d707, command-id=01f08e5e-3183-1950-b2ac-75aed9736bc4) - Closing
[0m16:52:47.360448 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m16:52:47.360448 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08e5e-3161-170a-afdf-3d869e04d707) - Closing
[0m16:52:47.581561 [info ] [Thread-3 (]: 7 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.91s]
[0m16:52:47.581561 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m16:52:47.597315 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:52:47.597315 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:52:47.597315 [info ] [MainThread]: 
[0m16:52:47.597315 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 13.93 seconds (13.93s).
[0m16:52:47.606214 [debug] [MainThread]: Command end result
[0m16:52:47.643865 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:52:47.643865 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:52:47.659355 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:52:47.660370 [info ] [MainThread]: 
[0m16:52:47.661733 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:52:47.662987 [info ] [MainThread]: 
[0m16:52:47.663993 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m16:52:47.664406 [debug] [MainThread]: Command `dbt test` succeeded at 16:52:47.664406 after 16.66 seconds
[0m16:52:47.665413 [debug] [MainThread]: Flushing usage events
[0m19:18:57.688098 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:18:57.832311 | 6dd24894-2a81-4e9d-be84-4c2da104cd62 ==============================
[0m19:18:57.832311 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:18:57.834325 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt seed', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m19:19:09.945839 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:19:09.945839 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:19:09.947850 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:19:29.038889 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:19:29.752906 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:19:30.019029 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m19:19:33.670744 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named bronze_customer. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for bronze_customer in this file:
   - models\bronze\properties.yml
  
[0m19:19:33.686760 [debug] [MainThread]: Command `dbt seed` failed at 19:19:33.686760 after 36.10 seconds
[0m19:19:33.686760 [debug] [MainThread]: Flushing usage events
[0m19:20:37.140052 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:20:37.233747 | bf7cba65-31a8-4e67-b5c9-08f4ae68f4f4 ==============================
[0m19:20:37.233747 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:20:37.235352 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt clean', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m19:20:37.604141 [debug] [MainThread]: Command `dbt clean` succeeded at 19:20:37.604141 after 0.57 seconds
[0m19:20:37.604141 [debug] [MainThread]: Flushing usage events
[0m19:20:46.340178 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:20:46.431071 | 685bb1fd-7305-47db-acc3-08f55e11bfba ==============================
[0m19:20:46.431071 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:20:46.431071 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m19:20:47.780705 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:20:47.782711 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:20:47.782711 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:20:49.022860 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:20:49.589941 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:20:49.589941 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m19:20:52.162729 [error] [MainThread]: Encountered an error:
Compilation Error
  dbt found two schema.yml entries for the same resource named bronze_customer. Resources and their associated columns may only be described a single time. To fix this, remove one of the resource entries for bronze_customer in this file:
   - models\bronze\properties.yml
  
[0m19:20:52.165690 [debug] [MainThread]: Command `dbt run` failed at 19:20:52.165107 after 5.90 seconds
[0m19:20:52.165690 [debug] [MainThread]: Flushing usage events
[0m19:22:24.717728 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:22:24.806793 | 326e1fc7-19f8-4de3-a91b-39638b439ebb ==============================
[0m19:22:24.806793 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:22:24.808800 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m19:22:26.383662 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:22:26.383662 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:22:26.385153 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:22:27.683762 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:22:28.325492 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:22:28.325492 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m19:22:30.916219 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m19:22:31.378519 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:22:31.426140 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:22:31.464452 [info ] [MainThread]: Found 6 models, 1 seed, 7 data tests, 6 sources, 687 macros
[0m19:22:31.467545 [info ] [MainThread]: 
[0m19:22:31.467545 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:22:31.467545 [info ] [MainThread]: 
[0m19:22:31.473956 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:22:31.473956 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:22:31.483234 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m19:22:31.483234 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m19:22:31.483234 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m19:22:31.483234 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m19:22:31.483234 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:22:32.351140 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1ddf-1271-b986-2fc8e7d653ad) - Created
[0m19:22:33.030896 [debug] [ThreadPool]: SQL status: OK in 1.550 seconds
[0m19:22:33.030896 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-1ddf-1271-b986-2fc8e7d653ad, command-id=01f08e73-1dff-1438-a48e-97f92f19d18b) - Closing
[0m19:22:33.030896 [debug] [ThreadPool]: On list_dbt-project: Close
[0m19:22:33.030896 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1ddf-1271-b986-2fc8e7d653ad) - Closing
[0m19:22:33.302119 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m19:22:33.302119 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m19:22:33.302119 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m19:22:33.302119 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m19:22:33.302119 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:22:34.026501 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1ee6-121d-853a-caa5165654ca) - Created
[0m19:22:34.309904 [debug] [ThreadPool]: SQL status: OK in 1.010 seconds
[0m19:22:34.311911 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-1ee6-121d-853a-caa5165654ca, command-id=01f08e73-1efd-1533-8341-e66d97fb72a0) - Closing
[0m19:22:34.313918 [debug] [ThreadPool]: On list_dbt-project: Close
[0m19:22:34.313918 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1ee6-121d-853a-caa5165654ca) - Closing
[0m19:22:34.497723 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m19:22:34.497723 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m19:22:34.516817 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m19:22:34.516817 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m19:22:34.516817 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:22:35.079293 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1f88-1175-b36b-3c953efc0340) - Created
[0m19:22:36.710016 [debug] [ThreadPool]: SQL status: OK in 2.190 seconds
[0m19:22:36.771888 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-1f88-1175-b36b-3c953efc0340, command-id=01f08e73-1f9f-149b-b55b-c80abb9eb9da) - Closing
[0m19:22:36.773626 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m19:22:36.773626 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-1f88-1175-b36b-3c953efc0340) - Closing
[0m19:22:36.942035 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m19:22:36.942035 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m19:22:36.955545 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m19:22:36.955545 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m19:22:36.957550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:22:37.507398 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-20fb-1324-9bf0-d2a189043a1c) - Created
[0m19:22:38.266276 [debug] [ThreadPool]: SQL status: OK in 1.310 seconds
[0m19:22:38.276129 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-20fb-1324-9bf0-d2a189043a1c, command-id=01f08e73-2111-1efc-8ec2-0b8015701613) - Closing
[0m19:22:38.276129 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m19:22:38.278135 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-20fb-1324-9bf0-d2a189043a1c) - Closing
[0m19:22:38.525515 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m19:22:38.525515 [info ] [Thread-5 (]: 1 of 6 START sql table model default.bronze_customer ........................... [RUN]
[0m19:22:38.525515 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m19:22:38.525515 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m19:22:38.525515 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m19:22:38.546025 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m19:22:38.550720 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m19:22:38.580135 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m19:22:38.580135 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m19:22:38.666832 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m19:22:38.668339 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m19:22:38.670344 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m19:22:38.670826 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:22:40.222512 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-226c-1bba-abc4-d8d15be004f3) - Created
[0m19:22:47.505199 [debug] [Thread-5 (]: SQL status: OK in 8.830 seconds
[0m19:22:47.510139 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-226c-1bba-abc4-d8d15be004f3, command-id=01f08e73-22b2-15af-8405-38de8c31df83) - Closing
[0m19:22:47.731325 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:22:47.763996 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m19:22:47.763996 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-226c-1bba-abc4-d8d15be004f3) - Closing
[0m19:22:48.518650 [info ] [Thread-5 (]: 1 of 6 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 9.98s]
[0m19:22:48.518650 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m19:22:48.518650 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m19:22:48.518650 [info ] [Thread-5 (]: 2 of 6 START sql view model bronze.bronze_date ................................. [RUN]
[0m19:22:48.518650 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m19:22:48.518650 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m19:22:48.518650 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m19:22:48.533740 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m19:22:48.533740 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m19:22:48.561568 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m19:22:48.583726 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m19:22:48.583726 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m19:22:48.583726 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m19:22:48.587025 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m19:22:48.587025 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:22:50.655723 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-28ab-181c-bdf5-882d357ca2ec) - Created
[0m19:22:51.380576 [debug] [Thread-5 (]: SQL status: OK in 2.790 seconds
[0m19:22:51.382584 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-28ab-181c-bdf5-882d357ca2ec, command-id=01f08e73-28e9-19ff-9230-7b48f21951e8) - Closing
[0m19:22:51.382584 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:22:51.382584 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m19:22:51.382584 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-28ab-181c-bdf5-882d357ca2ec) - Closing
[0m19:22:51.676174 [info ] [Thread-5 (]: 2 of 6 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 3.16s]
[0m19:22:51.677615 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m19:22:51.678120 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m19:22:51.679711 [info ] [Thread-5 (]: 3 of 6 START sql table model default.bronze_dim_product ........................ [RUN]
[0m19:22:51.680795 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m19:22:51.681461 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m19:22:51.682156 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m19:22:51.685945 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m19:22:51.689130 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m19:22:51.694326 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m19:22:51.696419 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m19:22:51.699170 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m19:22:51.700272 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m19:22:51.700844 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:22:53.047655 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-29ea-1e31-b240-172540d4b28f) - Created
[0m19:22:55.981700 [debug] [Thread-5 (]: SQL status: OK in 4.280 seconds
[0m19:22:55.981700 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-29ea-1e31-b240-172540d4b28f, command-id=01f08e73-2a56-1551-a645-8346215302a1) - Closing
[0m19:22:55.981700 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:22:55.981700 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m19:22:55.981700 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-29ea-1e31-b240-172540d4b28f) - Closing
[0m19:22:56.182202 [info ] [Thread-5 (]: 3 of 6 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 4.50s]
[0m19:22:56.188001 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m19:22:56.188001 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m19:22:56.188001 [info ] [Thread-5 (]: 4 of 6 START sql view model default.bronze_returns ............................. [RUN]
[0m19:22:56.188001 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m19:22:56.188001 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m19:22:56.188001 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m19:22:56.202095 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m19:22:56.202095 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m19:22:56.208687 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m19:22:56.210990 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m19:22:56.210990 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m19:22:56.214669 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m19:22:56.214669 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m19:22:56.214669 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:22:57.104712 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2ca0-15b9-8f64-9b478dfa22c7) - Created
[0m19:22:57.842224 [debug] [Thread-5 (]: SQL status: OK in 1.630 seconds
[0m19:22:57.844229 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-2ca0-15b9-8f64-9b478dfa22c7, command-id=01f08e73-2cc0-1a5a-96b9-18b156996cf6) - Closing
[0m19:22:57.844229 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:22:57.846235 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m19:22:57.846235 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2ca0-15b9-8f64-9b478dfa22c7) - Closing
[0m19:22:58.012084 [info ] [Thread-5 (]: 4 of 6 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 1.82s]
[0m19:22:58.022969 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m19:22:58.022969 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m19:22:58.022969 [info ] [Thread-5 (]: 5 of 6 START sql view model default.bronze_sales ............................... [RUN]
[0m19:22:58.027084 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m19:22:58.027084 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m19:22:58.027084 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m19:22:58.038059 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m19:22:58.043724 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m19:22:58.047950 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m19:22:58.051444 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m19:22:58.051934 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m19:22:58.051934 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m19:22:58.051934 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m19:22:58.051934 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:22:58.681434 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2d97-1e09-9df3-9d049e21831a) - Created
[0m19:22:59.230269 [debug] [Thread-5 (]: SQL status: OK in 1.180 seconds
[0m19:22:59.238612 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-2d97-1e09-9df3-9d049e21831a, command-id=01f08e73-2db0-1f0b-899b-2b4d66ab0eb9) - Closing
[0m19:22:59.238612 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:22:59.238612 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m19:22:59.242661 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2d97-1e09-9df3-9d049e21831a) - Closing
[0m19:22:59.397990 [info ] [Thread-5 (]: 5 of 6 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.38s]
[0m19:22:59.399474 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m19:22:59.399474 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m19:22:59.401534 [info ] [Thread-5 (]: 6 of 6 START sql table model default.bronze_store .............................. [RUN]
[0m19:22:59.401534 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m19:22:59.401534 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m19:22:59.401534 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m19:22:59.412248 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m19:22:59.414254 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m19:22:59.420605 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m19:22:59.423190 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m19:22:59.424669 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m19:22:59.425858 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m19:22:59.426995 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m19:23:00.062557 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2e5f-19f2-bd26-ac34290fd079) - Created
[0m19:23:02.967434 [debug] [Thread-5 (]: SQL status: OK in 3.540 seconds
[0m19:23:02.969442 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08e73-2e5f-19f2-bd26-ac34290fd079, command-id=01f08e73-2e84-1191-9a25-02d48ebd0b85) - Closing
[0m19:23:02.971452 [debug] [Thread-5 (]: Applying tags to relation None
[0m19:23:02.971452 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m19:23:02.973457 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08e73-2e5f-19f2-bd26-ac34290fd079) - Closing
[0m19:23:03.142252 [info ] [Thread-5 (]: 6 of 6 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.74s]
[0m19:23:03.142252 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m19:23:03.142252 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:23:03.142252 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:23:03.142252 [info ] [MainThread]: 
[0m19:23:03.153028 [info ] [MainThread]: Finished running 3 table models, 3 view models in 0 hours 0 minutes and 31.67 seconds (31.67s).
[0m19:23:03.156268 [debug] [MainThread]: Command end result
[0m19:23:03.213857 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:23:03.215872 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:23:03.232494 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m19:23:03.232494 [info ] [MainThread]: 
[0m19:23:03.232494 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:23:03.232494 [info ] [MainThread]: 
[0m19:23:03.232494 [info ] [MainThread]: Done. PASS=6 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=6
[0m19:23:03.232494 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m19:23:03.232494 [debug] [MainThread]: Command `dbt run` succeeded at 19:23:03.232494 after 38.60 seconds
[0m19:23:03.232494 [debug] [MainThread]: Flushing usage events
[0m19:23:20.776122 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:23:20.861543 | 838138ed-e239-43d3-9476-98e9eddef41e ==============================
[0m19:23:20.861543 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:23:20.866048 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt seed', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m19:23:22.412438 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:23:22.420669 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:23:22.420669 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:23:23.702158 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:23:24.263523 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:23:24.728150 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:23:24.730049 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:23:24.979745 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:23:24.985102 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:23:25.032270 [info ] [MainThread]: Found 6 models, 1 seed, 7 data tests, 6 sources, 687 macros
[0m19:23:25.037009 [info ] [MainThread]: 
[0m19:23:25.038052 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:23:25.039103 [info ] [MainThread]: 
[0m19:23:25.040394 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:23:25.040914 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:23:25.042822 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m19:23:25.043845 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m19:23:25.045405 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m19:23:25.045405 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m19:23:25.045405 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:26.496800 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-3dff-170f-829a-1bf163867f96) - Created
[0m19:23:26.838530 [debug] [ThreadPool]: SQL status: OK in 1.790 seconds
[0m19:23:26.838530 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-3dff-170f-829a-1bf163867f96, command-id=01f08e73-3e44-1fa2-b5da-da6d53ed25c0) - Closing
[0m19:23:26.838530 [debug] [ThreadPool]: On list_dbt-project: Close
[0m19:23:26.838530 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-3dff-170f-829a-1bf163867f96) - Closing
[0m19:23:27.521689 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m19:23:27.521689 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m19:23:27.553614 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m19:23:27.553614 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m19:23:27.553614 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:28.712291 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-3f7d-1314-b3a9-f99ebc67515a) - Created
[0m19:23:29.205657 [debug] [ThreadPool]: SQL status: OK in 1.650 seconds
[0m19:23:29.214307 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-3f7d-1314-b3a9-f99ebc67515a, command-id=01f08e73-3f96-153f-8d54-988c75e7f728) - Closing
[0m19:23:29.214307 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m19:23:29.214307 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-3f7d-1314-b3a9-f99ebc67515a) - Closing
[0m19:23:29.468012 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m19:23:29.468012 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m19:23:29.477062 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m19:23:29.477062 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m19:23:29.479068 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:23:30.233489 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-405d-1890-a5ea-396c3134a075) - Created
[0m19:23:30.785032 [debug] [ThreadPool]: SQL status: OK in 1.310 seconds
[0m19:23:30.800987 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-405d-1890-a5ea-396c3134a075, command-id=01f08e73-4080-1a1b-9141-34bf4485ae56) - Closing
[0m19:23:30.800987 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m19:23:30.800987 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-405d-1890-a5ea-396c3134a075) - Closing
[0m19:23:31.191780 [debug] [Thread-4 (]: Began running node seed.dbt_eTl.lookup
[0m19:23:31.191780 [info ] [Thread-4 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m19:23:31.191780 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m19:23:31.191780 [debug] [Thread-4 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m19:23:31.191780 [debug] [Thread-4 (]: Began compiling node seed.dbt_eTl.lookup
[0m19:23:31.191780 [debug] [Thread-4 (]: Began executing node seed.dbt_eTl.lookup
[0m19:23:31.211172 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m19:23:31.311318 [debug] [Thread-4 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m19:23:31.317100 [debug] [Thread-4 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create  table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using csv
    
    
    
    
    
  
[0m19:23:31.317100 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m19:23:34.381112 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08e73-42da-1594-aebc-0159c7bb7ab7) - Created
[0m19:23:35.222428 [debug] [Thread-4 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create  table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using csv
    
    
    
    
    
  
: [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV.
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: com.databricks.sql.managedcatalog.UnityCatalogServiceException: [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV.
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1036)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:785)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:746)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:18)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:42)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:236)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:293)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:289)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: com.databricks.sql.managedcatalog.UnityCatalogServiceException: [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV.
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:126)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:267)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7423)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7409)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:1459)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:123)
	at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:521)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:197)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1729)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:197)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:1073)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:1000)
	at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:259)
	at org.apache.spark.sql.execution.command.CreateDataSourceTableCommand.run(createDataSourceTables.scala:134)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:86)
	at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:195)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:86)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:83)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:82)
	at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:96)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:480)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:480)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:479)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:524)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:444)
	at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:819)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:373)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
	at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
	at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
	at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:373)
	at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:848)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:372)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:238)
	at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:772)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:475)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1374)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:471)
	at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:400)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:469)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:551)
	at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:543)
	at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)
	at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
	at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
	at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:543)
	at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
	at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:543)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:356)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1748)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:58)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:361)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:428)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:408)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:672)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:698)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:845)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:585)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:845)
	... 53 more
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:126)
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:267)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7423)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7409)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.createTable(ManagedCatalogClientImpl.scala:1459)
		at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createManagedOrExternalTable(PermissionEnforcingManagedCatalog.scala:123)
		at com.databricks.sql.managedcatalog.PermissionEnforcingManagedCatalog.createTable(PermissionEnforcingManagedCatalog.scala:521)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$createTable$1(ProfiledManagedCatalog.scala:197)
		at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1729)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.createTable(ProfiledManagedCatalog.scala:197)
		at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTableInternal(ManagedCatalogSessionCatalog.scala:1073)
		at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.createTable(ManagedCatalogSessionCatalog.scala:1000)
		at com.databricks.sql.DatabricksSessionCatalog.createTable(DatabricksSessionCatalog.scala:259)
		at org.apache.spark.sql.execution.command.CreateDataSourceTableCommand.run(createDataSourceTables.scala:134)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$2(commands.scala:86)
		at org.apache.spark.sql.execution.SparkPlan.runCommandInAetherOrSpark(SparkPlan.scala:195)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.$anonfun$sideEffectResult$1(commands.scala:86)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:94)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult$lzycompute(commands.scala:83)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.sideEffectResult(commands.scala:82)
		at org.apache.spark.sql.execution.command.ExecutedCommandExec.executeCollect(commands.scala:96)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$5(QueryExecution.scala:480)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$4(QueryExecution.scala:480)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:246)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$3(QueryExecution.scala:479)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:524)
		at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:444)
		at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:819)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:373)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
		at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
		at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
		at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:373)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:848)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:372)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:238)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:772)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:475)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1374)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:471)
		at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:400)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:469)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:551)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:543)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:521)
		at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:521)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:497)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:543)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:543)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:356)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1687)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:46)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:46)
		... 62 more
, operation-id=01f08e73-42f8-13d0-9c20-ce125449d559
[0m19:23:35.236626 [debug] [Thread-4 (]: On seed.dbt_eTl.lookup: Close
[0m19:23:35.236626 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08e73-42da-1594-aebc-0159c7bb7ab7) - Closing
[0m19:23:35.537144 [debug] [Thread-4 (]: Database Error in seed lookup (seeds\lookup.csv)
  [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV.
[0m19:23:35.550784 [error] [Thread-4 (]: 1 of 1 ERROR loading seed file bronze.lookup ................................... [[31mERROR[0m in 4.35s]
[0m19:23:35.550784 [debug] [Thread-4 (]: Finished running node seed.dbt_eTl.lookup
[0m19:23:35.550784 [debug] [Thread-7 (]: Marking all children of 'seed.dbt_eTl.lookup' to be skipped because of status 'error'.  Reason: Database Error in seed lookup (seeds\lookup.csv)
  [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV..
[0m19:23:35.550784 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:23:35.550784 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:23:35.550784 [info ] [MainThread]: 
[0m19:23:35.550784 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 10.51 seconds (10.51s).
[0m19:23:35.560076 [debug] [MainThread]: Command end result
[0m19:23:35.627842 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:23:35.628461 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:23:35.628461 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m19:23:35.628461 [info ] [MainThread]: 
[0m19:23:35.642566 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m19:23:35.644499 [info ] [MainThread]: 
[0m19:23:35.645172 [error] [MainThread]: [31mFailure in seed lookup (seeds\lookup.csv)[0m
[0m19:23:35.645172 [error] [MainThread]:   Database Error in seed lookup (seeds\lookup.csv)
  [RequestId=ac0be9b3-8ea4-4035-ba64-95884ad9b725 ErrorClass=INVALID_PARAMETER_VALUE.MANAGED_TABLE_FORMAT] Only Delta is supported for managed tables. Provided datasource format is CSV.
[0m19:23:35.645172 [info ] [MainThread]: 
[0m19:23:35.645172 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=1
[0m19:23:35.650563 [debug] [MainThread]: Command `dbt seed` failed at 19:23:35.650563 after 14.97 seconds
[0m19:23:35.650563 [debug] [MainThread]: Flushing usage events
[0m19:24:26.061999 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:24:26.156137 | c64b9901-5a1e-4e7b-9496-2ba7e5ea491a ==============================
[0m19:24:26.156137 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:24:26.157644 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt seed', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m19:24:27.675120 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:24:27.676177 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:24:27.676720 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:24:28.927636 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:24:29.467105 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:24:29.778061 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m19:24:29.778570 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m19:24:30.004021 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:24:30.004021 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:24:30.027891 [info ] [MainThread]: Found 6 models, 1 seed, 7 data tests, 6 sources, 687 macros
[0m19:24:30.030710 [info ] [MainThread]: 
[0m19:24:30.032719 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:24:30.033647 [info ] [MainThread]: 
[0m19:24:30.033647 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:24:30.035766 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:24:30.037045 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m19:24:30.037045 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m19:24:30.039177 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m19:24:30.039177 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m19:24:30.039177 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:31.137913 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-64a5-1e07-bee5-ac548bc5f3b8) - Created
[0m19:24:31.563074 [debug] [ThreadPool]: SQL status: OK in 1.520 seconds
[0m19:24:31.566134 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-64a5-1e07-bee5-ac548bc5f3b8, command-id=01f08e73-64d4-190b-9ed4-8b0f82935a80) - Closing
[0m19:24:31.566134 [debug] [ThreadPool]: On list_dbt-project: Close
[0m19:24:31.566134 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-64a5-1e07-bee5-ac548bc5f3b8) - Closing
[0m19:24:31.795055 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m19:24:31.796821 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m19:24:31.817740 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m19:24:31.817740 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m19:24:31.817740 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:32.632471 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-6597-1b1f-8060-e86a5e9535b0) - Created
[0m19:24:33.101679 [debug] [ThreadPool]: SQL status: OK in 1.280 seconds
[0m19:24:33.101679 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-6597-1b1f-8060-e86a5e9535b0, command-id=01f08e73-65af-15b5-9684-81dde8e46cfa) - Closing
[0m19:24:33.101679 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m19:24:33.101679 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-6597-1b1f-8060-e86a5e9535b0) - Closing
[0m19:24:33.273061 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m19:24:33.273061 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m19:24:33.289719 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m19:24:33.289719 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m19:24:33.289719 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:24:33.853531 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-6653-196b-b987-d5d8dec62188) - Created
[0m19:24:34.398807 [debug] [ThreadPool]: SQL status: OK in 1.110 seconds
[0m19:24:34.402934 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08e73-6653-196b-b987-d5d8dec62188, command-id=01f08e73-666b-162a-8034-378e3011bfa7) - Closing
[0m19:24:34.402934 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m19:24:34.402934 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08e73-6653-196b-b987-d5d8dec62188) - Closing
[0m19:24:34.603533 [debug] [Thread-4 (]: Began running node seed.dbt_eTl.lookup
[0m19:24:34.605541 [info ] [Thread-4 (]: 1 of 1 START seed file bronze.lookup ........................................... [RUN]
[0m19:24:34.607506 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m19:24:34.607506 [debug] [Thread-4 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m19:24:34.607506 [debug] [Thread-4 (]: Began compiling node seed.dbt_eTl.lookup
[0m19:24:34.607506 [debug] [Thread-4 (]: Began executing node seed.dbt_eTl.lookup
[0m19:24:34.619585 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m19:24:34.717267 [debug] [Thread-4 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m19:24:34.717267 [debug] [Thread-4 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create  table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m19:24:34.717267 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m19:24:36.470166 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08e73-67ce-160d-b539-217771f961d9) - Created
[0m19:24:38.794146 [debug] [Thread-4 (]: SQL status: OK in 4.080 seconds
[0m19:24:38.794146 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f08e73-67ce-160d-b539-217771f961d9, command-id=01f08e73-67fb-11ef-b16b-e2b6f8ecc47b) - Closing
[0m19:24:38.826287 [debug] [Thread-4 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m19:24:38.826287 [debug] [Thread-4 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m19:24:41.086645 [debug] [Thread-4 (]: SQL status: OK in 2.260 seconds
[0m19:24:41.093421 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f08e73-67ce-160d-b539-217771f961d9, command-id=01f08e73-6962-1055-8108-354d03e50794) - Closing
[0m19:24:41.100046 [debug] [Thread-4 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m19:24:41.117221 [debug] [Thread-4 (]: On seed.dbt_eTl.lookup: Close
[0m19:24:41.117221 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08e73-67ce-160d-b539-217771f961d9) - Closing
[0m19:24:41.864800 [info ] [Thread-4 (]: 1 of 1 OK loaded seed file bronze.lookup ....................................... [[32mINSERT 3[0m in 7.26s]
[0m19:24:41.864800 [debug] [Thread-4 (]: Finished running node seed.dbt_eTl.lookup
[0m19:24:41.864800 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:24:41.864800 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:24:41.864800 [info ] [MainThread]: 
[0m19:24:41.864800 [info ] [MainThread]: Finished running 1 seed in 0 hours 0 minutes and 11.83 seconds (11.83s).
[0m19:24:41.864800 [debug] [MainThread]: Command end result
[0m19:24:42.038297 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:24:42.038297 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:24:42.045814 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m19:24:42.045814 [info ] [MainThread]: 
[0m19:24:42.045814 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:24:42.045814 [info ] [MainThread]: 
[0m19:24:42.045814 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m19:24:42.061537 [debug] [MainThread]: Command `dbt seed` succeeded at 19:24:42.061537 after 16.10 seconds
[0m19:24:42.061537 [debug] [MainThread]: Flushing usage events
[0m19:21:36.717035 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:21:36.809393 | b3425de2-2f75-4485-a44b-160ea4db2983 ==============================
[0m19:21:36.809393 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:21:36.810400 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt ', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m19:21:37.232586 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m19:21:37.238961 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m19:21:37.243342 [debug] [MainThread]: Command `cli deps` succeeded at 19:21:37.241843 after 0.60 seconds
[0m19:21:37.243342 [debug] [MainThread]: Flushing usage events
[0m19:42:27.012671 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:42:27.100438 | 36410c9a-1c70-4803-97c1-9615a5e16c3b ==============================
[0m19:42:27.100438 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:42:27.100438 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m19:42:31.072401 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:42:31.072401 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:42:31.072401 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:42:32.883278 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:42:33.481771 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:42:33.813221 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m19:42:33.820311 [debug] [MainThread]: Partial parsing: added file: dbt_eTl://analyses\jinja-3.sql
[0m19:42:34.024091 [error] [MainThread]: Encountered an error:
Compilation Error in analysis jinja-3 (analyses\jinja-3.sql)
  Expected an expression, got 'end of statement block'
    line 4
      {% set %}
[0m19:42:34.024091 [debug] [MainThread]: Command `dbt test` failed at 19:42:34.024091 after 7.06 seconds
[0m19:42:34.026805 [debug] [MainThread]: Flushing usage events
[0m19:42:53.859439 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 19:42:53.939090 | e251d4af-fbef-43a4-bfbd-f02b347a3e40 ==============================
[0m19:42:53.939090 [info ] [MainThread]: Running with dbt=1.10.11
[0m19:42:53.939090 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m19:42:54.795217 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m19:42:54.796306 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m19:42:54.796306 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m19:42:55.566601 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m19:42:55.884652 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m19:42:56.044303 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m19:42:56.044303 [debug] [MainThread]: Partial parsing: added file: dbt_eTl://analyses\jinja-3.sql
[0m19:42:56.382108 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:42:56.429515 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:42:56.557845 [info ] [MainThread]: Found 6 models, 1 seed, 7 data tests, 1 analysis, 6 sources, 687 macros
[0m19:42:56.557845 [info ] [MainThread]: 
[0m19:42:56.557845 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m19:42:56.557845 [info ] [MainThread]: 
[0m19:42:56.557845 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:42:56.557845 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:42:56.557845 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m19:42:56.557845 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m19:42:56.589285 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m19:42:56.589285 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m19:42:56.590795 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:42:57.785149 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3f-229e-1744-b35e-1b37114664af) - Created
[0m19:43:14.851867 [debug] [ThreadPool]: SQL status: OK in 18.260 seconds
[0m19:43:14.899287 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f3f-229e-1744-b35e-1b37114664af, command-id=01f08f3f-22de-1a27-85df-7d016986a9e5) - Closing
[0m19:43:15.160927 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m19:43:15.160927 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3f-229e-1744-b35e-1b37114664af) - Closing
[0m19:43:15.331243 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m19:43:15.331243 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m19:43:15.338330 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m19:43:15.338330 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m19:43:15.338330 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m19:43:15.836035 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3f-2d8b-152e-a152-a33bb6889dbb) - Created
[0m19:43:16.833211 [debug] [ThreadPool]: SQL status: OK in 1.490 seconds
[0m19:43:16.833211 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f3f-2d8b-152e-a152-a33bb6889dbb, command-id=01f08f3f-2da1-18b8-9af5-2780b2159d79) - Closing
[0m19:43:16.833211 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m19:43:16.833211 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f3f-2d8b-152e-a152-a33bb6889dbb) - Closing
[0m19:43:17.000585 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m19:43:17.000585 [info ] [Thread-3 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m19:43:17.016464 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m19:43:17.016464 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m19:43:17.016464 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m19:43:17.037187 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m19:43:17.038486 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m19:43:17.052440 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m19:43:17.052440 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m19:43:17.052440 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m19:43:17.067996 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:17.618412 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-2e96-169c-9f73-e95ad62e5647) - Created
[0m19:43:24.546171 [debug] [Thread-3 (]: SQL status: OK in 7.490 seconds
[0m19:43:24.562014 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-2e96-169c-9f73-e95ad62e5647, command-id=01f08f3f-2eb2-1b58-be13-9c862cebeee8) - Closing
[0m19:43:24.783677 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m19:43:24.783677 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-2e96-169c-9f73-e95ad62e5647) - Closing
[0m19:43:24.965943 [info ] [Thread-3 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 7.95s]
[0m19:43:24.965943 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m19:43:24.965943 [debug] [Thread-3 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m19:43:24.965943 [info ] [Thread-3 (]: 2 of 7 START test non_negative_test_bronze_sales_gross_amount .................. [RUN]
[0m19:43:24.965943 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m19:43:24.965943 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m19:43:24.965943 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m19:43:24.965943 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m19:43:24.965943 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m19:43:24.965943 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m19:43:24.981951 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m19:43:24.983098 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
  SELECT 
    *
  FROM `dbt-project`.`default`.`bronze_sales`
  WHERE gross_amount < 0

  
  
      
    ) dbt_internal_test
[0m19:43:24.983098 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:25.451090 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-3347-1ecc-b24d-161b6e5a63b3) - Created
[0m19:43:27.373185 [debug] [Thread-3 (]: SQL status: OK in 2.390 seconds
[0m19:43:27.385089 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-3347-1ecc-b24d-161b6e5a63b3, command-id=01f08f3f-335d-1a70-ba80-597416329d65) - Closing
[0m19:43:27.385089 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: Close
[0m19:43:27.385089 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-3347-1ecc-b24d-161b6e5a63b3) - Closing
[0m19:43:27.552207 [info ] [Thread-3 (]: 2 of 7 PASS non_negative_test_bronze_sales_gross_amount ........................ [[32mPASS[0m in 2.59s]
[0m19:43:27.558831 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m19:43:27.559202 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m19:43:27.559583 [info ] [Thread-3 (]: 3 of 7 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m19:43:27.559583 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m19:43:27.559583 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m19:43:27.559583 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m19:43:27.559583 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m19:43:27.568446 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m19:43:27.570549 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m19:43:27.571560 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m19:43:27.571560 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m19:43:27.572452 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:28.098340 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-34d9-1d90-8d9b-c13ff1f02d4e) - Created
[0m19:43:29.303356 [debug] [Thread-3 (]: SQL status: OK in 1.730 seconds
[0m19:43:29.305363 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-34d9-1d90-8d9b-c13ff1f02d4e, command-id=01f08f3f-34f0-149f-b955-990c676942ab) - Closing
[0m19:43:29.305363 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m19:43:29.305363 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-34d9-1d90-8d9b-c13ff1f02d4e) - Closing
[0m19:43:29.469771 [info ] [Thread-3 (]: 3 of 7 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.91s]
[0m19:43:29.471459 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m19:43:29.472054 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m19:43:29.472054 [info ] [Thread-3 (]: 4 of 7 START test not_null_bronze_sales_gross_amount ........................... [RUN]
[0m19:43:29.473071 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m19:43:29.473071 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m19:43:29.474740 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m19:43:29.477902 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m19:43:29.477902 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m19:43:29.485715 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m19:43:29.485715 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m19:43:29.485715 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m19:43:29.485715 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:30.055666 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-3601-120c-8e7a-cc19eb44cd9e) - Created
[0m19:43:30.895518 [debug] [Thread-3 (]: SQL status: OK in 1.410 seconds
[0m19:43:30.895518 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-3601-120c-8e7a-cc19eb44cd9e, command-id=01f08f3f-361a-1d9c-a7bb-f60c86fbee3b) - Closing
[0m19:43:30.895518 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m19:43:30.895518 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-3601-120c-8e7a-cc19eb44cd9e) - Closing
[0m19:43:31.086947 [info ] [Thread-3 (]: 4 of 7 PASS not_null_bronze_sales_gross_amount ................................. [[32mPASS[0m in 1.61s]
[0m19:43:31.086947 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m19:43:31.086947 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:43:31.086947 [info ] [Thread-3 (]: 5 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m19:43:31.086947 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m19:43:31.086947 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m19:43:31.086947 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:43:31.086947 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:43:31.086947 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:43:31.106482 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:43:31.108537 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m19:43:31.109519 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m19:43:31.109519 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:31.599487 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-36f1-1523-bdf0-bfc1da87a332) - Created
[0m19:43:32.326342 [debug] [Thread-3 (]: SQL status: OK in 1.220 seconds
[0m19:43:32.328739 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-36f1-1523-bdf0-bfc1da87a332, command-id=01f08f3f-3706-1a1c-927d-9844ab333a0d) - Closing
[0m19:43:32.329746 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m19:43:32.329746 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-36f1-1523-bdf0-bfc1da87a332) - Closing
[0m19:43:32.494394 [info ] [Thread-3 (]: 5 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.41s]
[0m19:43:32.494394 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m19:43:32.494394 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m19:43:32.494394 [info ] [Thread-3 (]: 6 of 7 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m19:43:32.494394 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m19:43:32.494394 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m19:43:32.494394 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m19:43:32.505099 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m19:43:32.507105 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m19:43:32.509111 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m19:43:32.510117 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m19:43:32.511400 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:43:32.511400 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:33.043466 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-37ca-101b-9c67-8e565732134a) - Created
[0m19:43:34.105912 [debug] [Thread-3 (]: SQL status: OK in 1.590 seconds
[0m19:43:34.109400 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-37ca-101b-9c67-8e565732134a, command-id=01f08f3f-37e3-19c1-9a47-5c78e51745cd) - Closing
[0m19:43:34.110590 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m19:43:34.111862 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-37ca-101b-9c67-8e565732134a) - Closing
[0m19:43:34.267924 [info ] [Thread-3 (]: 6 of 7 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.77s]
[0m19:43:34.267924 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m19:43:34.283650 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m19:43:34.283650 [info ] [Thread-3 (]: 7 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m19:43:34.283650 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m19:43:34.283650 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m19:43:34.283650 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m19:43:34.291632 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:43:34.293877 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m19:43:34.293877 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:43:34.293877 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m19:43:34.293877 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m19:43:34.293877 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m19:43:34.802473 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-38d8-1f30-8b0a-1a7bce8e44bc) - Created
[0m19:43:36.022739 [debug] [Thread-3 (]: SQL status: OK in 1.730 seconds
[0m19:43:36.024743 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f3f-38d8-1f30-8b0a-1a7bce8e44bc, command-id=01f08f3f-38ef-16b8-937d-a31bebe0776e) - Closing
[0m19:43:36.024743 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m19:43:36.024743 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f3f-38d8-1f30-8b0a-1a7bce8e44bc) - Closing
[0m19:43:36.179599 [info ] [Thread-3 (]: 7 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.90s]
[0m19:43:36.195408 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m19:43:36.195408 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m19:43:36.195408 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m19:43:36.195408 [info ] [MainThread]: 
[0m19:43:36.195408 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 39.64 seconds (39.64s).
[0m19:43:36.203535 [debug] [MainThread]: Command end result
[0m19:43:36.248332 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m19:43:36.253628 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m19:43:36.260144 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m19:43:36.261150 [info ] [MainThread]: 
[0m19:43:36.261150 [info ] [MainThread]: [32mCompleted successfully[0m
[0m19:43:36.262150 [info ] [MainThread]: 
[0m19:43:36.262150 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m19:43:36.263152 [debug] [MainThread]: Command `dbt test` succeeded at 19:43:36.263152 after 42.45 seconds
[0m19:43:36.264151 [debug] [MainThread]: Flushing usage events
[0m00:51:48.099856 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 00:51:48.220951 | 1c8b39b4-3947-43c1-bc47-cf5b1a51f0a2 ==============================
[0m00:51:48.220951 [info ] [MainThread]: Running with dbt=1.10.11
[0m00:51:48.221954 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt test', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m00:51:53.906027 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m00:51:53.907013 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m00:51:53.907013 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m00:52:02.634734 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m00:52:03.016032 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m00:52:03.193724 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:52:03.194723 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:52:03.350310 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m00:52:03.360523 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m00:52:03.495126 [info ] [MainThread]: Found 6 models, 1 seed, 7 data tests, 1 analysis, 6 sources, 687 macros
[0m00:52:03.504776 [info ] [MainThread]: 
[0m00:52:03.506782 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m00:52:03.506782 [info ] [MainThread]: 
[0m00:52:03.508799 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m00:52:03.508799 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:52:03.517650 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m00:52:03.517650 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m00:52:03.537146 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m00:52:03.537146 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m00:52:03.537146 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:52:04.661575 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f6a-516e-1909-b11b-ad7139650452) - Created
[0m00:52:21.663762 [debug] [ThreadPool]: SQL status: OK in 18.130 seconds
[0m00:52:21.696159 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f6a-516e-1909-b11b-ad7139650452, command-id=01f08f6a-51a6-132d-85a7-9659ec7a1f66) - Closing
[0m00:52:22.015815 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m00:52:22.015815 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f6a-516e-1909-b11b-ad7139650452) - Closing
[0m00:52:22.196223 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m00:52:22.196223 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m00:52:22.212086 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m00:52:22.212086 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m00:52:22.212086 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:52:22.746552 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f6a-5c56-1e64-aa5b-b724f5c10c5b) - Created
[0m00:52:23.897216 [debug] [ThreadPool]: SQL status: OK in 1.690 seconds
[0m00:52:23.897216 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08f6a-5c56-1e64-aa5b-b724f5c10c5b, command-id=01f08f6a-5c6d-177c-a19a-c48283badf89) - Closing
[0m00:52:23.913356 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m00:52:23.913356 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08f6a-5c56-1e64-aa5b-b724f5c10c5b) - Closing
[0m00:52:24.106559 [debug] [Thread-3 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m00:52:24.107617 [info ] [Thread-3 (]: 1 of 7 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m00:52:24.108632 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m00:52:24.108632 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m00:52:24.108632 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m00:52:24.129106 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m00:52:24.130106 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m00:52:24.150811 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m00:52:24.150811 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m00:52:24.150811 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m00:52:24.150811 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:24.682688 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-5d7b-12d4-b84d-e9aca1121321) - Created
[0m00:52:28.340369 [debug] [Thread-3 (]: SQL status: OK in 4.190 seconds
[0m00:52:28.350068 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-5d7b-12d4-b84d-e9aca1121321, command-id=01f08f6a-5d94-187b-a2f4-8116a4e213a6) - Closing
[0m00:52:28.350068 [debug] [Thread-3 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m00:52:28.350068 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-5d7b-12d4-b84d-e9aca1121321) - Closing
[0m00:52:28.516678 [info ] [Thread-3 (]: 1 of 7 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 4.41s]
[0m00:52:28.516678 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m00:52:28.516678 [debug] [Thread-3 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m00:52:28.516678 [info ] [Thread-3 (]: 2 of 7 START test non_negative_test_bronze_sales_gross_amount .................. [RUN]
[0m00:52:28.516678 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m00:52:28.516678 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m00:52:28.516678 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m00:52:28.535466 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m00:52:28.535466 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m00:52:28.535466 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m00:52:28.542257 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m00:52:28.543112 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
  SELECT 
    *
  FROM `dbt-project`.`default`.`bronze_sales`
  WHERE gross_amount < 0

  
  
      
    ) dbt_internal_test
[0m00:52:28.544392 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:29.121018 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-601d-1967-a9b8-c05d6c0ecf0e) - Created
[0m00:52:30.507178 [debug] [Thread-3 (]: SQL status: OK in 1.960 seconds
[0m00:52:30.507178 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-601d-1967-a9b8-c05d6c0ecf0e, command-id=01f08f6a-6038-1081-bd1b-b7aaaae507f1) - Closing
[0m00:52:30.510030 [debug] [Thread-3 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: Close
[0m00:52:30.510030 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-601d-1967-a9b8-c05d6c0ecf0e) - Closing
[0m00:52:30.671330 [info ] [Thread-3 (]: 2 of 7 PASS non_negative_test_bronze_sales_gross_amount ........................ [[32mPASS[0m in 2.15s]
[0m00:52:30.671330 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m00:52:30.671330 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m00:52:30.671330 [info ] [Thread-3 (]: 3 of 7 START test not_null_bronze_customer_customer_sk ......................... [RUN]
[0m00:52:30.671330 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m00:52:30.671330 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m00:52:30.671330 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m00:52:30.687249 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m00:52:30.688247 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m00:52:30.692519 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m00:52:30.694528 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m00:52:30.694528 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m00:52:30.694528 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:31.286453 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-6168-1ced-84fc-11ee7e1aac0f) - Created
[0m00:52:32.512881 [debug] [Thread-3 (]: SQL status: OK in 1.820 seconds
[0m00:52:32.512881 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-6168-1ced-84fc-11ee7e1aac0f, command-id=01f08f6a-6184-1149-884c-3c331fb3f0ef) - Closing
[0m00:52:32.512881 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m00:52:32.512881 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-6168-1ced-84fc-11ee7e1aac0f) - Closing
[0m00:52:32.681489 [info ] [Thread-3 (]: 3 of 7 PASS not_null_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.01s]
[0m00:52:32.681489 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m00:52:32.681489 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m00:52:32.692758 [info ] [Thread-3 (]: 4 of 7 START test not_null_bronze_sales_gross_amount ........................... [RUN]
[0m00:52:32.694545 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m00:52:32.694545 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m00:52:32.694545 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m00:52:32.700482 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m00:52:32.700482 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m00:52:32.801227 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m00:52:32.802038 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m00:52:32.802038 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m00:52:32.802038 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:33.333317 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-62a3-1cee-92c4-05a59a24f011) - Created
[0m00:52:34.073171 [debug] [Thread-3 (]: SQL status: OK in 1.270 seconds
[0m00:52:34.076158 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-62a3-1cee-92c4-05a59a24f011, command-id=01f08f6a-62be-1a94-9c0a-ff86b09c30bf) - Closing
[0m00:52:34.077166 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m00:52:34.077166 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-62a3-1cee-92c4-05a59a24f011) - Closing
[0m00:52:34.243746 [info ] [Thread-3 (]: 4 of 7 PASS not_null_bronze_sales_gross_amount ................................. [[32mPASS[0m in 1.55s]
[0m00:52:34.243746 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m00:52:34.255161 [debug] [Thread-3 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m00:52:34.255161 [info ] [Thread-3 (]: 5 of 7 START test not_null_bronze_sales_sales_id ............................... [RUN]
[0m00:52:34.257178 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m00:52:34.259536 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m00:52:34.260556 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m00:52:34.273404 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m00:52:34.274392 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m00:52:34.275367 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m00:52:34.275367 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m00:52:34.275367 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m00:52:34.275367 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:34.788432 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-6382-1ec1-b5ac-33625b82d45a) - Created
[0m00:52:35.711758 [debug] [Thread-3 (]: SQL status: OK in 1.440 seconds
[0m00:52:35.715345 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-6382-1ec1-b5ac-33625b82d45a, command-id=01f08f6a-6399-1a8a-84f8-7c2a5277e461) - Closing
[0m00:52:35.715345 [debug] [Thread-3 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m00:52:35.715345 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-6382-1ec1-b5ac-33625b82d45a) - Closing
[0m00:52:35.891333 [info ] [Thread-3 (]: 5 of 7 PASS not_null_bronze_sales_sales_id ..................................... [[32mPASS[0m in 1.63s]
[0m00:52:35.891333 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m00:52:35.891333 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m00:52:35.891333 [info ] [Thread-3 (]: 6 of 7 START test unique_bronze_customer_customer_sk ........................... [RUN]
[0m00:52:35.891333 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m00:52:35.891333 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m00:52:35.891333 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m00:52:35.913464 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m00:52:35.914559 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m00:52:35.919519 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m00:52:35.921637 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m00:52:35.924683 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m00:52:35.924683 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:36.428599 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-647d-1aeb-8d16-fe058b85102f) - Created
[0m00:52:37.311274 [debug] [Thread-3 (]: SQL status: OK in 1.390 seconds
[0m00:52:37.313146 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-647d-1aeb-8d16-fe058b85102f, command-id=01f08f6a-6493-158a-b582-8295b0d6fb99) - Closing
[0m00:52:37.314329 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m00:52:37.314329 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-647d-1aeb-8d16-fe058b85102f) - Closing
[0m00:52:37.496497 [info ] [Thread-3 (]: 6 of 7 PASS unique_bronze_customer_customer_sk ................................. [[32mPASS[0m in 1.61s]
[0m00:52:37.498512 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m00:52:37.498512 [debug] [Thread-3 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m00:52:37.498512 [info ] [Thread-3 (]: 7 of 7 START test unique_bronze_sales_sales_id ................................. [RUN]
[0m00:52:37.498512 [debug] [Thread-3 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m00:52:37.498512 [debug] [Thread-3 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m00:52:37.498512 [debug] [Thread-3 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m00:52:37.498512 [debug] [Thread-3 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m00:52:37.498512 [debug] [Thread-3 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m00:52:37.512267 [debug] [Thread-3 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m00:52:37.512267 [debug] [Thread-3 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m00:52:37.513783 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m00:52:37.514789 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m00:52:37.996820 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-656e-1aa9-bf49-e2461ef5e90c) - Created
[0m00:52:38.683863 [debug] [Thread-3 (]: SQL status: OK in 1.170 seconds
[0m00:52:38.683863 [debug] [Thread-3 (]: Databricks adapter: Cursor(session-id=01f08f6a-656e-1aa9-bf49-e2461ef5e90c, command-id=01f08f6a-6582-16d5-a251-64910831d9fb) - Closing
[0m00:52:38.683863 [debug] [Thread-3 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m00:52:38.683863 [debug] [Thread-3 (]: Databricks adapter: Connection(session-id=01f08f6a-656e-1aa9-bf49-e2461ef5e90c) - Closing
[0m00:52:38.854148 [info ] [Thread-3 (]: 7 of 7 PASS unique_bronze_sales_sales_id ....................................... [[32mPASS[0m in 1.36s]
[0m00:52:38.854148 [debug] [Thread-3 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m00:52:38.854148 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m00:52:38.854148 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m00:52:38.854148 [info ] [MainThread]: 
[0m00:52:38.854148 [info ] [MainThread]: Finished running 7 data tests in 0 hours 0 minutes and 35.35 seconds (35.35s).
[0m00:52:38.854148 [debug] [MainThread]: Command end result
[0m00:52:38.902231 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m00:52:38.909001 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m00:52:38.916002 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m00:52:38.916002 [info ] [MainThread]: 
[0m00:52:38.916002 [info ] [MainThread]: [32mCompleted successfully[0m
[0m00:52:38.916002 [info ] [MainThread]: 
[0m00:52:38.916002 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m00:52:38.916002 [debug] [MainThread]: Command `dbt test` succeeded at 00:52:38.916002 after 50.89 seconds
[0m00:52:38.916002 [debug] [MainThread]: Flushing usage events
[0m01:10:28.874177 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 01:10:28.969241 | a4534fe3-fd87-4598-aa7f-9a0b8ab170d9 ==============================
[0m01:10:28.969241 [info ] [MainThread]: Running with dbt=1.10.11
[0m01:10:28.969241 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'quiet': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m01:10:29.801939 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m01:10:29.801939 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m01:10:29.801939 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m01:10:30.595054 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m01:10:30.891865 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m01:10:31.066558 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 2 files added, 1 files changed.
[0m01:10:31.066558 [debug] [MainThread]: Partial parsing: added file: dbt_eTl://analyses\query_macro.sql
[0m01:10:31.066558 [debug] [MainThread]: Partial parsing: added file: dbt_eTl://macros\multiply_cols.sql
[0m01:10:31.066558 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://analyses\jinja-3.sql
[0m01:10:31.201933 [error] [MainThread]: Encountered an error:
Compilation Error
  Analysis 'analysis.dbt_eTl.jinja-3' (analyses\jinja-3.sql) depends on a node named 'bronze_ales' which was not found
[0m01:10:31.201933 [debug] [MainThread]: Command `dbt build` failed at 01:10:31.201933 after 2.38 seconds
[0m01:10:31.201933 [debug] [MainThread]: Flushing usage events
[0m01:16:46.544778 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 01:16:46.660602 | 7feb6e32-523b-44c7-9bdb-3efe7e431617 ==============================
[0m01:16:46.660602 [info ] [MainThread]: Running with dbt=1.10.11
[0m01:16:46.661666 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt ', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'empty': 'None', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m01:16:46.902660 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:16:46.904666 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:16:46.906659 [debug] [MainThread]: Command `cli deps` succeeded at 01:16:46.906659 after 0.43 seconds
[0m01:16:46.907759 [debug] [MainThread]: Flushing usage events
[0m01:27:59.484119 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 01:27:59.593975 | 2068bcf6-816b-4aad-80bc-7a36a1755d24 ==============================
[0m01:27:59.593975 [info ] [MainThread]: Running with dbt=1.10.11
[0m01:27:59.593975 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt ', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'None', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m01:27:59.842451 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:27:59.845556 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m01:27:59.846555 [debug] [MainThread]: Command `cli deps` succeeded at 01:27:59.846555 after 0.48 seconds
[0m01:27:59.847553 [debug] [MainThread]: Flushing usage events
[0m12:14:34.952797 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 12:14:35.141411 | e0a44458-19b5-471d-a839-460944124784 ==============================
[0m12:14:35.141411 [info ] [MainThread]: Running with dbt=1.10.11
[0m12:14:35.141411 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run --select models/silver', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m12:14:36.000430 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m12:14:36.000430 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m12:14:36.000430 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m12:14:36.815066 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m12:14:37.299835 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m12:14:37.480091 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m12:14:37.482094 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m12:14:37.635804 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m12:14:37.657292 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m12:14:37.679446 [info ] [MainThread]: Found 7 models, 1 seed, 7 data tests, 2 analyses, 6 sources, 688 macros
[0m12:14:37.683262 [info ] [MainThread]: 
[0m12:14:37.683262 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m12:14:37.683262 [info ] [MainThread]: 
[0m12:14:37.683262 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:14:37.683262 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:14:37.683262 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m12:14:37.683262 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m12:14:37.683262 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m12:14:37.683262 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m12:14:37.683262 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:38.773425 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-abf3-149e-841e-5e2d99a53a71) - Created
[0m12:14:39.480140 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m12:14:39.481234 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fc9-abf3-149e-841e-5e2d99a53a71, command-id=01f08fc9-ac12-1ad2-b969-ec7e8314c83a) - Closing
[0m12:14:39.482225 [debug] [ThreadPool]: On list_dbt-project: Close
[0m12:14:39.482225 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-abf3-149e-841e-5e2d99a53a71) - Closing
[0m12:14:39.711891 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m12:14:39.711891 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m12:14:39.727912 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m12:14:39.727912 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m12:14:39.727912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:40.819638 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-ad24-1b3f-b77c-9b3f1f042be6) - Created
[0m12:14:41.769332 [debug] [ThreadPool]: SQL status: OK in 2.040 seconds
[0m12:14:41.773089 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fc9-ad24-1b3f-b77c-9b3f1f042be6, command-id=01f08fc9-ad50-1fbc-bd0b-16e8ebcd1259) - Closing
[0m12:14:41.773089 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m12:14:41.773089 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-ad24-1b3f-b77c-9b3f1f042be6) - Closing
[0m12:14:41.996679 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m12:14:41.996679 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m12:14:41.996679 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m12:14:41.996679 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m12:14:41.996679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m12:14:42.935424 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-ae69-19e0-9fd8-befe3fd6bfbf) - Created
[0m12:14:43.421763 [debug] [ThreadPool]: SQL status: OK in 1.430 seconds
[0m12:14:43.421763 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fc9-ae69-19e0-9fd8-befe3fd6bfbf, command-id=01f08fc9-ae91-1e89-8d91-3341e510d4b7) - Closing
[0m12:14:43.421763 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m12:14:43.421763 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fc9-ae69-19e0-9fd8-befe3fd6bfbf) - Closing
[0m12:14:43.613399 [debug] [Thread-4 (]: Began running node model.dbt_eTl.silver_sales
[0m12:14:43.613399 [info ] [Thread-4 (]: 1 of 1 START sql view model default.silver_sales ............................... [RUN]
[0m12:14:43.613399 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m12:14:43.613399 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m12:14:43.613399 [debug] [Thread-4 (]: Began compiling node model.dbt_eTl.silver_sales
[0m12:14:43.629334 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m12:14:43.629334 [debug] [Thread-4 (]: Began executing node model.dbt_eTl.silver_sales
[0m12:14:43.693540 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m12:14:43.697563 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m12:14:43.749314 [debug] [Thread-4 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m12:14:43.769054 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m12:14:43.770018 [debug] [Thread-4 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m12:14:43.771011 [debug] [Thread-4 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m12:14:43.771011 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m12:14:44.296716 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08fc9-af42-1a5a-806e-9ba8258f1caa) - Created
[0m12:14:45.380087 [debug] [Thread-4 (]: SQL status: OK in 1.610 seconds
[0m12:14:45.380087 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f08fc9-af42-1a5a-806e-9ba8258f1caa, command-id=01f08fc9-af5a-12df-8c4e-6e64705799c7) - Closing
[0m12:14:45.393334 [debug] [Thread-4 (]: Applying tags to relation None
[0m12:14:45.393334 [debug] [Thread-4 (]: On model.dbt_eTl.silver_sales: Close
[0m12:14:45.393334 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08fc9-af42-1a5a-806e-9ba8258f1caa) - Closing
[0m12:14:45.582841 [info ] [Thread-4 (]: 1 of 1 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 1.96s]
[0m12:14:45.583839 [debug] [Thread-4 (]: Finished running node model.dbt_eTl.silver_sales
[0m12:14:45.585837 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m12:14:45.585837 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m12:14:45.585837 [info ] [MainThread]: 
[0m12:14:45.586872 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 7.90 seconds (7.90s).
[0m12:14:45.587840 [debug] [MainThread]: Command end result
[0m12:14:45.712864 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m12:14:45.717825 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m12:14:45.723835 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m12:14:45.724832 [info ] [MainThread]: 
[0m12:14:45.724832 [info ] [MainThread]: [32mCompleted successfully[0m
[0m12:14:45.725833 [info ] [MainThread]: 
[0m12:14:45.726830 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m12:14:45.727490 [debug] [MainThread]: Command `dbt run` succeeded at 12:14:45.727490 after 10.86 seconds
[0m12:14:45.727490 [debug] [MainThread]: Flushing usage events
[0m13:50:50.004626 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 13:50:50.193149 | 3ba195eb-00b6-4f85-ba86-0970f1b7955e ==============================
[0m13:50:50.193149 [info ] [MainThread]: Running with dbt=1.10.11
[0m13:50:50.193149 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m13:50:51.326857 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m13:50:51.326857 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m13:50:51.326857 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m13:50:53.227970 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m13:50:53.736453 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m13:50:53.927718 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m13:50:53.927718 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m13:50:54.084820 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m13:50:54.084820 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m13:50:54.118484 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m13:50:54.118484 [info ] [MainThread]: 
[0m13:50:54.118484 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m13:50:54.118484 [info ] [MainThread]: 
[0m13:50:54.118484 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m13:50:54.118484 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m13:50:54.133634 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m13:50:54.133634 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m13:50:54.135188 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m13:50:54.136322 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m13:50:54.137533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:50:55.670717 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-1f2b-1514-b815-7a5019750ba4) - Created
[0m13:50:56.783527 [debug] [ThreadPool]: SQL status: OK in 2.650 seconds
[0m13:50:56.795813 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd7-1f2b-1514-b815-7a5019750ba4, command-id=01f08fd7-1f62-161c-a339-86028806df43) - Closing
[0m13:50:56.795813 [debug] [ThreadPool]: On list_dbt-project: Close
[0m13:50:56.795813 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-1f2b-1514-b815-7a5019750ba4) - Closing
[0m13:50:57.296452 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m13:50:57.296452 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m13:50:57.296452 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m13:50:57.296452 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m13:50:57.301892 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:50:58.421803 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-20d7-12fc-9e8f-c4fd458e4e55) - Created
[0m13:50:58.930552 [debug] [ThreadPool]: SQL status: OK in 1.630 seconds
[0m13:50:58.930552 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd7-20d7-12fc-9e8f-c4fd458e4e55, command-id=01f08fd7-2102-17b9-8a22-8135a01ed1c0) - Closing
[0m13:50:58.930552 [debug] [ThreadPool]: On list_dbt-project: Close
[0m13:50:58.930552 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-20d7-12fc-9e8f-c4fd458e4e55) - Closing
[0m13:50:59.544793 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_default) - Creating connection
[0m13:50:59.549482 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_default'
[0m13:50:59.549482 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "default"
"
[0m13:50:59.568378 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_default"
[0m13:50:59.568378 [debug] [ThreadPool]: On create_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_default"} */
create schema if not exists `dbt-project`.`default`
  
[0m13:50:59.569381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:01.018351 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-2252-1ae5-9916-58e21462e9a4) - Created
[0m13:51:01.800513 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_default"} */
create schema if not exists `dbt-project`.`default`
  
: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [NO_SUCH_CATALOG_EXCEPTION] org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1037)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:786)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:771)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$getCatalogProto$1(ManagedCatalogClientImpl.scala:657)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7501)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7500)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:74)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:268)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7481)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7467)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalogProto(ManagedCatalogClientImpl.scala:632)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalog(ManagedCatalogClientImpl.scala:623)
	at com.databricks.sql.managedcatalog.ManagedCatalogCommon.$anonfun$getCatalogMetadata$5(ManagedCatalogCommon.scala:455)
	at scala.Option.getOrElse(Option.scala:201)
	at com.databricks.sql.managedcatalog.ManagedCatalogCommon.getCatalogMetadata(ManagedCatalogCommon.scala:452)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$getCatalogMetadata$1(ProfiledManagedCatalog.scala:118)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1836)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.getCatalogMetadata(ProfiledManagedCatalog.scala:118)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.getCatalog(ManagedCatalogSessionCatalog.scala:656)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.$anonfun$resolveNamespaceCollation$1(DataSourceV2Strategy.scala:115)
	at scala.Option.orElse(Option.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.resolveNamespaceCollation(DataSourceV2Strategy.scala:112)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.apply(DataSourceV2Strategy.scala:497)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:88)
	at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:88)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:86)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$6(QueryPlanner.scala:112)
	at scala.collection.IterableOnceOps.foldLeft(IterableOnce.scala:727)
	at scala.collection.IterableOnceOps.foldLeft$(IterableOnce.scala:721)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1306)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$5(QueryPlanner.scala:109)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$.$anonfun$createSparkPlan$1(QueryExecution.scala:1384)
	at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
	at org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:1384)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$2(QueryExecution.scala:687)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:655)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:810)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$6(QueryExecution.scala:810)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:803)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:800)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:800)
	at org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:789)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:799)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:798)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhaseWithTracker$1(QueryExecution.scala:828)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:253)
	at org.apache.spark.sql.execution.QueryExecution.executePhaseWithTracker(QueryExecution.scala:828)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$1(QueryExecution.scala:684)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
	at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
	at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:693)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$2(QueryExecution.scala:702)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$1(QueryExecution.scala:702)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
	at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
	at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:734)
	at org.apache.spark.sql.execution.QueryExecution.simpleString(QueryExecution.scala:907)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$explainString(QueryExecution.scala:974)
	at org.apache.spark.sql.execution.QueryExecution.explainStringLocal(QueryExecution.scala:935)
	at org.apache.spark.sql.execution.QueryExecution.explainString(QueryExecution.scala:928)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:464)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:458)
	at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:834)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:386)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
	at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
	at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
	at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:386)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1747)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:379)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:432)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:412)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:672)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:699)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:846)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:585)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:846)
	... 53 more
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$getCatalogProto$1(ManagedCatalogClientImpl.scala:657)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7501)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7500)
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:74)
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:268)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7481)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7467)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalogProto(ManagedCatalogClientImpl.scala:632)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalog(ManagedCatalogClientImpl.scala:623)
		at com.databricks.sql.managedcatalog.ManagedCatalogCommon.$anonfun$getCatalogMetadata$5(ManagedCatalogCommon.scala:455)
		at scala.Option.getOrElse(Option.scala:201)
		at com.databricks.sql.managedcatalog.ManagedCatalogCommon.getCatalogMetadata(ManagedCatalogCommon.scala:452)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$getCatalogMetadata$1(ProfiledManagedCatalog.scala:118)
		at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1836)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.getCatalogMetadata(ProfiledManagedCatalog.scala:118)
		at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.getCatalog(ManagedCatalogSessionCatalog.scala:656)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.$anonfun$resolveNamespaceCollation$1(DataSourceV2Strategy.scala:115)
		at scala.Option.orElse(Option.scala:477)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.resolveNamespaceCollation(DataSourceV2Strategy.scala:112)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.apply(DataSourceV2Strategy.scala:497)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:88)
		at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:88)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:86)
		at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
		at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$6(QueryPlanner.scala:112)
		at scala.collection.IterableOnceOps.foldLeft(IterableOnce.scala:727)
		at scala.collection.IterableOnceOps.foldLeft$(IterableOnce.scala:721)
		at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1306)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$5(QueryPlanner.scala:109)
		at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
		at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
		at org.apache.spark.sql.execution.QueryExecution$.$anonfun$createSparkPlan$1(QueryExecution.scala:1384)
		at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
		at org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:1384)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$2(QueryExecution.scala:687)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:655)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:810)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
		at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
		at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
		at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
		at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
		at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
		at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
		at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
		at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)
		at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
		at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$6(QueryExecution.scala:810)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:803)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:800)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:800)
		at org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:789)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:799)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:798)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhaseWithTracker$1(QueryExecution.scala:828)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:253)
		at org.apache.spark.sql.execution.QueryExecution.executePhaseWithTracker(QueryExecution.scala:828)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$1(QueryExecution.scala:684)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
		at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:693)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$2(QueryExecution.scala:702)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$1(QueryExecution.scala:702)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
		at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:734)
		at org.apache.spark.sql.execution.QueryExecution.simpleString(QueryExecution.scala:907)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$explainString(QueryExecution.scala:974)
		at org.apache.spark.sql.execution.QueryExecution.explainStringLocal(QueryExecution.scala:935)
		at org.apache.spark.sql.execution.QueryExecution.explainString(QueryExecution.scala:928)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:464)
		at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:458)
		at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:834)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:386)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
		at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
		at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
		at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:386)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:863)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:385)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:238)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:787)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:502)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:498)
		at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:496)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:578)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:570)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:529)
		at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:529)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:505)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:570)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:570)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:374)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		... 62 more
, operation-id=01f08fd7-228f-18cf-a1b5-e569467b5436
[0m13:51:01.800513 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
macro create_schema
: Database Error
  [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
[0m13:51:01.800513 [debug] [ThreadPool]: On create_dbt-project_default: Close
[0m13:51:01.800513 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-2252-1ae5-9916-58e21462e9a4) - Closing
[0m13:51:02.147587 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_bronze) - Creating connection
[0m13:51:02.149326 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_bronze'
[0m13:51:02.151342 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "bronze"
"
[0m13:51:02.157396 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_bronze"
[0m13:51:02.157396 [debug] [ThreadPool]: On create_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_bronze"} */
create schema if not exists `dbt-project`.`bronze`
  
[0m13:51:02.159403 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m13:51:03.326748 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-23bd-1b9e-92a9-e273f7801ab0) - Created
[0m13:51:03.966888 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_bronze"} */
create schema if not exists `dbt-project`.`bronze`
  
: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [NO_SUCH_CATALOG_EXCEPTION] org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1037)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:786)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:771)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.analysis.NoSuchCatalogException: [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$getCatalogProto$1(ManagedCatalogClientImpl.scala:657)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7501)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7500)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:74)
	at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:268)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7481)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7467)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalogProto(ManagedCatalogClientImpl.scala:632)
	at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalog(ManagedCatalogClientImpl.scala:623)
	at com.databricks.sql.managedcatalog.ManagedCatalogCommon.$anonfun$getCatalogMetadata$5(ManagedCatalogCommon.scala:455)
	at scala.Option.getOrElse(Option.scala:201)
	at com.databricks.sql.managedcatalog.ManagedCatalogCommon.getCatalogMetadata(ManagedCatalogCommon.scala:452)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$getCatalogMetadata$1(ProfiledManagedCatalog.scala:118)
	at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1836)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
	at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.getCatalogMetadata(ProfiledManagedCatalog.scala:118)
	at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.getCatalog(ManagedCatalogSessionCatalog.scala:656)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.$anonfun$resolveNamespaceCollation$1(DataSourceV2Strategy.scala:115)
	at scala.Option.orElse(Option.scala:477)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.resolveNamespaceCollation(DataSourceV2Strategy.scala:112)
	at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.apply(DataSourceV2Strategy.scala:497)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:88)
	at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:88)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:86)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$6(QueryPlanner.scala:112)
	at scala.collection.IterableOnceOps.foldLeft(IterableOnce.scala:727)
	at scala.collection.IterableOnceOps.foldLeft$(IterableOnce.scala:721)
	at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1306)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$5(QueryPlanner.scala:109)
	at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
	at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
	at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
	at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
	at org.apache.spark.sql.execution.QueryExecution$.$anonfun$createSparkPlan$1(QueryExecution.scala:1384)
	at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
	at org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:1384)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$2(QueryExecution.scala:687)
	at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
	at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
	at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:655)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:810)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
	at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
	at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)
	at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
	at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$6(QueryExecution.scala:810)
	at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:803)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:800)
	at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:800)
	at org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:789)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:799)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:798)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhaseWithTracker$1(QueryExecution.scala:828)
	at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:253)
	at org.apache.spark.sql.execution.QueryExecution.executePhaseWithTracker(QueryExecution.scala:828)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$1(QueryExecution.scala:684)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
	at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
	at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:693)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$2(QueryExecution.scala:702)
	at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
	at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$1(QueryExecution.scala:702)
	at scala.util.Try$.apply(Try.scala:217)
	at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
	at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
	at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:734)
	at org.apache.spark.sql.execution.QueryExecution.simpleString(QueryExecution.scala:907)
	at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$explainString(QueryExecution.scala:974)
	at org.apache.spark.sql.execution.QueryExecution.explainStringLocal(QueryExecution.scala:935)
	at org.apache.spark.sql.execution.QueryExecution.explainString(QueryExecution.scala:928)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:464)
	at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:458)
	at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:834)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:386)
	at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
	at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
	at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
	at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
	at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:386)
	at org.apache.spark.util.Utils$.getTryWithCallerStacktrace(Utils.scala:1747)
	at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
	at org.apache.spark.sql.execution.QueryExecution.commandExecuted(QueryExecution.scala:379)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:432)
	at org.apache.spark.sql.classic.Dataset.<init>(Dataset.scala:412)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.getOrCreateDF(SparkExecuteStatementOperation.scala:672)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.analyzeQuery(SparkExecuteStatementOperation.scala:699)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$5(SparkExecuteStatementOperation.scala:846)
	at org.apache.spark.util.Utils$.timeTakenMs(Utils.scala:585)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:846)
	... 53 more
	Suppressed: org.apache.spark.util.Utils$OriginalTryStackTraceException: Full stacktrace of original doTryWithCallerStacktrace caller
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$getCatalogProto$1(ManagedCatalogClientImpl.scala:657)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$2(ManagedCatalogClientImpl.scala:7501)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.$anonfun$recordAndWrapExceptionBase$1(ManagedCatalogClientImpl.scala:7500)
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException(ErrorDetailsHandler.scala:74)
		at com.databricks.managedcatalog.ErrorDetailsHandler.wrapServiceException$(ErrorDetailsHandler.scala:66)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.wrapServiceException(ManagedCatalogClientImpl.scala:268)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapExceptionBase(ManagedCatalogClientImpl.scala:7481)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.recordAndWrapException(ManagedCatalogClientImpl.scala:7467)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalogProto(ManagedCatalogClientImpl.scala:632)
		at com.databricks.managedcatalog.ManagedCatalogClientImpl.getCatalog(ManagedCatalogClientImpl.scala:623)
		at com.databricks.sql.managedcatalog.ManagedCatalogCommon.$anonfun$getCatalogMetadata$5(ManagedCatalogCommon.scala:455)
		at scala.Option.getOrElse(Option.scala:201)
		at com.databricks.sql.managedcatalog.ManagedCatalogCommon.getCatalogMetadata(ManagedCatalogCommon.scala:452)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$getCatalogMetadata$1(ProfiledManagedCatalog.scala:118)
		at org.apache.spark.sql.catalyst.MetricKeyUtils$.measure(MetricKey.scala:1836)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.$anonfun$profile$1(ProfiledManagedCatalog.scala:64)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.profile(ProfiledManagedCatalog.scala:63)
		at com.databricks.sql.managedcatalog.ProfiledManagedCatalog.getCatalogMetadata(ProfiledManagedCatalog.scala:118)
		at com.databricks.sql.managedcatalog.ManagedCatalogSessionCatalog.getCatalog(ManagedCatalogSessionCatalog.scala:656)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.$anonfun$resolveNamespaceCollation$1(DataSourceV2Strategy.scala:115)
		at scala.Option.orElse(Option.scala:477)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.resolveNamespaceCollation(DataSourceV2Strategy.scala:112)
		at org.apache.spark.sql.execution.datasources.v2.DataSourceV2Strategy.apply(DataSourceV2Strategy.scala:497)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$3(QueryPlanner.scala:88)
		at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$2(QueryPlanner.scala:88)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$1(QueryPlanner.scala:86)
		at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:601)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
		at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$6(QueryPlanner.scala:112)
		at scala.collection.IterableOnceOps.foldLeft(IterableOnce.scala:727)
		at scala.collection.IterableOnceOps.foldLeft$(IterableOnce.scala:721)
		at scala.collection.AbstractIterator.foldLeft(Iterator.scala:1306)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.$anonfun$plan$5(QueryPlanner.scala:109)
		at scala.collection.Iterator$$anon$10.nextCur(Iterator.scala:594)
		at scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:608)
		at org.apache.spark.sql.catalyst.planning.QueryPlanner.plan(QueryPlanner.scala:127)
		at org.apache.spark.sql.execution.SparkStrategies.plan(SparkStrategies.scala:107)
		at org.apache.spark.sql.execution.QueryExecution$.$anonfun$createSparkPlan$1(QueryExecution.scala:1384)
		at com.databricks.spark.util.MemoryTracker$.withThreadAllocatedBytes(MemoryTracker.scala:51)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.measureRule(QueryPlanningTracker.scala:338)
		at org.apache.spark.sql.execution.QueryExecution$.createSparkPlan(QueryExecution.scala:1384)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$2(QueryExecution.scala:687)
		at com.databricks.spark.util.FrameProfiler$.$anonfun$record$1(FrameProfiler.scala:113)
		at com.databricks.spark.util.FrameProfilerExporter$.maybeExportFrameProfiler(FrameProfilerExporter.scala:159)
		at com.databricks.spark.util.FrameProfiler$.record(FrameProfiler.scala:104)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:655)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$7(QueryExecution.scala:810)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withExecutionPhase$1(SQLExecution.scala:155)
		at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
		at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
		at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
		at com.databricks.util.TracingSpanUtils$.$anonfun$withTracing$4(TracingSpanUtils.scala:235)
		at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:129)
		at com.databricks.util.TracingSpanUtils$.withTracing(TracingSpanUtils.scala:233)
		at com.databricks.tracing.TracingUtils$.withTracing(TracingUtils.scala:296)
		at com.databricks.spark.util.DatabricksTracingHelper.withSpan(DatabricksSparkTracingHelper.scala:115)
		at com.databricks.spark.util.DBRTracing$.withSpan(DBRTracing.scala:47)
		at org.apache.spark.sql.execution.SQLExecution$.withExecutionPhase(SQLExecution.scala:136)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$6(QueryExecution.scala:810)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$4(QueryExecution.scala:803)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$3(QueryExecution.scala:800)
		at com.databricks.util.LexicalThreadLocal$Handle.runWith(LexicalThreadLocal.scala:63)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:800)
		at org.apache.spark.sql.execution.QueryExecution.withQueryExecutionId(QueryExecution.scala:789)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:799)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:798)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhaseWithTracker$1(QueryExecution.scala:828)
		at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:253)
		at org.apache.spark.sql.execution.QueryExecution.executePhaseWithTracker(QueryExecution.scala:828)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazySparkPlan$1(QueryExecution.scala:684)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
		at org.apache.spark.sql.execution.QueryExecution.sparkPlan(QueryExecution.scala:693)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$2(QueryExecution.scala:702)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyExecutedPlan$1(QueryExecution.scala:702)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		at org.apache.spark.util.LazyTry.get(LazyTry.scala:75)
		at org.apache.spark.sql.execution.QueryExecution.executedPlan(QueryExecution.scala:734)
		at org.apache.spark.sql.execution.QueryExecution.simpleString(QueryExecution.scala:907)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$explainString(QueryExecution.scala:974)
		at org.apache.spark.sql.execution.QueryExecution.explainStringLocal(QueryExecution.scala:935)
		at org.apache.spark.sql.execution.QueryExecution.explainString(QueryExecution.scala:928)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$13(SQLExecution.scala:464)
		at com.databricks.sql.util.MemoryTrackerHelper.withMemoryTracking(MemoryTrackerHelper.scala:111)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$12(SQLExecution.scala:458)
		at org.apache.spark.sql.execution.SQLExecution$.withSessionTagsApplied(SQLExecution.scala:834)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$11(SQLExecution.scala:386)
		at org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:97)
		at org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:121)
		at org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:115)
		at org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:120)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$10(SQLExecution.scala:386)
		at org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:863)
		at org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId0$1(SQLExecution.scala:385)
		at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:860)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId0(SQLExecution.scala:238)
		at org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:787)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$2(QueryExecution.scala:502)
		at org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:1449)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$1(QueryExecution.scala:498)
		at org.apache.spark.sql.execution.QueryExecution.withMVTagsIfNecessary(QueryExecution.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.org$apache$spark$sql$execution$QueryExecution$$eagerlyExecute$1(QueryExecution.scala:496)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:578)
		at org.apache.spark.sql.execution.QueryExecution$$anonfun$$nestedInanonfun$eagerlyExecuteCommands$8$1.applyOrElse(QueryExecution.scala:570)
		at org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:529)
		at org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(origin.scala:121)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:529)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.org$apache$spark$sql$catalyst$plans$logical$AnalysisHelper$$super$transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning(AnalysisHelper.scala:361)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.transformDownWithPruning$(AnalysisHelper.scala:357)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.transformDownWithPruning(LogicalPlan.scala:42)
		at org.apache.spark.sql.catalyst.trees.TreeNode.transformDown(TreeNode.scala:505)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$eagerlyExecuteCommands$8(QueryExecution.scala:570)
		at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:418)
		at org.apache.spark.sql.execution.QueryExecution.eagerlyExecuteCommands(QueryExecution.scala:570)
		at org.apache.spark.sql.execution.QueryExecution.$anonfun$lazyCommandExecuted$1(QueryExecution.scala:374)
		at scala.util.Try$.apply(Try.scala:217)
		at org.apache.spark.util.Utils$.doTryWithCallerStacktrace(Utils.scala:1686)
		at org.apache.spark.util.LazyTry.tryT$lzycompute(LazyTry.scala:60)
		at org.apache.spark.util.LazyTry.tryT(LazyTry.scala:59)
		... 62 more
, operation-id=01f08fd7-23f0-1ec7-ae97-2636d3779897
[0m13:51:03.974538 [debug] [ThreadPool]: Databricks adapter: Exception while trying to execute query
macro create_schema
: Database Error
  [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
[0m13:51:03.974538 [debug] [ThreadPool]: On create_dbt-project_bronze: Close
[0m13:51:03.974538 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd7-23bd-1b9e-92a9-e273f7801ab0) - Closing
[0m13:51:04.246993 [info ] [MainThread]: 
[0m13:51:04.246993 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 10.13 seconds (10.13s).
[0m13:51:04.246993 [error] [MainThread]: Encountered an error:
Database Error
  Database Error
    [NO_SUCH_CATALOG_EXCEPTION] Catalog 'dbt-project' was not found. Please verify the catalog name and then retry the query or command again. SQLSTATE: 42704
[0m13:51:04.262637 [debug] [MainThread]: Command `dbt run` failed at 13:51:04.262637 after 14.33 seconds
[0m13:51:04.268622 [debug] [MainThread]: Flushing usage events
[0m14:06:54.910791 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:06:55.224943 | a377f2c1-1c0a-4cbe-bce6-b3ac0a7cf83e ==============================
[0m14:06:55.224943 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:06:55.240873 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:06:56.605100 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:06:56.608609 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:06:56.608609 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:06:58.445150 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:06:58.884193 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:06:59.226152 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:06:59.226152 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:06:59.370843 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:06:59.386745 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:06:59.402482 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:06:59.402482 [info ] [MainThread]: 
[0m14:06:59.402482 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:06:59.402482 [info ] [MainThread]: 
[0m14:06:59.418247 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:06:59.418247 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:06:59.418247 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:06:59.418247 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:06:59.418247 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:06:59.418247 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:06:59.426745 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:07:01.244704 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-5e9a-11e5-9a13-edbcd6677530) - Created
[0m14:07:01.742955 [debug] [ThreadPool]: SQL status: OK in 2.300 seconds
[0m14:07:01.746767 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd9-5e9a-11e5-9a13-edbcd6677530, command-id=01f08fd9-5ee6-1213-9daf-6ba0e5e3d49e) - Closing
[0m14:07:01.746767 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:07:01.748773 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-5e9a-11e5-9a13-edbcd6677530) - Closing
[0m14:07:02.126988 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:07:02.126988 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:07:02.126988 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:07:02.126988 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:07:02.126988 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:07:03.217749 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-5feb-1125-bde6-e260afc4ef86) - Created
[0m14:07:03.662529 [debug] [ThreadPool]: SQL status: OK in 1.540 seconds
[0m14:07:03.662529 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd9-5feb-1125-bde6-e260afc4ef86, command-id=01f08fd9-6012-17ae-bbd9-e3a918ab8d22) - Closing
[0m14:07:03.662529 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:07:03.662529 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-5feb-1125-bde6-e260afc4ef86) - Closing
[0m14:07:03.918317 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_bronze) - Creating connection
[0m14:07:03.918317 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_bronze'
[0m14:07:03.918317 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "bronze"
"
[0m14:07:03.932339 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_bronze"
[0m14:07:03.932339 [debug] [ThreadPool]: On create_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_bronze"} */
create schema if not exists `dbt-project`.`bronze`
  
[0m14:07:03.932339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:07:04.679259 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-60d0-1432-a90e-f344d3e84bb7) - Created
[0m14:07:05.316573 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m14:07:05.316573 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd9-60d0-1432-a90e-f344d3e84bb7, command-id=01f08fd9-60f1-1b4f-b81d-cd4edf420d89) - Closing
[0m14:07:05.332531 [debug] [ThreadPool]: On create_dbt-project_bronze: Close
[0m14:07:05.332531 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-60d0-1432-a90e-f344d3e84bb7) - Closing
[0m14:07:05.550205 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:07:05.552363 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:07:05.567252 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:07:05.567252 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:07:05.567252 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:07:06.334763 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-61cb-1072-8b65-55a205083dde) - Created
[0m14:07:07.086572 [debug] [ThreadPool]: SQL status: OK in 1.520 seconds
[0m14:07:07.117972 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd9-61cb-1072-8b65-55a205083dde, command-id=01f08fd9-61ed-13fa-8b06-45deaf3395dc) - Closing
[0m14:07:07.117972 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:07:07.117972 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-61cb-1072-8b65-55a205083dde) - Closing
[0m14:07:07.354710 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:07:07.356723 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:07:07.358731 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:07:07.358731 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:07:07.358731 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:07:08.123155 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-62de-12d3-aa35-4d9dcd4c80db) - Created
[0m14:07:08.588813 [debug] [ThreadPool]: SQL status: OK in 1.230 seconds
[0m14:07:08.593789 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fd9-62de-12d3-aa35-4d9dcd4c80db, command-id=01f08fd9-62ff-168a-bb66-cb8610e5ccaf) - Closing
[0m14:07:08.595804 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:07:08.595804 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fd9-62de-12d3-aa35-4d9dcd4c80db) - Closing
[0m14:07:08.834819 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:07:08.834819 [info ] [Thread-6 (]: 1 of 7 START sql table model default.bronze_customer ........................... [RUN]
[0m14:07:08.834819 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:07:08.834819 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:07:08.834819 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:07:08.838543 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:07:08.838543 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:07:08.877512 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m14:07:08.877512 [warn ] [Thread-6 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:07:08.931707 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:07:08.938504 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:07:08.938504 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:07:08.938504 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:09.716511 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-63d1-127e-8642-e07d64519f9c) - Created
[0m14:07:12.818362 [debug] [Thread-6 (]: SQL status: OK in 3.880 seconds
[0m14:07:12.820372 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-63d1-127e-8642-e07d64519f9c, command-id=01f08fd9-63f2-142d-ade8-56ff1fb20676) - Closing
[0m14:07:12.836168 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:12.853447 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:07:12.853447 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-63d1-127e-8642-e07d64519f9c) - Closing
[0m14:07:13.175601 [info ] [Thread-6 (]: 1 of 7 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.33s]
[0m14:07:13.175601 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:07:13.175601 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_date
[0m14:07:13.175601 [info ] [Thread-6 (]: 2 of 7 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:07:13.175601 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:07:13.175601 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:07:13.175601 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:07:13.185279 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:07:13.187054 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:07:13.200269 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:07:13.218269 [debug] [Thread-6 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:07:13.218269 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:07:13.226788 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:07:13.226788 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:07:13.226788 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:14.402872 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-669c-1ab9-b41e-d0e82920a7d4) - Created
[0m14:07:15.157853 [debug] [Thread-6 (]: SQL status: OK in 1.930 seconds
[0m14:07:15.161883 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-669c-1ab9-b41e-d0e82920a7d4, command-id=01f08fd9-66bc-161b-9b04-a34db2f05c1a) - Closing
[0m14:07:15.161883 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:15.161883 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_date: Close
[0m14:07:15.173707 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-669c-1ab9-b41e-d0e82920a7d4) - Closing
[0m14:07:15.381315 [info ] [Thread-6 (]: 2 of 7 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.21s]
[0m14:07:15.381315 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:07:15.381315 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:07:15.381315 [info ] [Thread-6 (]: 3 of 7 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:07:15.397049 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:07:15.397049 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:07:15.397049 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:07:15.397049 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:07:15.397049 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:07:15.397049 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m14:07:15.397049 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:07:15.397049 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:07:15.397049 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:07:15.397049 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:16.312617 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-67b9-1097-a035-ac375bc62f87) - Created
[0m14:07:18.994858 [debug] [Thread-6 (]: SQL status: OK in 3.600 seconds
[0m14:07:18.994858 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-67b9-1097-a035-ac375bc62f87, command-id=01f08fd9-67e0-1bfb-8e19-231da56e3c26) - Closing
[0m14:07:19.002992 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:19.002992 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:07:19.002992 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-67b9-1097-a035-ac375bc62f87) - Closing
[0m14:07:19.307866 [info ] [Thread-6 (]: 3 of 7 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.91s]
[0m14:07:19.321270 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:07:19.321270 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:07:19.324871 [info ] [Thread-6 (]: 4 of 7 START sql view model default.bronze_returns ............................. [RUN]
[0m14:07:19.326844 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:07:19.326844 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:07:19.329642 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:07:19.433299 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:07:19.449226 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:07:19.449226 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:07:19.449226 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:07:19.449226 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:07:19.449226 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:07:19.449226 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:07:19.449226 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:20.379406 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6a2b-1ea9-bd10-0b80ce161b21) - Created
[0m14:07:21.278262 [debug] [Thread-6 (]: SQL status: OK in 1.830 seconds
[0m14:07:21.278262 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-6a2b-1ea9-bd10-0b80ce161b21, command-id=01f08fd9-6a4f-14d2-a68f-1af1134e74bd) - Closing
[0m14:07:21.278262 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:21.278262 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:07:21.286594 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6a2b-1ea9-bd10-0b80ce161b21) - Closing
[0m14:07:21.577884 [info ] [Thread-6 (]: 4 of 7 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.25s]
[0m14:07:21.585421 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:07:21.585421 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:07:21.588447 [info ] [Thread-6 (]: 5 of 7 START sql view model default.bronze_sales ............................... [RUN]
[0m14:07:21.588447 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:07:21.592206 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:07:21.592206 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:07:21.596487 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:07:21.596487 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:07:21.604950 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:07:21.608353 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:07:21.608353 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:07:21.610398 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:07:21.611640 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:07:21.611640 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:22.394748 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6b5c-11f1-8ef9-550828c975c3) - Created
[0m14:07:23.048631 [debug] [Thread-6 (]: SQL status: OK in 1.440 seconds
[0m14:07:23.052660 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-6b5c-11f1-8ef9-550828c975c3, command-id=01f08fd9-6b7f-19ee-a64a-f9d7287d56b3) - Closing
[0m14:07:23.054669 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:23.054669 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:07:23.056678 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6b5c-11f1-8ef9-550828c975c3) - Closing
[0m14:07:23.285240 [info ] [Thread-6 (]: 5 of 7 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 1.69s]
[0m14:07:23.285240 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:07:23.285240 [debug] [Thread-6 (]: Began running node model.dbt_eTl.bronze_store
[0m14:07:23.285240 [info ] [Thread-6 (]: 6 of 7 START sql table model default.bronze_store .............................. [RUN]
[0m14:07:23.292390 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:07:23.292390 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:07:23.294412 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:07:23.301154 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:07:23.301154 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:07:23.302930 [debug] [Thread-6 (]: MATERIALIZING TABLE
[0m14:07:23.306720 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:07:23.307041 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:07:23.311107 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:07:23.311107 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:24.059862 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6c5e-12ad-a18f-e820fe3a1954) - Created
[0m14:07:30.848525 [debug] [Thread-6 (]: SQL status: OK in 7.540 seconds
[0m14:07:30.848525 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-6c5e-12ad-a18f-e820fe3a1954, command-id=01f08fd9-6c7e-10c4-a377-8875fc3f5507) - Closing
[0m14:07:31.176227 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:31.177885 [debug] [Thread-6 (]: On model.dbt_eTl.bronze_store: Close
[0m14:07:31.178487 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-6c5e-12ad-a18f-e820fe3a1954) - Closing
[0m14:07:31.617561 [info ] [Thread-6 (]: 6 of 7 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 8.33s]
[0m14:07:31.622651 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:07:31.622651 [debug] [Thread-6 (]: Began running node model.dbt_eTl.silver_sales
[0m14:07:31.622651 [info ] [Thread-6 (]: 7 of 7 START sql view model default.silver_sales ............................... [RUN]
[0m14:07:31.626483 [debug] [Thread-6 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:07:31.629294 [debug] [Thread-6 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:07:31.630758 [debug] [Thread-6 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:07:31.640430 [debug] [Thread-6 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:07:31.641386 [debug] [Thread-6 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:07:31.649986 [debug] [Thread-6 (]: MATERIALIZING VIEW
[0m14:07:31.649986 [debug] [Thread-6 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:07:31.649986 [debug] [Thread-6 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:07:31.658244 [debug] [Thread-6 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:07:31.659400 [debug] [Thread-6 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:07:31.660653 [debug] [Thread-6 (]: Opening a new connection, currently in state init
[0m14:07:33.157925 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-71bc-19e5-b4c1-e6c36883b992) - Created
[0m14:07:34.217802 [debug] [Thread-6 (]: SQL status: OK in 2.550 seconds
[0m14:07:34.217802 [debug] [Thread-6 (]: Databricks adapter: Cursor(session-id=01f08fd9-71bc-19e5-b4c1-e6c36883b992, command-id=01f08fd9-71eb-1255-b3f2-40023577fcdf) - Closing
[0m14:07:34.220216 [debug] [Thread-6 (]: Applying tags to relation None
[0m14:07:34.220216 [debug] [Thread-6 (]: On model.dbt_eTl.silver_sales: Close
[0m14:07:34.222221 [debug] [Thread-6 (]: Databricks adapter: Connection(session-id=01f08fd9-71bc-19e5-b4c1-e6c36883b992) - Closing
[0m14:07:35.097967 [info ] [Thread-6 (]: 7 of 7 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 3.47s]
[0m14:07:35.097967 [debug] [Thread-6 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:07:35.097967 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:07:35.097967 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:07:35.105945 [info ] [MainThread]: 
[0m14:07:35.105945 [info ] [MainThread]: Finished running 3 table models, 4 view models in 0 hours 0 minutes and 35.68 seconds (35.68s).
[0m14:07:35.112347 [debug] [MainThread]: Command end result
[0m14:07:35.200248 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:07:35.204961 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:07:35.218937 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:07:35.219714 [info ] [MainThread]: 
[0m14:07:35.223859 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:07:35.225864 [info ] [MainThread]: 
[0m14:07:35.232077 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m14:07:35.239363 [debug] [MainThread]: Command `dbt run` succeeded at 14:07:35.239363 after 40.37 seconds
[0m14:07:35.239363 [debug] [MainThread]: Flushing usage events
[0m14:18:39.135023 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:18:39.278621 | 34bd50d0-ba0d-43cc-89ed-6c326438c449 ==============================
[0m14:18:39.278621 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:18:39.278621 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run --select model/silver', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m14:18:40.250229 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:18:40.250229 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:18:40.250229 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:18:41.165570 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:18:41.587340 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:18:41.791624 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:18:41.791624 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:18:41.976264 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:18:41.984145 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:18:41.984145 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:18:42.000865 [warn ] [MainThread]: The selection criterion 'model/silver' does not match any enabled nodes
[0m14:18:42.000865 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m14:18:42.007262 [debug] [MainThread]: Command end result
[0m14:18:42.047208 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:18:42.050973 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:18:42.055870 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:18:42.057879 [debug] [MainThread]: Command `dbt run` succeeded at 14:18:42.057879 after 2.97 seconds
[0m14:18:42.057879 [debug] [MainThread]: Flushing usage events
[0m14:19:16.984056 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:19:17.077597 | 034e2a08-4f13-4216-a009-78cc07d0171c ==============================
[0m14:19:17.077597 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:19:17.080078 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run --select models/silver', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:19:18.082833 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:19:18.082833 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:19:18.082833 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:19:19.011138 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:19:19.420704 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:19:19.643423 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:19:19.643423 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:19:19.853281 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:19:19.860084 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:19:19.861038 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:19:19.876906 [info ] [MainThread]: 
[0m14:19:19.876906 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:19:19.876906 [info ] [MainThread]: 
[0m14:19:19.876906 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:19:19.881528 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:19:19.882538 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:19:19.882538 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:19:19.883543 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:19:19.883543 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:19:19.883543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:21.237152 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-17d2-1e64-9a73-7273435f546d) - Created
[0m14:19:21.761137 [debug] [ThreadPool]: SQL status: OK in 1.880 seconds
[0m14:19:21.764159 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-17d2-1e64-9a73-7273435f546d, command-id=01f08fdb-17fa-17f1-9d4b-55ffee58b91c) - Closing
[0m14:19:21.764159 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:19:21.766172 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-17d2-1e64-9a73-7273435f546d) - Closing
[0m14:19:21.994676 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:19:22.001327 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:19:22.010362 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:19:22.010362 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:19:22.010362 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:22.935290 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-18d5-11fc-a2a1-fe0edd35991b) - Created
[0m14:19:24.448487 [debug] [ThreadPool]: SQL status: OK in 2.440 seconds
[0m14:19:24.460971 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-18d5-11fc-a2a1-fe0edd35991b, command-id=01f08fdb-18f9-1ba3-bfdc-26631dab1191) - Closing
[0m14:19:24.473601 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:19:24.473601 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-18d5-11fc-a2a1-fe0edd35991b) - Closing
[0m14:19:24.755441 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:19:24.760520 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:19:24.763198 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:19:24.763198 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:19:24.763198 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:19:25.809460 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-1a8e-1e5d-8744-a29887818c26) - Created
[0m14:19:26.332190 [debug] [ThreadPool]: SQL status: OK in 1.570 seconds
[0m14:19:26.340237 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-1a8e-1e5d-8744-a29887818c26, command-id=01f08fdb-1ab0-1d8c-88d5-761d9a986823) - Closing
[0m14:19:26.342253 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:19:26.344359 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-1a8e-1e5d-8744-a29887818c26) - Closing
[0m14:19:26.599201 [debug] [Thread-4 (]: Began running node model.dbt_eTl.silver_sales
[0m14:19:26.599201 [info ] [Thread-4 (]: 1 of 1 START sql view model default.silver_sales ............................... [RUN]
[0m14:19:26.605827 [debug] [Thread-4 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:19:26.605827 [debug] [Thread-4 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:19:26.605827 [debug] [Thread-4 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:19:26.626834 [debug] [Thread-4 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:19:26.626834 [debug] [Thread-4 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:19:26.660548 [debug] [Thread-4 (]: MATERIALIZING VIEW
[0m14:19:26.660548 [warn ] [Thread-4 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:19:26.676893 [debug] [Thread-4 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:19:26.682674 [debug] [Thread-4 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:19:26.682674 [debug] [Thread-4 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:19:26.691636 [debug] [Thread-4 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:19:26.691636 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m14:19:27.722920 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08fdb-1bb0-1b9d-a44f-81c5c8a282ca) - Created
[0m14:19:28.609807 [debug] [Thread-4 (]: SQL status: OK in 1.920 seconds
[0m14:19:28.613833 [debug] [Thread-4 (]: Databricks adapter: Cursor(session-id=01f08fdb-1bb0-1b9d-a44f-81c5c8a282ca, command-id=01f08fdb-1bd7-193e-923f-67dd7819b434) - Closing
[0m14:19:28.627866 [debug] [Thread-4 (]: Applying tags to relation None
[0m14:19:28.629871 [debug] [Thread-4 (]: On model.dbt_eTl.silver_sales: Close
[0m14:19:28.629871 [debug] [Thread-4 (]: Databricks adapter: Connection(session-id=01f08fdb-1bb0-1b9d-a44f-81c5c8a282ca) - Closing
[0m14:19:28.844895 [info ] [Thread-4 (]: 1 of 1 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 2.24s]
[0m14:19:28.852070 [debug] [Thread-4 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:19:28.852070 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:19:28.852070 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:19:28.852070 [info ] [MainThread]: 
[0m14:19:28.852070 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 8.98 seconds (8.98s).
[0m14:19:28.865554 [debug] [MainThread]: Command end result
[0m14:19:29.058880 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:19:29.058880 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:19:29.071806 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:19:29.071806 [info ] [MainThread]: 
[0m14:19:29.081142 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:19:29.081680 [info ] [MainThread]: 
[0m14:19:29.081680 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m14:19:29.081680 [debug] [MainThread]: Command `dbt run` succeeded at 14:19:29.081680 after 12.14 seconds
[0m14:19:29.081680 [debug] [MainThread]: Flushing usage events
[0m14:21:34.833142 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:21:34.973430 | ba8da18d-0b97-4c75-8c58-f1724e2fad87 ==============================
[0m14:21:34.973430 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:21:34.973430 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:21:36.152462 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:21:36.152462 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:21:36.152462 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:21:37.089002 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:21:37.539070 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:21:37.795267 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:21:37.795267 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:21:37.969923 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:21:37.969923 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:21:38.216557 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:21:38.225628 [info ] [MainThread]: 
[0m14:21:38.225628 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:21:38.225628 [info ] [MainThread]: 
[0m14:21:38.229579 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:21:38.229579 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:21:38.249154 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:21:38.251167 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:21:38.251167 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:21:38.251167 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:21:38.251167 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:39.608101 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6a2f-1275-83a6-3b03226d60fc) - Created
[0m14:21:40.195457 [debug] [ThreadPool]: SQL status: OK in 1.930 seconds
[0m14:21:40.196607 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-6a2f-1275-83a6-3b03226d60fc, command-id=01f08fdb-6a74-1bdd-892c-9b5e3d2148b2) - Closing
[0m14:21:40.196607 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:21:40.196607 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6a2f-1275-83a6-3b03226d60fc) - Closing
[0m14:21:40.434869 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:21:40.439423 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:21:40.440981 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:21:40.440981 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:21:40.442991 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:41.363998 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6b5b-1acd-8537-68ef9c6d7ce3) - Created
[0m14:21:41.716776 [debug] [ThreadPool]: SQL status: OK in 1.270 seconds
[0m14:21:41.718613 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-6b5b-1acd-8537-68ef9c6d7ce3, command-id=01f08fdb-6b7c-12cf-b9ac-b1e3736b3fd2) - Closing
[0m14:21:41.719837 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:21:41.720366 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6b5b-1acd-8537-68ef9c6d7ce3) - Closing
[0m14:21:41.969647 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:21:41.969647 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:21:41.981531 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:21:41.981531 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:21:41.981531 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:42.750986 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6c2e-1ca8-9635-d7da15c396a6) - Created
[0m14:21:43.310121 [debug] [ThreadPool]: SQL status: OK in 1.330 seconds
[0m14:21:43.322501 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-6c2e-1ca8-9635-d7da15c396a6, command-id=01f08fdb-6c52-160d-87bc-4325c6cd3943) - Closing
[0m14:21:43.322501 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:21:43.322501 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6c2e-1ca8-9635-d7da15c396a6) - Closing
[0m14:21:43.599205 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:21:43.605969 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:21:43.610821 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:21:43.614974 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:21:43.614974 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:21:44.628169 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6d42-1149-946f-932a583675ae) - Created
[0m14:21:45.548294 [debug] [ThreadPool]: SQL status: OK in 1.930 seconds
[0m14:21:45.554558 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-6d42-1149-946f-932a583675ae, command-id=01f08fdb-6d6e-14db-b69c-224f989b5d3d) - Closing
[0m14:21:45.554558 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:21:45.554558 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-6d42-1149-946f-932a583675ae) - Closing
[0m14:21:46.166520 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:21:46.166520 [info ] [Thread-5 (]: 1 of 15 START sql table model default.bronze_customer .......................... [RUN]
[0m14:21:46.166520 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:21:46.172641 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:21:46.172641 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:21:46.179904 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:21:46.181246 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:21:46.193339 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:21:46.193339 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:21:46.255350 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:21:46.255350 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:21:46.255350 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:21:46.255350 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:48.251516 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-6f62-152e-9d62-3b744835613b) - Created
[0m14:21:50.672680 [debug] [Thread-5 (]: SQL status: OK in 4.420 seconds
[0m14:21:50.674690 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-6f62-152e-9d62-3b744835613b, command-id=01f08fdb-6f9a-1476-bfe7-07d18ac18a18) - Closing
[0m14:21:50.694497 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:50.700248 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:21:50.700248 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-6f62-152e-9d62-3b744835613b) - Closing
[0m14:21:50.984455 [info ] [Thread-5 (]: 1 of 15 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 4.80s]
[0m14:21:50.984455 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:21:50.984455 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:21:50.984455 [info ] [Thread-5 (]: 2 of 15 START sql view model bronze.bronze_date ................................ [RUN]
[0m14:21:50.984455 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:21:50.984455 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:21:50.984455 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:21:50.984455 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:21:50.984455 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:21:51.016303 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:21:51.032101 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:21:51.032101 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:21:51.032101 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:21:51.032101 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:21:51.032101 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:52.253331 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-71d6-11bf-a71d-61df938ae5b5) - Created
[0m14:21:53.371924 [debug] [Thread-5 (]: SQL status: OK in 2.340 seconds
[0m14:21:53.371924 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-71d6-11bf-a71d-61df938ae5b5, command-id=01f08fdb-71fb-127a-84f5-86252616eff2) - Closing
[0m14:21:53.378277 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:53.378277 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:21:53.378277 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-71d6-11bf-a71d-61df938ae5b5) - Closing
[0m14:21:53.638019 [info ] [Thread-5 (]: 2 of 15 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.65s]
[0m14:21:53.644988 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:21:53.647006 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:21:53.648038 [info ] [Thread-5 (]: 3 of 15 START sql table model default.bronze_dim_product ....................... [RUN]
[0m14:21:53.649475 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:21:53.651998 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:21:53.651998 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:21:53.755485 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:21:53.755485 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:21:53.769248 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:21:53.769248 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:21:53.769248 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:21:53.769248 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:21:53.769248 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:55.180231 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7388-1c88-8728-3bfb6d146563) - Created
[0m14:21:57.316542 [debug] [Thread-5 (]: SQL status: OK in 3.550 seconds
[0m14:21:57.316542 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7388-1c88-8728-3bfb6d146563, command-id=01f08fdb-73b7-1a01-b720-d4053c7438ab) - Closing
[0m14:21:57.316542 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:21:57.316542 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:21:57.316542 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7388-1c88-8728-3bfb6d146563) - Closing
[0m14:21:57.827465 [info ] [Thread-5 (]: 3 of 15 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 4.18s]
[0m14:21:57.827465 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:21:57.827465 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:21:57.827465 [info ] [Thread-5 (]: 4 of 15 START sql view model default.bronze_returns ............................ [RUN]
[0m14:21:57.827465 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:21:57.827465 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:21:57.827465 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:21:57.844778 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:21:57.846056 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:21:57.851421 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:21:57.851421 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:21:57.853421 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:21:57.853421 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:21:57.853421 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:21:57.853421 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:21:59.270572 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-75fa-12cb-9ee9-54a71bc83603) - Created
[0m14:22:00.088701 [debug] [Thread-5 (]: SQL status: OK in 2.240 seconds
[0m14:22:00.088701 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-75fa-12cb-9ee9-54a71bc83603, command-id=01f08fdb-7627-1d36-914c-ab9aeb0fd3bb) - Closing
[0m14:22:00.088701 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:22:00.088701 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:22:00.088701 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-75fa-12cb-9ee9-54a71bc83603) - Closing
[0m14:22:00.604316 [info ] [Thread-5 (]: 4 of 15 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 2.76s]
[0m14:22:00.606331 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:22:00.606331 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:22:00.606331 [info ] [Thread-5 (]: 5 of 15 START sql view model default.bronze_sales .............................. [RUN]
[0m14:22:00.606331 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:22:00.614424 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:22:00.614424 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:22:00.622079 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:22:00.622079 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:22:00.629275 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:22:00.629275 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:22:00.629275 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:22:00.629275 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:22:00.629275 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:22:00.629275 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:02.037440 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7796-1a3a-ae25-5b7cd10c2e31) - Created
[0m14:22:02.858886 [debug] [Thread-5 (]: SQL status: OK in 2.230 seconds
[0m14:22:02.860894 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7796-1a3a-ae25-5b7cd10c2e31, command-id=01f08fdb-77d1-1500-8125-09bca84be7b4) - Closing
[0m14:22:02.862901 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:22:02.864907 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:22:02.864907 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7796-1a3a-ae25-5b7cd10c2e31) - Closing
[0m14:22:03.329676 [info ] [Thread-5 (]: 5 of 15 OK created sql view model default.bronze_sales ......................... [[32mOK[0m in 2.72s]
[0m14:22:03.332542 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:22:03.334741 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:22:03.334741 [info ] [Thread-5 (]: 6 of 15 START sql table model default.bronze_store ............................. [RUN]
[0m14:22:03.337372 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:22:03.337372 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:22:03.337372 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:22:03.337372 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:22:03.347128 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:22:03.354154 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:22:03.356159 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:22:03.357934 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:22:03.360301 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:22:03.360301 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:04.497048 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-791f-1098-835c-614f615d47fc) - Created
[0m14:22:06.752114 [debug] [Thread-5 (]: SQL status: OK in 3.390 seconds
[0m14:22:06.754145 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-791f-1098-835c-614f615d47fc, command-id=01f08fdb-7945-1f16-8e47-0621d63fa4ac) - Closing
[0m14:22:06.758323 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:22:06.762494 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:22:06.762494 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-791f-1098-835c-614f615d47fc) - Closing
[0m14:22:07.154940 [info ] [Thread-5 (]: 6 of 15 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 3.82s]
[0m14:22:07.159212 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:22:07.162239 [debug] [Thread-5 (]: Began running node seed.dbt_eTl.lookup
[0m14:22:07.164251 [info ] [Thread-5 (]: 7 of 15 START seed file bronze.lookup .......................................... [RUN]
[0m14:22:07.166260 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m14:22:07.168359 [debug] [Thread-5 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m14:22:07.168359 [debug] [Thread-5 (]: Began compiling node seed.dbt_eTl.lookup
[0m14:22:07.170419 [debug] [Thread-5 (]: Began executing node seed.dbt_eTl.lookup
[0m14:22:07.211042 [debug] [Thread-5 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m14:22:07.211042 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create  table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m14:22:07.211042 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:07.974510 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7b35-17a1-a556-d8496b862719) - Created
[0m14:22:09.778470 [debug] [Thread-5 (]: SQL status: OK in 2.570 seconds
[0m14:22:09.787536 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7b35-17a1-a556-d8496b862719, command-id=01f08fdb-7b57-16d2-b9a3-74fa5a18d2eb) - Closing
[0m14:22:09.806162 [debug] [Thread-5 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m14:22:09.806162 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m14:22:11.364575 [debug] [Thread-5 (]: SQL status: OK in 1.560 seconds
[0m14:22:11.364575 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7b35-17a1-a556-d8496b862719, command-id=01f08fdb-7c6f-1be9-b2e8-54385e7010f1) - Closing
[0m14:22:11.376308 [debug] [Thread-5 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m14:22:11.380333 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: Close
[0m14:22:11.380333 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7b35-17a1-a556-d8496b862719) - Closing
[0m14:22:11.760143 [info ] [Thread-5 (]: 7 of 15 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.59s]
[0m14:22:11.760143 [debug] [Thread-5 (]: Finished running node seed.dbt_eTl.lookup
[0m14:22:11.767150 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:22:11.767150 [info ] [Thread-5 (]: 8 of 15 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m14:22:11.767150 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m14:22:11.767150 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m14:22:11.767150 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:22:11.785799 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:22:11.789523 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:22:11.810374 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:22:11.813693 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:22:11.813693 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m14:22:11.813693 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:13.097219 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7e36-1832-a0fa-d49088b2e681) - Created
[0m14:22:14.228200 [debug] [Thread-5 (]: SQL status: OK in 2.410 seconds
[0m14:22:14.243927 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7e36-1832-a0fa-d49088b2e681, command-id=01f08fdb-7e68-1869-bea4-0aca9ec9a3b5) - Closing
[0m14:22:14.243927 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m14:22:14.243927 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7e36-1832-a0fa-d49088b2e681) - Closing
[0m14:22:14.568941 [info ] [Thread-5 (]: 8 of 15 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 2.80s]
[0m14:22:14.570045 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:22:14.570770 [debug] [Thread-5 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:22:14.572070 [info ] [Thread-5 (]: 9 of 15 START test unique_bronze_customer_customer_sk .......................... [RUN]
[0m14:22:14.573165 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m14:22:14.573791 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m14:22:14.574399 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:22:14.591778 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:22:14.593594 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:22:14.597178 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:22:14.598379 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:22:14.598918 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:22:14.599447 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:15.860835 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7fca-120a-ad45-b3762a2592c2) - Created
[0m14:22:16.607933 [debug] [Thread-5 (]: SQL status: OK in 2.010 seconds
[0m14:22:16.607933 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-7fca-120a-ad45-b3762a2592c2, command-id=01f08fdb-800e-1126-b931-b8719e7eb174) - Closing
[0m14:22:16.607933 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m14:22:16.607933 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-7fca-120a-ad45-b3762a2592c2) - Closing
[0m14:22:16.903457 [info ] [Thread-5 (]: 9 of 15 PASS unique_bronze_customer_customer_sk ................................ [[32mPASS[0m in 2.33s]
[0m14:22:16.903457 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:22:16.903457 [debug] [Thread-5 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:22:16.903457 [info ] [Thread-5 (]: 10 of 15 START test non_negative_test_bronze_sales_gross_amount ................ [RUN]
[0m14:22:16.903457 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m14:22:16.912172 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m14:22:16.914189 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:22:16.922649 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:22:16.922649 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:22:16.922649 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:22:16.922649 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:22:16.936920 [debug] [Thread-5 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
  SELECT 
    *
  FROM `dbt-project`.`default`.`bronze_sales`
  WHERE gross_amount < 0

  
  
      
    ) dbt_internal_test
[0m14:22:16.938438 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:17.999993 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-8126-1cef-8478-d396abf28dc4) - Created
[0m14:22:19.037370 [debug] [Thread-5 (]: SQL status: OK in 2.100 seconds
[0m14:22:19.041550 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-8126-1cef-8478-d396abf28dc4, command-id=01f08fdb-8152-1098-ab4f-c507de076ace) - Closing
[0m14:22:19.041550 [debug] [Thread-5 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: Close
[0m14:22:19.041550 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-8126-1cef-8478-d396abf28dc4) - Closing
[0m14:22:19.547393 [info ] [Thread-5 (]: 10 of 15 PASS non_negative_test_bronze_sales_gross_amount ...................... [[32mPASS[0m in 2.64s]
[0m14:22:19.550543 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:22:19.550543 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:22:19.550543 [info ] [Thread-5 (]: 11 of 15 START test not_null_bronze_sales_gross_amount ......................... [RUN]
[0m14:22:19.550543 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m14:22:19.559333 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m14:22:19.559333 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:22:19.571914 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:22:19.575741 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:22:19.578883 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:22:19.578883 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:22:19.578883 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m14:22:19.578883 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:20.805044 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-82dd-1648-af1d-bd331a960858) - Created
[0m14:22:21.396707 [debug] [Thread-5 (]: SQL status: OK in 1.820 seconds
[0m14:22:21.400077 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-82dd-1648-af1d-bd331a960858, command-id=01f08fdb-82fd-1ccd-a362-3b5686c6cf89) - Closing
[0m14:22:21.402082 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m14:22:21.402082 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-82dd-1648-af1d-bd331a960858) - Closing
[0m14:22:21.630261 [info ] [Thread-5 (]: 11 of 15 PASS not_null_bronze_sales_gross_amount ............................... [[32mPASS[0m in 2.07s]
[0m14:22:21.632280 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:22:21.635722 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:22:21.635722 [info ] [Thread-5 (]: 12 of 15 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m14:22:21.638243 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m14:22:21.639587 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m14:22:21.639587 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:22:21.649307 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:22:21.651759 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:22:21.654851 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:22:21.659668 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:22:21.659668 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m14:22:21.661696 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:22.431560 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-83d6-1bc4-bff6-c6158966fe33) - Created
[0m14:22:23.011676 [debug] [Thread-5 (]: SQL status: OK in 1.350 seconds
[0m14:22:23.015864 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-83d6-1bc4-bff6-c6158966fe33, command-id=01f08fdb-83f6-1f09-ae46-fcaea532250b) - Closing
[0m14:22:23.015864 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m14:22:23.015864 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-83d6-1bc4-bff6-c6158966fe33) - Closing
[0m14:22:23.251596 [info ] [Thread-5 (]: 12 of 15 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 1.61s]
[0m14:22:23.258257 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:22:23.258257 [debug] [Thread-5 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:22:23.258257 [info ] [Thread-5 (]: 13 of 15 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m14:22:23.258257 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m14:22:23.258257 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m14:22:23.258257 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:22:23.273774 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:22:23.273774 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:22:23.282338 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:22:23.282338 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:22:23.282338 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:22:23.282338 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:24.154815 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-84d8-1ee9-9143-75ebb84e9489) - Created
[0m14:22:26.914874 [debug] [Thread-5 (]: SQL status: OK in 3.630 seconds
[0m14:22:26.914874 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-84d8-1ee9-9143-75ebb84e9489, command-id=01f08fdb-84fc-1684-8917-e97e2f99dd52) - Closing
[0m14:22:26.914874 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m14:22:26.914874 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-84d8-1ee9-9143-75ebb84e9489) - Closing
[0m14:22:27.185062 [info ] [Thread-5 (]: 13 of 15 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 3.93s]
[0m14:22:27.187835 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:22:27.187835 [debug] [Thread-5 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:22:27.187835 [info ] [Thread-5 (]: 14 of 15 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m14:22:27.191569 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m14:22:27.191569 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m14:22:27.191569 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:22:27.214648 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:22:27.214648 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:22:27.220902 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:22:27.225995 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:22:27.225995 [debug] [Thread-5 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m14:22:27.225995 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:28.293432 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-8746-1436-b7fc-6570c9961b37) - Created
[0m14:22:29.381531 [debug] [Thread-5 (]: SQL status: OK in 2.160 seconds
[0m14:22:29.386805 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-8746-1436-b7fc-6570c9961b37, command-id=01f08fdb-8775-1811-be9d-177af9e629b0) - Closing
[0m14:22:29.389030 [debug] [Thread-5 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m14:22:29.389030 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-8746-1436-b7fc-6570c9961b37) - Closing
[0m14:22:29.669836 [info ] [Thread-5 (]: 14 of 15 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 2.48s]
[0m14:22:29.669836 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:22:29.669836 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m14:22:29.671909 [info ] [Thread-5 (]: 15 of 15 START sql view model default.silver_sales ............................. [RUN]
[0m14:22:29.673664 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:22:29.673664 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:22:29.673664 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:22:29.686547 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:22:29.689784 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:22:29.694309 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:22:29.694309 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:22:29.694309 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:22:29.697868 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:22:29.697868 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:22:29.700069 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:22:30.484540 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-88a3-1585-be1d-fd3896b9ca97) - Created
[0m14:22:31.277605 [debug] [Thread-5 (]: SQL status: OK in 1.580 seconds
[0m14:22:31.277605 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-88a3-1585-be1d-fd3896b9ca97, command-id=01f08fdb-88c3-15d6-bced-c355823e6248) - Closing
[0m14:22:31.277605 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:22:31.283234 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m14:22:31.283234 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-88a3-1585-be1d-fd3896b9ca97) - Closing
[0m14:22:31.630217 [info ] [Thread-5 (]: 15 of 15 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 1.96s]
[0m14:22:31.630217 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:22:31.636818 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:22:31.636818 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:22:31.636818 [info ] [MainThread]: 
[0m14:22:31.636818 [info ] [MainThread]: Finished running 1 seed, 3 table models, 7 data tests, 4 view models in 0 hours 0 minutes and 53.41 seconds (53.41s).
[0m14:22:31.649820 [debug] [MainThread]: Command end result
[0m14:22:31.706632 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:22:31.707829 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:22:31.707829 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:22:31.718205 [info ] [MainThread]: 
[0m14:22:31.718205 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:22:31.719877 [info ] [MainThread]: 
[0m14:22:31.719877 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=15
[0m14:22:31.719877 [debug] [MainThread]: Command `dbt build` succeeded at 14:22:31.719877 after 56.93 seconds
[0m14:22:31.719877 [debug] [MainThread]: Flushing usage events
[0m14:23:55.685438 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:23:55.927053 | 85164ebd-6fb7-46ed-bc28-917b30522856 ==============================
[0m14:23:55.927053 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:23:55.929067 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt clean', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'None', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:23:56.152977 [debug] [MainThread]: Command `dbt clean` succeeded at 14:23:56.152977 after 0.53 seconds
[0m14:23:56.152977 [debug] [MainThread]: Flushing usage events
[0m14:24:30.182044 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:24:30.276902 | 39b1424a-b39a-470a-aafd-f4872e84c6a1 ==============================
[0m14:24:30.276902 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:24:30.276902 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'empty': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m14:24:31.267742 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:24:31.267742 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:24:31.267742 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:24:32.352535 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:24:32.736372 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:24:32.736372 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m14:24:34.968301 [warn ] [MainThread]: [[33mWARNING[0m][MissingArgumentsPropertyInGenericTestDeprecation]: Deprecated
functionality
Found top-level arguments to test `accepted_values`. Arguments to generic tests
should be nested under the `arguments` property.`
[0m14:24:35.405218 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:24:35.405218 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:24:35.436957 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:24:35.436957 [info ] [MainThread]: 
[0m14:24:35.436957 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:24:35.436957 [info ] [MainThread]: 
[0m14:24:35.436957 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:24:35.452971 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:24:35.461497 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:24:35.461497 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:24:35.461497 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:24:35.461497 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:24:35.461497 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:37.474278 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d3f6-1440-b3f3-f4652a583df1) - Created
[0m14:24:38.104113 [debug] [ThreadPool]: SQL status: OK in 2.640 seconds
[0m14:24:38.104113 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-d3f6-1440-b3f3-f4652a583df1, command-id=01f08fdb-d477-1cd9-856a-922e5d65a5c3) - Closing
[0m14:24:38.104113 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:24:38.104113 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d3f6-1440-b3f3-f4652a583df1) - Closing
[0m14:24:38.374360 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:24:38.374360 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:24:38.374360 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:24:38.374360 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:24:38.374360 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:39.966272 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d5c5-1e5b-b2d9-55c091e03ee7) - Created
[0m14:24:40.357867 [debug] [ThreadPool]: SQL status: OK in 1.980 seconds
[0m14:24:40.357867 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-d5c5-1e5b-b2d9-55c091e03ee7, command-id=01f08fdb-d5ef-1e13-a5a2-9e41aa40e1c0) - Closing
[0m14:24:40.357867 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:24:40.357867 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d5c5-1e5b-b2d9-55c091e03ee7) - Closing
[0m14:24:40.862355 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:24:40.862355 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:24:40.886971 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:24:40.888121 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:24:40.888121 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:41.930136 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d6f6-1333-a06a-d8cc9a8eb956) - Created
[0m14:24:42.600581 [debug] [ThreadPool]: SQL status: OK in 1.710 seconds
[0m14:24:42.610801 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-d6f6-1333-a06a-d8cc9a8eb956, command-id=01f08fdb-d71c-13c2-9d72-7a0987e0cc9b) - Closing
[0m14:24:42.612824 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:24:42.612824 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d6f6-1333-a06a-d8cc9a8eb956) - Closing
[0m14:24:43.097992 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:24:43.114061 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:24:43.114061 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:24:43.114061 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:24:43.114061 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:24:44.749357 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d884-1fb3-b0ea-adbc90ba59cc) - Created
[0m14:24:45.670452 [debug] [ThreadPool]: SQL status: OK in 2.560 seconds
[0m14:24:45.670452 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdb-d884-1fb3-b0ea-adbc90ba59cc, command-id=01f08fdb-d8ce-1629-b47e-97fb08a2118d) - Closing
[0m14:24:45.670452 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:24:45.670452 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdb-d884-1fb3-b0ea-adbc90ba59cc) - Closing
[0m14:24:46.495318 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:24:46.498375 [info ] [Thread-5 (]: 1 of 15 START sql table model default.bronze_customer .......................... [RUN]
[0m14:24:46.500380 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:24:46.500380 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:24:46.500380 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:24:46.513033 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:24:46.515677 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:24:46.535779 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:24:46.535779 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:24:46.607116 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:24:46.607116 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:24:46.607116 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:24:46.607116 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:24:47.963851 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-da48-12be-9a64-8da524ad51f5) - Created
[0m14:24:49.993618 [debug] [Thread-5 (]: SQL status: OK in 3.390 seconds
[0m14:24:49.993618 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-da48-12be-9a64-8da524ad51f5, command-id=01f08fdb-dab5-1fd8-9f7a-a23151c6ab1d) - Closing
[0m14:24:50.015216 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:24:50.032705 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:24:50.032705 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-da48-12be-9a64-8da524ad51f5) - Closing
[0m14:24:50.327126 [info ] [Thread-5 (]: 1 of 15 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 3.83s]
[0m14:24:50.327126 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:24:50.327126 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:24:50.327126 [info ] [Thread-5 (]: 2 of 15 START sql view model bronze.bronze_date ................................ [RUN]
[0m14:24:50.327126 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:24:50.327126 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:24:50.327126 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:24:50.348861 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:24:50.353266 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:24:50.375382 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:24:50.384267 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:24:50.384267 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:24:50.384267 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:24:50.384267 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:24:50.384267 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:24:51.781481 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-dc9b-1fee-98cd-edd8559905da) - Created
[0m14:24:52.761404 [debug] [Thread-5 (]: SQL status: OK in 2.380 seconds
[0m14:24:52.761404 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-dc9b-1fee-98cd-edd8559905da, command-id=01f08fdb-dcfe-1182-b587-2eb902757444) - Closing
[0m14:24:52.761404 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:24:52.761404 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:24:52.761404 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-dc9b-1fee-98cd-edd8559905da) - Closing
[0m14:24:53.037537 [info ] [Thread-5 (]: 2 of 15 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.71s]
[0m14:24:53.037537 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:24:53.050082 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:24:53.050082 [info ] [Thread-5 (]: 3 of 15 START sql table model default.bronze_dim_product ....................... [RUN]
[0m14:24:53.050082 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:24:53.050082 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:24:53.050082 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:24:53.054042 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:24:53.054042 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:24:53.054042 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:24:53.054042 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:24:53.054042 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:24:53.054042 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:24:53.054042 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:24:54.244088 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-de50-14ca-82b4-e077b45b1a95) - Created
[0m14:24:56.630476 [debug] [Thread-5 (]: SQL status: OK in 3.580 seconds
[0m14:24:56.630476 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-de50-14ca-82b4-e077b45b1a95, command-id=01f08fdb-de72-157d-8f83-009c1b40cbf9) - Closing
[0m14:24:56.632513 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:24:56.632513 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:24:56.632513 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-de50-14ca-82b4-e077b45b1a95) - Closing
[0m14:24:57.027895 [info ] [Thread-5 (]: 3 of 15 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 3.98s]
[0m14:24:57.043680 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:24:57.043680 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:24:57.043680 [info ] [Thread-5 (]: 4 of 15 START sql view model default.bronze_returns ............................ [RUN]
[0m14:24:57.043680 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:24:57.043680 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:24:57.043680 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:24:57.043680 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:24:57.043680 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:24:57.043680 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:24:57.043680 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:24:57.060500 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:24:57.061936 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:24:57.062816 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:24:57.063681 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:24:58.508285 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e0c8-1d7f-9909-4e0ddbae60c8) - Created
[0m14:24:59.805849 [debug] [Thread-5 (]: SQL status: OK in 2.740 seconds
[0m14:24:59.807853 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-e0c8-1d7f-9909-4e0ddbae60c8, command-id=01f08fdb-e101-1ca7-a0c4-29cdcb6c467f) - Closing
[0m14:24:59.807853 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:24:59.809857 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:24:59.809857 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e0c8-1d7f-9909-4e0ddbae60c8) - Closing
[0m14:25:00.211870 [info ] [Thread-5 (]: 4 of 15 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 3.17s]
[0m14:25:00.211870 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:25:00.211870 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:25:00.211870 [info ] [Thread-5 (]: 5 of 15 START sql view model default.bronze_sales .............................. [RUN]
[0m14:25:00.211870 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:25:00.211870 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:25:00.211870 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:25:00.223455 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:25:00.225202 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:25:00.229792 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:25:00.234319 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:25:00.234319 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:25:00.234319 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:25:00.234319 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:25:00.234319 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:01.172314 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e265-1aa6-92db-5c50f880d31d) - Created
[0m14:25:02.042839 [debug] [Thread-5 (]: SQL status: OK in 1.810 seconds
[0m14:25:02.045859 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-e265-1aa6-92db-5c50f880d31d, command-id=01f08fdb-e297-1ad8-b2e4-c93f1e29e1e2) - Closing
[0m14:25:02.046737 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:25:02.046737 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:25:02.046737 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e265-1aa6-92db-5c50f880d31d) - Closing
[0m14:25:02.406041 [info ] [Thread-5 (]: 5 of 15 OK created sql view model default.bronze_sales ......................... [[32mOK[0m in 2.19s]
[0m14:25:02.406041 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:25:02.408433 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:25:02.408433 [info ] [Thread-5 (]: 6 of 15 START sql table model default.bronze_store ............................. [RUN]
[0m14:25:02.408433 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:25:02.408433 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:25:02.408433 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:25:02.408433 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:25:02.408433 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:25:02.417574 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:25:02.417574 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:25:02.417574 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:25:02.421889 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:25:02.421889 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:03.764141 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e3e7-1cb8-be4e-2f8f733d7cc4) - Created
[0m14:25:05.843509 [debug] [Thread-5 (]: SQL status: OK in 3.420 seconds
[0m14:25:05.845515 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-e3e7-1cb8-be4e-2f8f733d7cc4, command-id=01f08fdb-e421-1d45-86b3-2e8e84954a67) - Closing
[0m14:25:05.847519 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:25:05.849524 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:25:05.849524 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e3e7-1cb8-be4e-2f8f733d7cc4) - Closing
[0m14:25:06.861617 [info ] [Thread-5 (]: 6 of 15 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 4.45s]
[0m14:25:06.861617 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:25:06.861617 [debug] [Thread-5 (]: Began running node seed.dbt_eTl.lookup
[0m14:25:06.861617 [info ] [Thread-5 (]: 7 of 15 START seed file bronze.lookup .......................................... [RUN]
[0m14:25:06.861617 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m14:25:06.861617 [debug] [Thread-5 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m14:25:06.861617 [debug] [Thread-5 (]: Began compiling node seed.dbt_eTl.lookup
[0m14:25:06.861617 [debug] [Thread-5 (]: Began executing node seed.dbt_eTl.lookup
[0m14:25:06.917955 [debug] [Thread-5 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m14:25:06.932517 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m14:25:06.934257 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:09.019770 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e6e6-1748-acb1-bb8eb8da8a64) - Created
[0m14:25:10.865454 [debug] [Thread-5 (]: SQL status: OK in 3.930 seconds
[0m14:25:10.869617 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-e6e6-1748-acb1-bb8eb8da8a64, command-id=01f08fdb-e744-1c5c-b2e6-78f666ea8def) - Closing
[0m14:25:10.892283 [debug] [Thread-5 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m14:25:10.892283 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m14:25:12.297531 [debug] [Thread-5 (]: SQL status: OK in 1.410 seconds
[0m14:25:12.299210 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-e6e6-1748-acb1-bb8eb8da8a64, command-id=01f08fdb-e85f-167e-b72b-c98af268d2d3) - Closing
[0m14:25:12.300152 [debug] [Thread-5 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m14:25:12.300152 [debug] [Thread-5 (]: On seed.dbt_eTl.lookup: Close
[0m14:25:12.300152 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-e6e6-1748-acb1-bb8eb8da8a64) - Closing
[0m14:25:12.849507 [info ] [Thread-5 (]: 7 of 15 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 5.99s]
[0m14:25:12.849507 [debug] [Thread-5 (]: Finished running node seed.dbt_eTl.lookup
[0m14:25:12.849507 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:25:12.849507 [info ] [Thread-5 (]: 8 of 15 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m14:25:12.849507 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m14:25:12.849507 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m14:25:12.849507 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:25:12.865415 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:25:12.868963 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:25:12.903465 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:25:12.903465 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m14:25:12.903465 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m14:25:12.903465 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:14.549853 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-ea5e-14f8-bb75-78d50efbda93) - Created
[0m14:25:15.316381 [debug] [Thread-5 (]: SQL status: OK in 2.410 seconds
[0m14:25:15.320786 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-ea5e-14f8-bb75-78d50efbda93, command-id=01f08fdb-ea8e-142e-acae-f85bbbe3d072) - Closing
[0m14:25:15.324379 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m14:25:15.324379 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-ea5e-14f8-bb75-78d50efbda93) - Closing
[0m14:25:15.738067 [info ] [Thread-5 (]: 8 of 15 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 2.89s]
[0m14:25:15.740180 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m14:25:15.740180 [debug] [Thread-5 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:25:15.740180 [info ] [Thread-5 (]: 9 of 15 START test unique_bronze_customer_customer_sk .......................... [RUN]
[0m14:25:15.740180 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m14:25:15.742745 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m14:25:15.742745 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:25:15.757228 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:25:15.757228 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:25:15.763608 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:25:15.765614 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m14:25:15.765614 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:25:15.765614 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:16.900321 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-ebc5-1b76-ba78-84183fcf910b) - Created
[0m14:25:18.110789 [debug] [Thread-5 (]: SQL status: OK in 2.350 seconds
[0m14:25:18.112793 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-ebc5-1b76-ba78-84183fcf910b, command-id=01f08fdb-ebf6-15a8-bc9a-b32c17b63816) - Closing
[0m14:25:18.115802 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m14:25:18.115802 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-ebc5-1b76-ba78-84183fcf910b) - Closing
[0m14:25:19.053916 [info ] [Thread-5 (]: 9 of 15 PASS unique_bronze_customer_customer_sk ................................ [[32mPASS[0m in 3.31s]
[0m14:25:19.053916 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m14:25:19.058262 [debug] [Thread-5 (]: Began running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:25:19.058262 [info ] [Thread-5 (]: 10 of 15 START test non_negative_test_bronze_sales_gross_amount ................ [RUN]
[0m14:25:19.058262 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d) - Creating connection
[0m14:25:19.058262 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d'
[0m14:25:19.058262 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:25:19.058262 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:25:19.058262 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:25:19.070021 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:25:19.071888 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"
[0m14:25:19.073342 [debug] [Thread-5 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
  SELECT 
    *
  FROM `dbt-project`.`default`.`bronze_sales`
  WHERE gross_amount < 0

  
  
      
    ) dbt_internal_test
[0m14:25:19.073711 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:20.475251 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-edf4-153a-981c-0cb6102804a3) - Created
[0m14:25:20.835120 [debug] [Thread-5 (]: SQL status: OK in 1.760 seconds
[0m14:25:20.835120 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-edf4-153a-981c-0cb6102804a3, command-id=01f08fdb-ee14-1eaf-851a-22589a468625) - Closing
[0m14:25:20.835120 [debug] [Thread-5 (]: On test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d: Close
[0m14:25:20.850812 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-edf4-153a-981c-0cb6102804a3) - Closing
[0m14:25:21.143985 [info ] [Thread-5 (]: 10 of 15 PASS non_negative_test_bronze_sales_gross_amount ...................... [[32mPASS[0m in 2.08s]
[0m14:25:21.143985 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.non_negative_test_bronze_sales_gross_amount.cdfbb2fb2d
[0m14:25:21.145988 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:25:21.145988 [info ] [Thread-5 (]: 11 of 15 START test not_null_bronze_sales_gross_amount ......................... [RUN]
[0m14:25:21.145988 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff) - Creating connection
[0m14:25:21.145988 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff'
[0m14:25:21.145988 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:25:21.157593 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:25:21.160019 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:25:21.166688 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:25:21.169727 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"
[0m14:25:21.170900 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select gross_amount
from `dbt-project`.`default`.`bronze_sales`
where gross_amount is null



  
  
      
    ) dbt_internal_test
[0m14:25:21.171481 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:22.237789 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-eeff-1718-b3d9-b2af23a7ada4) - Created
[0m14:25:22.842113 [debug] [Thread-5 (]: SQL status: OK in 1.670 seconds
[0m14:25:22.845898 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-eeff-1718-b3d9-b2af23a7ada4, command-id=01f08fdb-ef22-144a-91d7-eff61dad34db) - Closing
[0m14:25:22.847468 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff: Close
[0m14:25:22.848529 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-eeff-1718-b3d9-b2af23a7ada4) - Closing
[0m14:25:23.073057 [info ] [Thread-5 (]: 11 of 15 PASS not_null_bronze_sales_gross_amount ............................... [[32mPASS[0m in 1.93s]
[0m14:25:23.073057 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_gross_amount.d0005f80ff
[0m14:25:23.073057 [debug] [Thread-5 (]: Began running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:25:23.076505 [info ] [Thread-5 (]: 12 of 15 START test not_null_bronze_sales_sales_id ............................. [RUN]
[0m14:25:23.076505 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb) - Creating connection
[0m14:25:23.076505 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb'
[0m14:25:23.076505 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:25:23.091774 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:25:23.094828 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:25:23.105049 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:25:23.105049 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"
[0m14:25:23.105049 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select sales_id
from `dbt-project`.`default`.`bronze_sales`
where sales_id is null



  
  
      
    ) dbt_internal_test
[0m14:25:23.105049 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:23.878359 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-effc-1579-bdbe-f8f05f34a63f) - Created
[0m14:25:24.629770 [debug] [Thread-5 (]: SQL status: OK in 1.520 seconds
[0m14:25:24.633457 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-effc-1579-bdbe-f8f05f34a63f, command-id=01f08fdb-f01c-1855-9382-6d13c29694ea) - Closing
[0m14:25:24.635453 [debug] [Thread-5 (]: On test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb: Close
[0m14:25:24.636093 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-effc-1579-bdbe-f8f05f34a63f) - Closing
[0m14:25:24.927341 [info ] [Thread-5 (]: 12 of 15 PASS not_null_bronze_sales_sales_id ................................... [[32mPASS[0m in 1.85s]
[0m14:25:24.931704 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.not_null_bronze_sales_sales_id.e4b1b997fb
[0m14:25:24.932876 [debug] [Thread-5 (]: Began running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:25:24.932876 [info ] [Thread-5 (]: 13 of 15 START test unique_bronze_sales_sales_id ............................... [RUN]
[0m14:25:24.932876 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d) - Creating connection
[0m14:25:24.934883 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d'
[0m14:25:24.934883 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:25:24.941285 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:25:24.941285 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:25:24.948534 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:25:24.952257 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"
[0m14:25:24.952257 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    sales_id as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_sales`
where sales_id is not null
group by sales_id
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m14:25:24.952257 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:26.630823 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f197-1bdd-b9c3-e3ec465348f3) - Created
[0m14:25:27.015617 [debug] [Thread-5 (]: SQL status: OK in 2.060 seconds
[0m14:25:27.017622 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-f197-1bdd-b9c3-e3ec465348f3, command-id=01f08fdb-f1c0-1ae1-adfd-859875b3eb4b) - Closing
[0m14:25:27.017622 [debug] [Thread-5 (]: On test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d: Close
[0m14:25:27.019626 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f197-1bdd-b9c3-e3ec465348f3) - Closing
[0m14:25:27.351025 [info ] [Thread-5 (]: 13 of 15 PASS unique_bronze_sales_sales_id ..................................... [[32mPASS[0m in 2.42s]
[0m14:25:27.351025 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.unique_bronze_sales_sales_id.3c35aa753d
[0m14:25:27.351025 [debug] [Thread-5 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:25:27.353371 [info ] [Thread-5 (]: 14 of 15 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m14:25:27.353876 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m14:25:27.353876 [debug] [Thread-5 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m14:25:27.353876 [debug] [Thread-5 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:25:27.366375 [debug] [Thread-5 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:25:27.366375 [debug] [Thread-5 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:25:27.366375 [debug] [Thread-5 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:25:27.366375 [debug] [Thread-5 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m14:25:27.366375 [debug] [Thread-5 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m14:25:27.366375 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:28.377642 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f2a3-1655-9ff7-75a012deee8e) - Created
[0m14:25:29.507155 [debug] [Thread-5 (]: SQL status: OK in 2.140 seconds
[0m14:25:29.510448 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-f2a3-1655-9ff7-75a012deee8e, command-id=01f08fdb-f2ca-1dcf-a105-80442eeabbfc) - Closing
[0m14:25:29.511594 [debug] [Thread-5 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m14:25:29.512139 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f2a3-1655-9ff7-75a012deee8e) - Closing
[0m14:25:30.010794 [info ] [Thread-5 (]: 14 of 15 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 2.66s]
[0m14:25:30.010794 [debug] [Thread-5 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m14:25:30.010794 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m14:25:30.010794 [info ] [Thread-5 (]: 15 of 15 START sql view model default.silver_sales ............................. [RUN]
[0m14:25:30.010794 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:25:30.010794 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:25:30.010794 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:25:30.010794 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:25:30.010794 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:25:30.010794 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:25:30.025938 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:25:30.027598 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:25:30.027598 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:25:30.030413 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:25:30.031152 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:25:31.036257 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f438-122a-9273-f1b1189d1859) - Created
[0m14:25:31.946231 [debug] [Thread-5 (]: SQL status: OK in 1.920 seconds
[0m14:25:31.946231 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdb-f438-122a-9273-f1b1189d1859, command-id=01f08fdb-f460-1693-90ee-fceadd903203) - Closing
[0m14:25:31.946231 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:25:31.946231 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m14:25:31.946231 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdb-f438-122a-9273-f1b1189d1859) - Closing
[0m14:25:32.511080 [info ] [Thread-5 (]: 15 of 15 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 2.50s]
[0m14:25:32.512085 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:25:32.514090 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:25:32.516095 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:25:32.516095 [info ] [MainThread]: 
[0m14:25:32.516095 [info ] [MainThread]: Finished running 1 seed, 3 table models, 7 data tests, 4 view models in 0 hours 0 minutes and 57.08 seconds (57.08s).
[0m14:25:32.521443 [debug] [MainThread]: Command end result
[0m14:25:32.570099 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:25:32.584179 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:25:32.590967 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:25:32.597045 [info ] [MainThread]: 
[0m14:25:32.597045 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:25:32.599666 [info ] [MainThread]: 
[0m14:25:32.599666 [info ] [MainThread]: Done. PASS=15 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=15
[0m14:25:32.600902 [warn ] [MainThread]: [[33mWARNING[0m][DeprecationsSummary]: Deprecated functionality
Summary of encountered deprecations:
- MissingArgumentsPropertyInGenericTestDeprecation: 1 occurrence
To see all deprecation instances instead of just the first occurrence of each,
run command again with the `--show-all-deprecations` flag. You may also need to
run with `--no-partial-parse` as some deprecations are only encountered during
parsing.
[0m14:25:32.600902 [debug] [MainThread]: Command `dbt build` succeeded at 14:25:32.600902 after 62.46 seconds
[0m14:25:32.600902 [debug] [MainThread]: Flushing usage events
[0m14:27:45.099984 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:27:45.327858 | 9b106c1c-9514-4fee-8acd-951eb0249a16 ==============================
[0m14:27:45.327858 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:27:45.327858 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m14:27:46.434182 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:27:46.434182 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:27:46.434182 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:27:47.476746 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:27:47.961300 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:27:48.214109 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:27:48.214109 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:27:48.422076 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:27:48.425117 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:27:48.434403 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:27:48.434403 [info ] [MainThread]: 
[0m14:27:48.434403 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:27:48.434403 [info ] [MainThread]: 
[0m14:27:48.434403 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:27:48.434403 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:27:48.453057 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:27:48.453057 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:27:48.453057 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:27:48.453057 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:27:48.453057 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:50.565388 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4752-17eb-967e-9b69b3f3918c) - Created
[0m14:27:51.020325 [debug] [ThreadPool]: SQL status: OK in 2.570 seconds
[0m14:27:51.020325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-4752-17eb-967e-9b69b3f3918c, command-id=01f08fdc-478f-1137-8fa4-2033dfa6defc) - Closing
[0m14:27:51.020325 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:27:51.020325 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4752-17eb-967e-9b69b3f3918c) - Closing
[0m14:27:51.325792 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:27:51.325792 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:27:51.325792 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:27:51.325792 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:27:51.325792 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:53.104816 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-48da-1ba7-9b46-c9086b0f7017) - Created
[0m14:27:53.553612 [debug] [ThreadPool]: SQL status: OK in 2.230 seconds
[0m14:27:53.555617 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-48da-1ba7-9b46-c9086b0f7017, command-id=01f08fdc-490e-1fb4-b9d3-3dbf72a30a42) - Closing
[0m14:27:53.557632 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:27:53.557632 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-48da-1ba7-9b46-c9086b0f7017) - Closing
[0m14:27:54.389274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:27:54.389274 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:27:54.419553 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:27:54.419553 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:27:54.419553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:55.628246 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4a6d-17ca-8743-5a40e2374ef0) - Created
[0m14:27:56.178322 [debug] [ThreadPool]: SQL status: OK in 1.760 seconds
[0m14:27:56.178322 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-4a6d-17ca-8743-5a40e2374ef0, command-id=01f08fdc-4a92-1218-bf34-ec77873b3c7c) - Closing
[0m14:27:56.178322 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:27:56.178322 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4a6d-17ca-8743-5a40e2374ef0) - Closing
[0m14:27:56.548689 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:27:56.548689 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:27:56.555177 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:27:56.555177 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:27:56.555177 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:27:57.948679 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4baf-1bd4-ba28-977830c35aeb) - Created
[0m14:27:58.594809 [debug] [ThreadPool]: SQL status: OK in 2.040 seconds
[0m14:27:58.599464 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-4baf-1bd4-ba28-977830c35aeb, command-id=01f08fdc-4bf1-18c6-8971-5f8da54a502c) - Closing
[0m14:27:58.599464 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:27:58.599464 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-4baf-1bd4-ba28-977830c35aeb) - Closing
[0m14:27:58.832223 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:27:58.832223 [info ] [Thread-5 (]: 1 of 7 START sql table model default.bronze_customer ........................... [RUN]
[0m14:27:58.832223 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:27:58.832223 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:27:58.832223 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:27:58.851495 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:27:58.852500 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:27:58.884644 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:27:58.884644 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:27:58.963053 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:27:58.963053 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:27:58.963053 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:27:58.966733 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:27:59.725303 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-4ce2-1912-8bb8-18a0bfeebc0c) - Created
[0m14:28:01.812926 [debug] [Thread-5 (]: SQL status: OK in 2.850 seconds
[0m14:28:01.814939 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-4ce2-1912-8bb8-18a0bfeebc0c, command-id=01f08fdc-4d01-1be9-81d4-bcad9f7e71bd) - Closing
[0m14:28:01.830251 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:01.849464 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:28:01.849464 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-4ce2-1912-8bb8-18a0bfeebc0c) - Closing
[0m14:28:02.484131 [info ] [Thread-5 (]: 1 of 7 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 3.65s]
[0m14:28:02.484131 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:28:02.484131 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:28:02.484131 [info ] [Thread-5 (]: 2 of 7 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:28:02.484131 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:28:02.484131 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:28:02.484131 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:28:02.500718 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:28:02.503354 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:28:02.527116 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:28:02.547146 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:28:02.548756 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:28:02.549817 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:28:02.550885 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:28:02.551460 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:03.820644 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-4f39-1e54-9871-27abc8807a94) - Created
[0m14:28:04.685437 [debug] [Thread-5 (]: SQL status: OK in 2.130 seconds
[0m14:28:04.686460 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-4f39-1e54-9871-27abc8807a94, command-id=01f08fdc-4f72-1be0-8a17-121be5fba235) - Closing
[0m14:28:04.688467 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:04.688467 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:28:04.688467 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-4f39-1e54-9871-27abc8807a94) - Closing
[0m14:28:04.943989 [info ] [Thread-5 (]: 2 of 7 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.46s]
[0m14:28:04.950024 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:28:04.950024 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:28:04.952131 [info ] [Thread-5 (]: 3 of 7 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:28:04.952131 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:28:04.952131 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:28:04.952131 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:28:04.952131 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:28:04.952131 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:28:04.952131 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:28:04.968158 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:28:04.969972 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:28:04.969972 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:28:04.971327 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:06.716932 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-50aa-1e38-83e7-63cfa1eaa403) - Created
[0m14:28:08.547214 [debug] [Thread-5 (]: SQL status: OK in 3.580 seconds
[0m14:28:08.547214 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-50aa-1e38-83e7-63cfa1eaa403, command-id=01f08fdc-512c-1a31-b080-178b8f16ea42) - Closing
[0m14:28:08.547214 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:08.547214 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:28:08.547214 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-50aa-1e38-83e7-63cfa1eaa403) - Closing
[0m14:28:08.832529 [info ] [Thread-5 (]: 3 of 7 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 3.88s]
[0m14:28:08.832529 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:28:08.832529 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:28:08.832529 [info ] [Thread-5 (]: 4 of 7 START sql view model default.bronze_returns ............................. [RUN]
[0m14:28:08.832529 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:28:08.832529 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:28:08.832529 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:28:08.850112 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:28:08.854131 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:28:08.965914 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:28:08.965914 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:28:08.965914 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:28:08.975156 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:28:08.975156 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:28:08.975156 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:10.476399 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5322-1056-8c32-1dd7c2ef554f) - Created
[0m14:28:11.607835 [debug] [Thread-5 (]: SQL status: OK in 2.630 seconds
[0m14:28:11.607835 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-5322-1056-8c32-1dd7c2ef554f, command-id=01f08fdc-5369-1c0d-9c2a-9e88581e3c61) - Closing
[0m14:28:11.607835 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:11.607835 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:28:11.607835 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5322-1056-8c32-1dd7c2ef554f) - Closing
[0m14:28:11.923073 [info ] [Thread-5 (]: 4 of 7 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.09s]
[0m14:28:11.932332 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:28:11.934338 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:28:11.934338 [info ] [Thread-5 (]: 5 of 7 START sql view model default.bronze_sales ............................... [RUN]
[0m14:28:11.936350 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:28:11.936350 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:28:11.938361 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:28:11.943705 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:28:11.945710 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:28:11.950628 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:28:11.952375 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:28:11.953569 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:28:11.955394 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:28:11.955394 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:28:11.957076 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:13.234305 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-54ac-199d-b2a9-7af5502ec3a1) - Created
[0m14:28:14.161459 [debug] [Thread-5 (]: SQL status: OK in 2.210 seconds
[0m14:28:14.165477 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-54ac-199d-b2a9-7af5502ec3a1, command-id=01f08fdc-550e-1747-88bf-e71d0cfe376d) - Closing
[0m14:28:14.165477 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:14.167499 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:28:14.167499 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-54ac-199d-b2a9-7af5502ec3a1) - Closing
[0m14:28:14.508766 [info ] [Thread-5 (]: 5 of 7 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 2.57s]
[0m14:28:14.508766 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:28:14.508766 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:28:14.508766 [info ] [Thread-5 (]: 6 of 7 START sql table model default.bronze_store .............................. [RUN]
[0m14:28:14.508766 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:28:14.508766 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:28:14.508766 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:28:14.508766 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:28:14.508766 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:28:14.526032 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:28:14.526032 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:28:14.526032 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:28:14.526032 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:28:14.526032 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:15.368116 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5634-106d-9b20-54dbd3a9be7f) - Created
[0m14:28:17.385318 [debug] [Thread-5 (]: SQL status: OK in 2.860 seconds
[0m14:28:17.387322 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-5634-106d-9b20-54dbd3a9be7f, command-id=01f08fdc-5653-1995-a003-7d06c32c82d1) - Closing
[0m14:28:17.387322 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:17.389327 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:28:17.389327 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5634-106d-9b20-54dbd3a9be7f) - Closing
[0m14:28:17.599716 [info ] [Thread-5 (]: 6 of 7 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 3.09s]
[0m14:28:17.599716 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:28:17.599716 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m14:28:17.599716 [info ] [Thread-5 (]: 7 of 7 START sql view model default.silver_sales ............................... [RUN]
[0m14:28:17.599716 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:28:17.599716 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:28:17.599716 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:28:17.615836 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:28:17.615836 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:28:17.615836 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:28:17.615836 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:28:17.615836 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:28:17.615836 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:28:17.632062 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:28:17.632400 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:28:18.382716 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5801-17ae-9627-8d83c4397d02) - Created
[0m14:28:19.259375 [debug] [Thread-5 (]: SQL status: OK in 1.630 seconds
[0m14:28:19.260949 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-5801-17ae-9627-8d83c4397d02, command-id=01f08fdc-5821-128f-8263-39cdc18f5ed7) - Closing
[0m14:28:19.261963 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:28:19.264547 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m14:28:19.265082 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-5801-17ae-9627-8d83c4397d02) - Closing
[0m14:28:19.496141 [info ] [Thread-5 (]: 7 of 7 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 1.90s]
[0m14:28:19.496141 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:28:19.507602 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:28:19.507602 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:28:19.507602 [info ] [MainThread]: 
[0m14:28:19.509609 [info ] [MainThread]: Finished running 3 table models, 4 view models in 0 hours 0 minutes and 31.07 seconds (31.07s).
[0m14:28:19.511339 [debug] [MainThread]: Command end result
[0m14:28:19.585275 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:28:19.585275 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:28:19.603134 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:28:19.603134 [info ] [MainThread]: 
[0m14:28:19.603134 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:28:19.603134 [info ] [MainThread]: 
[0m14:28:19.603134 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m14:28:19.610660 [debug] [MainThread]: Command `dbt run` succeeded at 14:28:19.610098 after 34.59 seconds
[0m14:28:19.611147 [debug] [MainThread]: Flushing usage events
[0m14:30:16.329942 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:30:16.549747 | ce14e20a-d95f-4065-86d6-a52bba4a973a ==============================
[0m14:30:16.549747 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:30:16.549747 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt run', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'empty': 'False', 'quiet': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m14:30:17.724035 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:30:17.724035 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:30:17.724035 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:30:18.866495 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:30:19.346356 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:30:19.592706 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:30:19.592706 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:30:19.814285 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:30:19.821394 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:30:19.831909 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 7 data tests, 6 sources, 688 macros
[0m14:30:19.840424 [info ] [MainThread]: 
[0m14:30:19.840424 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:30:19.840424 [info ] [MainThread]: 
[0m14:30:19.840424 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:30:19.840424 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:30:19.856462 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:30:19.856880 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:30:19.856880 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:30:19.859125 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:30:19.859752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:21.306825 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a13c-135e-ba41-602d9cd36d46) - Created
[0m14:30:21.841095 [debug] [ThreadPool]: SQL status: OK in 1.980 seconds
[0m14:30:21.841095 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-a13c-135e-ba41-602d9cd36d46, command-id=01f08fdc-a16a-1e56-b1ce-914cd698961c) - Closing
[0m14:30:21.841095 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:30:21.841095 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a13c-135e-ba41-602d9cd36d46) - Closing
[0m14:30:22.058729 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:30:22.058729 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:30:22.058729 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:30:22.058729 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:30:22.058729 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:22.855508 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a22c-1932-9903-d0362d4ed4aa) - Created
[0m14:30:23.259272 [debug] [ThreadPool]: SQL status: OK in 1.200 seconds
[0m14:30:23.259272 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-a22c-1932-9903-d0362d4ed4aa, command-id=01f08fdc-a250-137e-94fd-614c6b6e387e) - Closing
[0m14:30:23.259272 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:30:23.259272 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a22c-1932-9903-d0362d4ed4aa) - Closing
[0m14:30:23.710471 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:30:23.710471 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:30:23.729106 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:30:23.729106 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:30:23.729106 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:24.871273 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a35c-1cf4-b9cc-82faf5723f65) - Created
[0m14:30:25.426033 [debug] [ThreadPool]: SQL status: OK in 1.700 seconds
[0m14:30:25.432249 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-a35c-1cf4-b9cc-82faf5723f65, command-id=01f08fdc-a384-13ac-aa44-f83a25ed9b29) - Closing
[0m14:30:25.434280 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:30:25.434280 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a35c-1cf4-b9cc-82faf5723f65) - Closing
[0m14:30:25.871806 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:30:25.871806 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:30:25.871806 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:30:25.871806 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:30:25.871806 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:30:26.629600 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a473-1395-9a1e-0c45ae6bf1b7) - Created
[0m14:30:27.146389 [debug] [ThreadPool]: SQL status: OK in 1.270 seconds
[0m14:30:27.164626 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdc-a473-1395-9a1e-0c45ae6bf1b7, command-id=01f08fdc-a491-1db9-9976-b8928c93418d) - Closing
[0m14:30:27.164626 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:30:27.164626 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdc-a473-1395-9a1e-0c45ae6bf1b7) - Closing
[0m14:30:27.398227 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:30:27.398227 [info ] [Thread-5 (]: 1 of 7 START sql table model default.bronze_customer ........................... [RUN]
[0m14:30:27.398227 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:30:27.398227 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:30:27.398227 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:30:27.413143 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:30:27.413143 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:30:27.456799 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:30:27.460976 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:30:27.512169 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:30:27.512169 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:30:27.512169 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:30:27.512169 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:28.917895 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-a5a6-1fe3-926a-e471b0b9e767) - Created
[0m14:30:31.204815 [debug] [Thread-5 (]: SQL status: OK in 3.690 seconds
[0m14:30:31.204815 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-a5a6-1fe3-926a-e471b0b9e767, command-id=01f08fdc-a5f0-1dfa-969d-5c89bca06e94) - Closing
[0m14:30:31.226881 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:31.249434 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:30:31.249434 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-a5a6-1fe3-926a-e471b0b9e767) - Closing
[0m14:30:32.307514 [info ] [Thread-5 (]: 1 of 7 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.91s]
[0m14:30:32.309519 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:30:32.309519 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:30:32.309519 [info ] [Thread-5 (]: 2 of 7 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:30:32.309519 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:30:32.309519 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:30:32.313995 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:30:32.318003 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:30:32.320007 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:30:32.342746 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:30:32.358800 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:30:32.358800 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:30:32.358800 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:30:32.358800 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:30:32.358800 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:34.041221 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-a8a6-13b0-8991-c6241613747f) - Created
[0m14:30:34.971267 [debug] [Thread-5 (]: SQL status: OK in 2.610 seconds
[0m14:30:34.971267 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-a8a6-13b0-8991-c6241613747f, command-id=01f08fdc-a8fe-197a-b6f3-1546623478b1) - Closing
[0m14:30:34.971267 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:34.971267 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:30:34.971267 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-a8a6-13b0-8991-c6241613747f) - Closing
[0m14:30:35.199529 [info ] [Thread-5 (]: 2 of 7 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 2.89s]
[0m14:30:35.201533 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:30:35.201533 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:30:35.201533 [info ] [Thread-5 (]: 3 of 7 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:30:35.201533 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:30:35.201533 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:30:35.205265 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:30:35.209311 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:30:35.209311 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:30:35.213503 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:30:35.213503 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:30:35.213503 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:30:35.213503 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:30:35.213503 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:36.438283 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-aa41-1b1a-a304-eccfcf954aef) - Created
[0m14:30:39.274710 [debug] [Thread-5 (]: SQL status: OK in 4.060 seconds
[0m14:30:39.277505 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-aa41-1b1a-a304-eccfcf954aef, command-id=01f08fdc-aa6a-1429-ac77-8db26088dd82) - Closing
[0m14:30:39.279511 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:39.279511 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:30:39.281520 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-aa41-1b1a-a304-eccfcf954aef) - Closing
[0m14:30:39.773056 [info ] [Thread-5 (]: 3 of 7 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 4.57s]
[0m14:30:39.773056 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:30:39.773056 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:30:39.773056 [info ] [Thread-5 (]: 4 of 7 START sql view model default.bronze_returns ............................. [RUN]
[0m14:30:39.773056 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:30:39.787238 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:30:39.788239 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:30:39.792777 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:30:39.792777 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:30:39.907758 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:30:39.907758 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:30:39.907758 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:30:39.907758 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:30:39.907758 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:30:39.907758 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:42.025214 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-ad81-192b-bf96-ba8e13a43974) - Created
[0m14:30:43.166499 [debug] [Thread-5 (]: SQL status: OK in 3.260 seconds
[0m14:30:43.168504 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-ad81-192b-bf96-ba8e13a43974, command-id=01f08fdc-adc3-18e4-9328-baaa0bdfe635) - Closing
[0m14:30:43.170516 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:43.171520 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:30:43.171520 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-ad81-192b-bf96-ba8e13a43974) - Closing
[0m14:30:43.428763 [info ] [Thread-5 (]: 4 of 7 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 3.65s]
[0m14:30:43.428763 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:30:43.428763 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:30:43.428763 [info ] [Thread-5 (]: 5 of 7 START sql view model default.bronze_sales ............................... [RUN]
[0m14:30:43.428763 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:30:43.428763 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:30:43.428763 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:30:43.428763 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:30:43.428763 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:30:43.439003 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:30:43.440759 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_sales`
[0m14:30:43.441767 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:30:43.442660 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:30:43.443866 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_sales`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:30:43.443866 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:44.897607 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-af35-1ca7-ab1c-d713537ba0de) - Created
[0m14:30:46.229751 [debug] [Thread-5 (]: SQL status: OK in 2.790 seconds
[0m14:30:46.231757 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-af35-1ca7-ab1c-d713537ba0de, command-id=01f08fdc-af77-146b-9c41-9203f69a5ff7) - Closing
[0m14:30:46.233763 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:46.235268 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:30:46.236027 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-af35-1ca7-ab1c-d713537ba0de) - Closing
[0m14:30:46.743896 [info ] [Thread-5 (]: 5 of 7 OK created sql view model default.bronze_sales .......................... [[32mOK[0m in 3.32s]
[0m14:30:46.743896 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:30:46.743896 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:30:46.743896 [info ] [Thread-5 (]: 6 of 7 START sql table model default.bronze_store .............................. [RUN]
[0m14:30:46.743896 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:30:46.743896 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:30:46.743896 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:30:46.753421 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:30:46.753421 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:30:46.758484 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:30:46.759454 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:30:46.759454 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:30:46.759454 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:30:46.763541 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:48.589659 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-b181-1c30-aa24-9b4fbd2593a9) - Created
[0m14:30:50.776538 [debug] [Thread-5 (]: SQL status: OK in 4.010 seconds
[0m14:30:50.777544 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-b181-1c30-aa24-9b4fbd2593a9, command-id=01f08fdc-b1a8-17c8-8c24-c8319f18452c) - Closing
[0m14:30:50.777544 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:50.777544 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:30:50.777544 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-b181-1c30-aa24-9b4fbd2593a9) - Closing
[0m14:30:51.248214 [info ] [Thread-5 (]: 6 of 7 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 4.50s]
[0m14:30:51.248214 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:30:51.248214 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m14:30:51.248214 [info ] [Thread-5 (]: 7 of 7 START sql view model default.silver_sales ............................... [RUN]
[0m14:30:51.248214 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:30:51.248214 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:30:51.248214 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:30:51.248214 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:30:51.263931 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:30:51.268416 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:30:51.273852 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:30:51.275917 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:30:51.277927 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:30:51.279009 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`default`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:30:51.279627 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:30:53.313372 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-b448-19da-b2f9-4f78e1db155f) - Created
[0m14:30:54.463503 [debug] [Thread-5 (]: SQL status: OK in 3.170 seconds
[0m14:30:54.463503 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdc-b448-19da-b2f9-4f78e1db155f, command-id=01f08fdc-b478-1f5b-a533-2d5b2c9444da) - Closing
[0m14:30:54.463503 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:30:54.463503 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m14:30:54.463503 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdc-b448-19da-b2f9-4f78e1db155f) - Closing
[0m14:30:55.161405 [info ] [Thread-5 (]: 7 of 7 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 3.91s]
[0m14:30:55.161405 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:30:55.161405 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:30:55.161405 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:30:55.161405 [info ] [MainThread]: 
[0m14:30:55.161405 [info ] [MainThread]: Finished running 3 table models, 4 view models in 0 hours 0 minutes and 35.32 seconds (35.32s).
[0m14:30:55.161405 [debug] [MainThread]: Command end result
[0m14:30:55.207587 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:30:55.207587 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:30:55.222621 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:30:55.222621 [info ] [MainThread]: 
[0m14:30:55.230563 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:30:55.230563 [info ] [MainThread]: 
[0m14:30:55.230563 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m14:30:55.230563 [debug] [MainThread]: Command `dbt run` succeeded at 14:30:55.230563 after 38.98 seconds
[0m14:30:55.230563 [debug] [MainThread]: Flushing usage events
[0m14:32:55.913816 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 14:32:56.119161 | 10fb47fb-d032-4487-a058-fc5297f428a8 ==============================
[0m14:32:56.119161 [info ] [MainThread]: Running with dbt=1.10.11
[0m14:32:56.119161 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'log_cache_events': 'False', 'empty': 'False', 'use_experimental_parser': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m14:32:57.482339 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m14:32:57.482339 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m14:32:57.482339 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m14:32:58.687136 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m14:32:59.191781 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m14:32:59.465222 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m14:32:59.465222 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m14:32:59.686175 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:32:59.690875 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:32:59.703527 [info ] [MainThread]: Found 7 models, 2 analyses, 1 seed, 3 data tests, 6 sources, 688 macros
[0m14:32:59.707127 [info ] [MainThread]: 
[0m14:32:59.707127 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m14:32:59.707127 [info ] [MainThread]: 
[0m14:32:59.707127 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:32:59.707127 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:32:59.722958 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:32:59.722958 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:32:59.722958 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:32:59.726097 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:32:59.726097 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:00.687896 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0044-13d4-8c34-fd84fc06a996) - Created
[0m14:33:01.298770 [debug] [ThreadPool]: SQL status: OK in 1.570 seconds
[0m14:33:01.300960 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdd-0044-13d4-8c34-fd84fc06a996, command-id=01f08fdd-0068-1662-898e-cb1e15ad00f9) - Closing
[0m14:33:01.300960 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:33:01.300960 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0044-13d4-8c34-fd84fc06a996) - Closing
[0m14:33:01.569274 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m14:33:01.569274 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m14:33:01.572353 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m14:33:01.572353 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m14:33:01.572353 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:02.354202 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0142-1326-9bf6-21230ddfbe63) - Created
[0m14:33:02.764258 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m14:33:02.766266 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdd-0142-1326-9bf6-21230ddfbe63, command-id=01f08fdd-0163-1e62-8bbe-b7362ab930fd) - Closing
[0m14:33:02.766266 [debug] [ThreadPool]: On list_dbt-project: Close
[0m14:33:02.768273 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0142-1326-9bf6-21230ddfbe63) - Closing
[0m14:33:03.015329 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m14:33:03.017335 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m14:33:03.048866 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m14:33:03.050872 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m14:33:03.050872 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:03.872329 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-022a-1bfe-b7db-aa734d1a63b6) - Created
[0m14:33:04.395309 [debug] [ThreadPool]: SQL status: OK in 1.340 seconds
[0m14:33:04.403356 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdd-022a-1bfe-b7db-aa734d1a63b6, command-id=01f08fdd-0249-102f-9402-ebd418b8026f) - Closing
[0m14:33:04.403356 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m14:33:04.403356 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-022a-1bfe-b7db-aa734d1a63b6) - Closing
[0m14:33:04.605240 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m14:33:04.620945 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m14:33:04.620945 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m14:33:04.620945 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m14:33:04.620945 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m14:33:05.417896 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0315-15c3-9f4c-e2fc92be8727) - Created
[0m14:33:06.419298 [debug] [ThreadPool]: SQL status: OK in 1.800 seconds
[0m14:33:06.424513 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fdd-0315-15c3-9f4c-e2fc92be8727, command-id=01f08fdd-0335-1f88-96bb-9bdd586edd90) - Closing
[0m14:33:06.424513 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m14:33:06.424513 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fdd-0315-15c3-9f4c-e2fc92be8727) - Closing
[0m14:33:06.790208 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_customer
[0m14:33:06.793452 [info ] [Thread-5 (]: 1 of 7 START sql table model default.bronze_customer ........................... [RUN]
[0m14:33:06.795808 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m14:33:06.795808 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m14:33:06.795808 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m14:33:06.795808 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m14:33:06.812845 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_customer
[0m14:33:06.836271 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:33:06.836271 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m14:33:06.906406 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m14:33:06.906406 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m14:33:06.906406 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m14:33:06.906406 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:07.854902 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-047f-1efc-8ce3-e542e8fc8991) - Created
[0m14:33:10.202316 [debug] [Thread-5 (]: SQL status: OK in 3.300 seconds
[0m14:33:10.202316 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-047f-1efc-8ce3-e542e8fc8991, command-id=01f08fdd-04a9-16af-8ef4-de4550379c06) - Closing
[0m14:33:10.215369 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:10.231263 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_customer: Close
[0m14:33:10.231263 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-047f-1efc-8ce3-e542e8fc8991) - Closing
[0m14:33:11.070753 [info ] [Thread-5 (]: 1 of 7 OK created sql table model default.bronze_customer ...................... [[32mOK[0m in 4.28s]
[0m14:33:11.070753 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_customer
[0m14:33:11.070753 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_date
[0m14:33:11.070753 [info ] [Thread-5 (]: 2 of 7 START sql view model bronze.bronze_date ................................. [RUN]
[0m14:33:11.070753 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m14:33:11.070753 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m14:33:11.070753 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_date
[0m14:33:11.077553 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m14:33:11.080261 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_date
[0m14:33:11.103047 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:33:11.119428 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m14:33:11.119428 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m14:33:11.119428 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m14:33:11.119428 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m14:33:11.119428 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:12.879620 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0772-107a-b752-a06b0a600f07) - Created
[0m14:33:13.973712 [debug] [Thread-5 (]: SQL status: OK in 2.850 seconds
[0m14:33:13.975717 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-0772-107a-b752-a06b0a600f07, command-id=01f08fdd-07ab-1396-98af-8f26487a98ca) - Closing
[0m14:33:13.977221 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:13.979226 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_date: Close
[0m14:33:13.979226 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0772-107a-b752-a06b0a600f07) - Closing
[0m14:33:14.297344 [info ] [Thread-5 (]: 2 of 7 OK created sql view model bronze.bronze_date ............................ [[32mOK[0m in 3.23s]
[0m14:33:14.297344 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_date
[0m14:33:14.297344 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m14:33:14.297344 [info ] [Thread-5 (]: 3 of 7 START sql table model default.bronze_dim_product ........................ [RUN]
[0m14:33:14.307911 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m14:33:14.307911 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m14:33:14.307911 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m14:33:14.307911 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m14:33:14.307911 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m14:33:14.307911 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:33:14.307911 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m14:33:14.307911 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m14:33:14.307911 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m14:33:14.321379 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:16.865231 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-09dd-118b-b643-e277af9b6eb2) - Created
[0m14:33:19.319184 [debug] [Thread-5 (]: SQL status: OK in 5.000 seconds
[0m14:33:19.319184 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-09dd-118b-b643-e277af9b6eb2, command-id=01f08fdd-0a08-177a-a098-1e8dc2faa7cc) - Closing
[0m14:33:19.319184 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:19.319184 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m14:33:19.319184 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-09dd-118b-b643-e277af9b6eb2) - Closing
[0m14:33:19.612592 [info ] [Thread-5 (]: 3 of 7 OK created sql table model default.bronze_dim_product ................... [[32mOK[0m in 5.30s]
[0m14:33:19.612592 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m14:33:19.612592 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_returns
[0m14:33:19.612592 [info ] [Thread-5 (]: 4 of 7 START sql view model default.bronze_returns ............................. [RUN]
[0m14:33:19.612592 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m14:33:19.612592 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m14:33:19.612592 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m14:33:19.626789 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m14:33:19.628582 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_returns
[0m14:33:19.643457 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:33:19.773136 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m14:33:19.773136 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m14:33:19.773136 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m14:33:19.776748 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m14:33:19.776748 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:20.897165 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0c25-10e2-a2fe-e4754d514a3c) - Created
[0m14:33:21.996575 [debug] [Thread-5 (]: SQL status: OK in 2.220 seconds
[0m14:33:21.996575 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-0c25-10e2-a2fe-e4754d514a3c, command-id=01f08fdd-0c71-1617-9c76-f76a3f66d9c4) - Closing
[0m14:33:21.996575 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:21.996575 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_returns: Close
[0m14:33:21.996575 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0c25-10e2-a2fe-e4754d514a3c) - Closing
[0m14:33:22.519609 [info ] [Thread-5 (]: 4 of 7 OK created sql view model default.bronze_returns ........................ [[32mOK[0m in 2.91s]
[0m14:33:22.519609 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_returns
[0m14:33:22.519609 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_sales
[0m14:33:22.522874 [info ] [Thread-5 (]: 5 of 7 START sql view model bronze.bronze_sales ................................ [RUN]
[0m14:33:22.524017 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m14:33:22.524017 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m14:33:22.524017 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m14:33:22.524017 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m14:33:22.524017 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_sales
[0m14:33:22.524017 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:33:22.524017 [debug] [Thread-5 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m14:33:22.524017 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m14:33:22.524017 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m14:33:22.524017 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m14:33:22.524017 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:23.528751 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0de2-1a65-99a2-eb86b91510fd) - Created
[0m14:33:24.169246 [debug] [Thread-5 (]: SQL status: OK in 1.650 seconds
[0m14:33:24.174332 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-0de2-1a65-99a2-eb86b91510fd, command-id=01f08fdd-0e01-189c-90dc-5de178c84903) - Closing
[0m14:33:24.174332 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:24.176337 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_sales: Close
[0m14:33:24.176337 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0de2-1a65-99a2-eb86b91510fd) - Closing
[0m14:33:24.422150 [info ] [Thread-5 (]: 5 of 7 OK created sql view model bronze.bronze_sales ........................... [[32mOK[0m in 1.90s]
[0m14:33:24.422150 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_sales
[0m14:33:24.422150 [debug] [Thread-5 (]: Began running node model.dbt_eTl.bronze_store
[0m14:33:24.422150 [info ] [Thread-5 (]: 6 of 7 START sql table model default.bronze_store .............................. [RUN]
[0m14:33:24.422150 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m14:33:24.422150 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m14:33:24.422150 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.bronze_store
[0m14:33:24.422150 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m14:33:24.422150 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.bronze_store
[0m14:33:24.439873 [debug] [Thread-5 (]: MATERIALIZING TABLE
[0m14:33:24.439873 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m14:33:24.443399 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m14:33:24.444336 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m14:33:24.444873 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:26.388014 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0f7e-111f-9db8-80062615e7ac) - Created
[0m14:33:28.741768 [debug] [Thread-5 (]: SQL status: OK in 4.300 seconds
[0m14:33:28.741768 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-0f7e-111f-9db8-80062615e7ac, command-id=01f08fdd-0fb6-1614-8f38-219046ad7fad) - Closing
[0m14:33:28.741768 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:28.741768 [debug] [Thread-5 (]: On model.dbt_eTl.bronze_store: Close
[0m14:33:28.741768 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-0f7e-111f-9db8-80062615e7ac) - Closing
[0m14:33:29.605494 [info ] [Thread-5 (]: 6 of 7 OK created sql table model default.bronze_store ......................... [[32mOK[0m in 5.18s]
[0m14:33:29.605494 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.bronze_store
[0m14:33:29.607502 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m14:33:29.607502 [info ] [Thread-5 (]: 7 of 7 START sql view model default.silver_sales ............................... [RUN]
[0m14:33:29.607502 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m14:33:29.609795 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m14:33:29.609795 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m14:33:29.618970 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m14:33:29.621991 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m14:33:29.626011 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m14:33:29.627904 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m14:33:29.629170 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m14:33:29.631207 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m14:33:29.633721 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m14:33:29.633721 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m14:33:30.589166 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-1216-18b2-9851-b98dd95c48cf) - Created
[0m14:33:31.611360 [debug] [Thread-5 (]: SQL status: OK in 1.980 seconds
[0m14:33:31.611360 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08fdd-1216-18b2-9851-b98dd95c48cf, command-id=01f08fdd-1237-1f0b-a6d1-17918e844875) - Closing
[0m14:33:31.611360 [debug] [Thread-5 (]: Applying tags to relation None
[0m14:33:31.611360 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m14:33:31.615229 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08fdd-1216-18b2-9851-b98dd95c48cf) - Closing
[0m14:33:32.031628 [info ] [Thread-5 (]: 7 of 7 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 2.42s]
[0m14:33:32.032677 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m14:33:32.034925 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m14:33:32.035469 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m14:33:32.036516 [info ] [MainThread]: 
[0m14:33:32.037035 [info ] [MainThread]: Finished running 3 table models, 4 view models in 0 hours 0 minutes and 32.33 seconds (32.33s).
[0m14:33:32.040029 [debug] [MainThread]: Command end result
[0m14:33:32.086847 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m14:33:32.086847 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m14:33:32.101345 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m14:33:32.103384 [info ] [MainThread]: 
[0m14:33:32.103928 [info ] [MainThread]: [32mCompleted successfully[0m
[0m14:33:32.103928 [info ] [MainThread]: 
[0m14:33:32.103928 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=7
[0m14:33:32.103928 [debug] [MainThread]: Command `dbt run` succeeded at 14:33:32.103928 after 36.27 seconds
[0m14:33:32.103928 [debug] [MainThread]: Flushing usage events
[0m16:46:26.969757 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:46:27.234063 | 9032de7a-e13c-43c0-b4f4-33eabbf90db1 ==============================
[0m16:46:27.234063 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:46:27.236075 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m16:46:28.905512 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:46:28.905512 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:46:28.905512 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:46:31.167451 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:46:31.949181 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:46:32.378399 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m16:46:32.378399 [debug] [MainThread]: Partial parsing: added file: dbt_eTl://snapshots\gold_items.yml
[0m16:46:33.268818 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:46:33.268818 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:46:33.465932 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:46:33.472128 [info ] [MainThread]: 
[0m16:46:33.472128 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:46:33.475168 [info ] [MainThread]: 
[0m16:46:33.479282 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:46:33.480792 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:46:33.499904 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:46:33.499904 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:46:33.499904 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:46:33.499904 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:46:33.499904 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:34.415259 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-a928-1ab1-8ec5-47454d05a073) - Created
[0m16:46:35.078024 [debug] [ThreadPool]: SQL status: OK in 1.580 seconds
[0m16:46:35.080024 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-a928-1ab1-8ec5-47454d05a073, command-id=01f08fef-a94b-1a2c-8cb5-d60ee490d7a1) - Closing
[0m16:46:35.080792 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:46:35.080792 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-a928-1ab1-8ec5-47454d05a073) - Closing
[0m16:46:35.322844 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:46:35.323372 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:46:35.323898 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:46:35.324457 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:46:35.324998 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:36.108693 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-aa2b-193e-b420-10caff19e379) - Created
[0m16:46:36.434945 [debug] [ThreadPool]: SQL status: OK in 1.110 seconds
[0m16:46:36.434945 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-aa2b-193e-b420-10caff19e379, command-id=01f08fef-aa4d-193f-9a6f-2bd5c26eb8f4) - Closing
[0m16:46:36.434945 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:46:36.434945 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-aa2b-193e-b420-10caff19e379) - Closing
[0m16:46:36.721213 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:46:36.721213 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:46:36.721213 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:46:36.721213 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:46:36.721213 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:37.469519 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-aaff-1064-9dd9-6dbe440e77e2) - Created
[0m16:46:38.086282 [debug] [ThreadPool]: SQL status: OK in 1.370 seconds
[0m16:46:38.086282 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-aaff-1064-9dd9-6dbe440e77e2, command-id=01f08fef-ab1e-1abc-8d05-64d2f630522f) - Closing
[0m16:46:38.086282 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:46:38.086282 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-aaff-1064-9dd9-6dbe440e77e2) - Closing
[0m16:46:38.318379 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=create_dbt-project_gold) - Creating connection
[0m16:46:38.318379 [debug] [ThreadPool]: Acquiring new databricks connection 'create_dbt-project_gold'
[0m16:46:38.320700 [debug] [ThreadPool]: Creating schema "database: "dbt-project"
schema: "gold"
"
[0m16:46:38.337063 [debug] [ThreadPool]: Using databricks connection "create_dbt-project_gold"
[0m16:46:38.337063 [debug] [ThreadPool]: On create_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "create_dbt-project_gold"} */
create schema if not exists `dbt-project`.`gold`
  
[0m16:46:38.338063 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:39.116582 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-abf6-1bd5-88ac-dbe8e000a36c) - Created
[0m16:46:40.277573 [debug] [ThreadPool]: SQL status: OK in 1.940 seconds
[0m16:46:40.277573 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-abf6-1bd5-88ac-dbe8e000a36c, command-id=01f08fef-ac18-1aad-90c0-805ead7819e8) - Closing
[0m16:46:40.277573 [debug] [ThreadPool]: On create_dbt-project_gold: Close
[0m16:46:40.277573 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-abf6-1bd5-88ac-dbe8e000a36c) - Closing
[0m16:46:40.527459 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:46:40.529468 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:46:40.529468 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:46:40.529468 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:46:40.529468 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:41.312875 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-ad47-165c-9f8f-fe5ae298661d) - Created
[0m16:46:43.524400 [debug] [ThreadPool]: SQL status: OK in 2.990 seconds
[0m16:46:43.556652 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-ad47-165c-9f8f-fe5ae298661d, command-id=01f08fef-ad69-1a79-8422-7477af8d430c) - Closing
[0m16:46:43.558168 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:46:43.558168 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-ad47-165c-9f8f-fe5ae298661d) - Closing
[0m16:46:43.836325 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m16:46:43.836325 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m16:46:43.852295 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m16:46:43.852295 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m16:46:43.852295 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:44.871647 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-af67-1902-b851-d22290e502b2) - Created
[0m16:46:45.415958 [debug] [ThreadPool]: SQL status: OK in 1.560 seconds
[0m16:46:45.418970 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-af67-1902-b851-d22290e502b2, command-id=01f08fef-af88-1bfc-b2c2-514b6e4bf95d) - Closing
[0m16:46:45.418970 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m16:46:45.418970 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-af67-1902-b851-d22290e502b2) - Closing
[0m16:46:45.642910 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:46:45.642910 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:46:45.642910 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:46:45.642910 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:46:45.642910 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:46:46.493118 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-b05c-177c-96bb-faee809cf071) - Created
[0m16:46:47.209180 [debug] [ThreadPool]: SQL status: OK in 1.570 seconds
[0m16:46:47.209180 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-b05c-177c-96bb-faee809cf071, command-id=01f08fef-b07e-18b1-be0e-e89aabeaa971) - Closing
[0m16:46:47.217618 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:46:47.217618 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-b05c-177c-96bb-faee809cf071) - Closing
[0m16:46:47.445686 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_customer
[0m16:46:47.445686 [info ] [Thread-8 (]: 1 of 13 START sql table model default.bronze_customer .......................... [RUN]
[0m16:46:47.447695 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m16:46:47.447695 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m16:46:47.447695 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m16:46:47.449702 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m16:46:47.457733 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_customer
[0m16:46:47.480897 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m16:46:47.482071 [warn ] [Thread-8 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:46:47.542030 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m16:46:47.545032 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m16:46:47.545032 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m16:46:47.546038 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:46:48.630300 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b187-1442-954c-e49e86dc7b45) - Created
[0m16:46:56.454816 [debug] [Thread-8 (]: SQL status: OK in 8.900 seconds
[0m16:46:56.454816 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-b187-1442-954c-e49e86dc7b45, command-id=01f08fef-b1c5-1334-b001-76f59ca47701) - Closing
[0m16:46:56.975960 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:46:56.991610 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_customer: Close
[0m16:46:56.991610 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b187-1442-954c-e49e86dc7b45) - Closing
[0m16:46:57.293667 [info ] [Thread-8 (]: 1 of 13 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 9.84s]
[0m16:46:57.294687 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_customer
[0m16:46:57.294687 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_date
[0m16:46:57.296749 [info ] [Thread-8 (]: 2 of 13 START sql view model bronze.bronze_date ................................ [RUN]
[0m16:46:57.297798 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m16:46:57.298338 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m16:46:57.298872 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_date
[0m16:46:57.303137 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m16:46:57.303137 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_date
[0m16:46:57.338035 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m16:46:57.364090 [debug] [Thread-8 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m16:46:57.364090 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m16:46:57.364090 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m16:46:57.364090 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m16:46:57.364090 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:46:58.308580 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b769-1973-b8dc-300b395e50e9) - Created
[0m16:46:59.476404 [debug] [Thread-8 (]: SQL status: OK in 2.110 seconds
[0m16:46:59.478606 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-b769-1973-b8dc-300b395e50e9, command-id=01f08fef-b789-14ce-aea9-7c7fea46a34f) - Closing
[0m16:46:59.480108 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:46:59.489694 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_date: Close
[0m16:46:59.489694 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b769-1973-b8dc-300b395e50e9) - Closing
[0m16:46:59.735597 [info ] [Thread-8 (]: 2 of 13 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.44s]
[0m16:46:59.735597 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_date
[0m16:46:59.751357 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m16:46:59.751357 [info ] [Thread-8 (]: 3 of 13 START sql table model default.bronze_dim_product ....................... [RUN]
[0m16:46:59.751357 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m16:46:59.751357 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m16:46:59.751357 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m16:46:59.751357 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m16:46:59.751357 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m16:46:59.761117 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m16:46:59.763124 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m16:46:59.765130 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m16:46:59.765130 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m16:46:59.765130 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:00.550206 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b8c0-13e8-9cc1-69e095ef334d) - Created
[0m16:47:06.702156 [debug] [Thread-8 (]: SQL status: OK in 6.940 seconds
[0m16:47:06.704166 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-b8c0-13e8-9cc1-69e095ef334d, command-id=01f08fef-b8e1-1e67-9cfb-784465873ca7) - Closing
[0m16:47:06.987964 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:06.989976 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m16:47:06.989976 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-b8c0-13e8-9cc1-69e095ef334d) - Closing
[0m16:47:07.333517 [info ] [Thread-8 (]: 3 of 13 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 7.58s]
[0m16:47:07.335523 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m16:47:07.335523 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_returns
[0m16:47:07.337531 [info ] [Thread-8 (]: 4 of 13 START sql view model default.bronze_returns ............................ [RUN]
[0m16:47:07.337531 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m16:47:07.339539 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m16:47:07.339539 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m16:47:07.348638 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m16:47:07.351899 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_returns
[0m16:47:07.355383 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m16:47:07.358632 [debug] [Thread-8 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m16:47:07.359785 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m16:47:07.362307 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m16:47:07.363092 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m16:47:07.364808 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:08.487844 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-bd76-19e5-a3a0-c8351847b0fe) - Created
[0m16:47:09.867296 [debug] [Thread-8 (]: SQL status: OK in 2.500 seconds
[0m16:47:09.867296 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-bd76-19e5-a3a0-c8351847b0fe, command-id=01f08fef-bd9a-1a8c-bf63-2ea58a7a2dcd) - Closing
[0m16:47:09.867296 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:09.867296 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_returns: Close
[0m16:47:09.867296 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-bd76-19e5-a3a0-c8351847b0fe) - Closing
[0m16:47:10.256599 [info ] [Thread-8 (]: 4 of 13 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 2.92s]
[0m16:47:10.256599 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_returns
[0m16:47:10.256599 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_sales
[0m16:47:10.256599 [info ] [Thread-8 (]: 5 of 13 START sql view model bronze.bronze_sales ............................... [RUN]
[0m16:47:10.256599 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m16:47:10.256599 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m16:47:10.256599 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m16:47:10.271935 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m16:47:10.274243 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_sales
[0m16:47:10.278677 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m16:47:10.279707 [debug] [Thread-8 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m16:47:10.281030 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m16:47:10.283397 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m16:47:10.284023 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m16:47:10.285265 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:11.128602 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-bf0e-1833-920f-27e45131b576) - Created
[0m16:47:12.328058 [debug] [Thread-8 (]: SQL status: OK in 2.040 seconds
[0m16:47:12.328058 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-bf0e-1833-920f-27e45131b576, command-id=01f08fef-bf2e-1617-a4c8-30e884d3f836) - Closing
[0m16:47:12.328058 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:12.328058 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_sales: Close
[0m16:47:12.328058 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-bf0e-1833-920f-27e45131b576) - Closing
[0m16:47:12.647060 [info ] [Thread-8 (]: 5 of 13 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.39s]
[0m16:47:12.647060 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_sales
[0m16:47:12.647060 [debug] [Thread-8 (]: Began running node model.dbt_eTl.bronze_store
[0m16:47:12.647060 [info ] [Thread-8 (]: 6 of 13 START sql table model default.bronze_store ............................. [RUN]
[0m16:47:12.647060 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m16:47:12.647060 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m16:47:12.647060 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.bronze_store
[0m16:47:12.660999 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m16:47:12.664093 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.bronze_store
[0m16:47:12.671156 [debug] [Thread-8 (]: MATERIALIZING TABLE
[0m16:47:12.673502 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m16:47:12.675959 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m16:47:12.677137 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m16:47:12.677666 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:13.439184 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c06d-1dd3-8726-cfbc1d2e547f) - Created
[0m16:47:19.710619 [debug] [Thread-8 (]: SQL status: OK in 7.030 seconds
[0m16:47:19.710619 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-c06d-1dd3-8726-cfbc1d2e547f, command-id=01f08fef-c08f-102d-9277-912024a584e9) - Closing
[0m16:47:19.947774 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:19.947774 [debug] [Thread-8 (]: On model.dbt_eTl.bronze_store: Close
[0m16:47:19.947774 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c06d-1dd3-8726-cfbc1d2e547f) - Closing
[0m16:47:20.169176 [info ] [Thread-8 (]: 6 of 13 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 7.52s]
[0m16:47:20.169176 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.bronze_store
[0m16:47:20.169176 [debug] [Thread-8 (]: Began running node model.dbt_eTl.source_gold_items
[0m16:47:20.169176 [info ] [Thread-8 (]: 7 of 13 START sql view model default.source_gold_items ......................... [RUN]
[0m16:47:20.169176 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.source_gold_items) - Creating connection
[0m16:47:20.169176 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.source_gold_items'
[0m16:47:20.169176 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.source_gold_items
[0m16:47:20.185712 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.source_gold_items"
[0m16:47:20.188241 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.source_gold_items
[0m16:47:20.191234 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m16:47:20.191234 [debug] [Thread-8 (]: Creating view `dbt-project`.`default`.`source_gold_items`
[0m16:47:20.191234 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.source_gold_items"
[0m16:47:20.191234 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.source_gold_items"
[0m16:47:20.191234 [debug] [Thread-8 (]: On model.dbt_eTl.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.source_gold_items"} */

  
  
  create or replace view `dbt-project`.`default`.`source_gold_items`
  
  as (
    With dedup_query AS (
SELECT
*,
row_number() over (partition by id order by updatedate) as dedup_flag
FROM
`dbt-project`.`source`.`item`
)
SELECT
id, name, category,updatedate
FROM dedup_query
WHERE dedup_flag = 1
  )

[0m16:47:20.191234 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:20.965390 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c4e7-1fa3-a516-6f8371b77e75) - Created
[0m16:47:21.927107 [debug] [Thread-8 (]: SQL status: OK in 1.740 seconds
[0m16:47:21.929462 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-c4e7-1fa3-a516-6f8371b77e75, command-id=01f08fef-c50b-1a8c-aa36-f4dcd9c4bbd2) - Closing
[0m16:47:21.929462 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:21.929462 [debug] [Thread-8 (]: On model.dbt_eTl.source_gold_items: Close
[0m16:47:21.929462 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c4e7-1fa3-a516-6f8371b77e75) - Closing
[0m16:47:22.155020 [info ] [Thread-8 (]: 7 of 13 OK created sql view model default.source_gold_items .................... [[32mOK[0m in 1.99s]
[0m16:47:22.156769 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.source_gold_items
[0m16:47:22.157375 [debug] [Thread-8 (]: Began running node seed.dbt_eTl.lookup
[0m16:47:22.157375 [info ] [Thread-8 (]: 8 of 13 START seed file bronze.lookup .......................................... [RUN]
[0m16:47:22.157375 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m16:47:22.157375 [debug] [Thread-8 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m16:47:22.157375 [debug] [Thread-8 (]: Began compiling node seed.dbt_eTl.lookup
[0m16:47:22.157375 [debug] [Thread-8 (]: Began executing node seed.dbt_eTl.lookup
[0m16:47:22.204766 [debug] [Thread-8 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:47:22.204766 [debug] [Thread-8 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m16:47:22.204766 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:23.270952 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c64a-1bb8-93d4-a42cb227707d) - Created
[0m16:47:25.122299 [debug] [Thread-8 (]: SQL status: OK in 2.920 seconds
[0m16:47:25.122299 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-c64a-1bb8-93d4-a42cb227707d, command-id=01f08fef-c66a-1de5-adee-d7c677a7576d) - Closing
[0m16:47:25.144681 [debug] [Thread-8 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:47:25.144681 [debug] [Thread-8 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m16:47:26.926943 [debug] [Thread-8 (]: SQL status: OK in 1.780 seconds
[0m16:47:26.926943 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-c64a-1bb8-93d4-a42cb227707d, command-id=01f08fef-c789-13f0-837f-b6b8e517cb97) - Closing
[0m16:47:26.926943 [debug] [Thread-8 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m16:47:26.942877 [debug] [Thread-8 (]: On seed.dbt_eTl.lookup: Close
[0m16:47:26.942877 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c64a-1bb8-93d4-a42cb227707d) - Closing
[0m16:47:27.161084 [info ] [Thread-8 (]: 8 of 13 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 5.00s]
[0m16:47:27.161084 [debug] [Thread-8 (]: Finished running node seed.dbt_eTl.lookup
[0m16:47:27.173320 [debug] [Thread-8 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:47:27.173320 [info ] [Thread-8 (]: 9 of 13 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m16:47:27.176112 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:47:27.176642 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:47:27.176642 [debug] [Thread-8 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:47:27.204013 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:47:27.207214 [debug] [Thread-8 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:47:27.243897 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:47:27.247677 [debug] [Thread-8 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:47:27.249684 [debug] [Thread-8 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:47:27.249684 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:28.067201 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c926-1c58-b4a9-5c54713d6a1b) - Created
[0m16:47:29.289608 [debug] [Thread-8 (]: SQL status: OK in 2.040 seconds
[0m16:47:29.292629 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-c926-1c58-b4a9-5c54713d6a1b, command-id=01f08fef-c946-129d-81c5-663f876f6678) - Closing
[0m16:47:29.298892 [debug] [Thread-8 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:47:29.301923 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-c926-1c58-b4a9-5c54713d6a1b) - Closing
[0m16:47:29.514434 [info ] [Thread-8 (]: 9 of 13 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 2.34s]
[0m16:47:29.514434 [debug] [Thread-8 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:47:29.514434 [debug] [Thread-8 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:47:29.514434 [info ] [Thread-8 (]: 10 of 13 START test unique_bronze_customer_customer_sk ......................... [RUN]
[0m16:47:29.514434 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:47:29.530974 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:47:29.530974 [debug] [Thread-8 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:47:29.530974 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:47:29.530974 [debug] [Thread-8 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:47:29.547194 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:47:29.548893 [debug] [Thread-8 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:47:29.550210 [debug] [Thread-8 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:47:29.550898 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:30.339027 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-ca7f-1641-b2bb-b252e0e30919) - Created
[0m16:47:31.519002 [debug] [Thread-8 (]: SQL status: OK in 1.970 seconds
[0m16:47:31.519002 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-ca7f-1641-b2bb-b252e0e30919, command-id=01f08fef-caa1-1315-a45c-e58558c9ade8) - Closing
[0m16:47:31.519002 [debug] [Thread-8 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:47:31.519002 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-ca7f-1641-b2bb-b252e0e30919) - Closing
[0m16:47:31.749959 [info ] [Thread-8 (]: 10 of 13 PASS unique_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.24s]
[0m16:47:31.749959 [debug] [Thread-8 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:47:31.749959 [debug] [Thread-8 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:47:31.749959 [info ] [Thread-8 (]: 11 of 13 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:47:31.749959 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:47:31.749959 [debug] [Thread-8 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:47:31.749959 [debug] [Thread-8 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:47:31.757011 [debug] [Thread-8 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:47:31.772658 [debug] [Thread-8 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:47:31.777176 [debug] [Thread-8 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:47:31.779162 [debug] [Thread-8 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:47:31.779162 [debug] [Thread-8 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:47:31.780365 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:32.560117 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-cbd4-196f-b0d7-e315be63dc20) - Created
[0m16:47:33.491167 [debug] [Thread-8 (]: SQL status: OK in 1.710 seconds
[0m16:47:33.495878 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-cbd4-196f-b0d7-e315be63dc20, command-id=01f08fef-cbf4-171a-86be-0d3292883cfb) - Closing
[0m16:47:33.496851 [debug] [Thread-8 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:47:33.496851 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-cbd4-196f-b0d7-e315be63dc20) - Closing
[0m16:47:33.767318 [info ] [Thread-8 (]: 11 of 13 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 2.02s]
[0m16:47:33.771266 [debug] [Thread-8 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:47:33.771868 [debug] [Thread-8 (]: Began running node snapshot.dbt_eTl.gold_items
[0m16:47:33.773696 [info ] [Thread-8 (]: 12 of 13 START snapshot gold.gold_items ........................................ [RUN]
[0m16:47:33.774248 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_eTl.gold_items) - Creating connection
[0m16:47:33.776255 [debug] [Thread-8 (]: Acquiring new databricks connection 'snapshot.dbt_eTl.gold_items'
[0m16:47:33.777469 [debug] [Thread-8 (]: Began compiling node snapshot.dbt_eTl.gold_items
[0m16:47:33.787369 [debug] [Thread-8 (]: Began executing node snapshot.dbt_eTl.gold_items
[0m16:47:33.916729 [debug] [Thread-8 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:47:33.917728 [debug] [Thread-8 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updated_at as string ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        
  
  coalesce(nullif(updated_at, updated_at), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt-project`.`default`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m16:47:33.918728 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:34.798965 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-cd27-1011-929c-865b12cfc719) - Created
[0m16:47:35.450944 [debug] [Thread-8 (]: Databricks adapter: Exception while trying to execute query
/* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updated_at as string ), '')
        ) as dbt_scd_id,
        updated_at as dbt_updated_at,
        updated_at as dbt_valid_from,
        
  
  coalesce(nullif(updated_at, updated_at), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt-project`.`default`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33
Error properties: diagnostic-info=org.apache.hive.service.cli.HiveSQLException: Error running query: [UNRESOLVED_COLUMN.WITH_SUGGESTION] org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33
	at org.apache.spark.sql.hive.thriftserver.HiveThriftServerErrors$.runningQueryError(HiveThriftServerErrors.scala:49)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:1037)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.unity.UCSEphemeralState$Handle.runWith(UCSEphemeralState.scala:51)
	at com.databricks.unity.HandleImpl.runWith(UCSHandle.scala:104)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:786)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$5(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at org.apache.spark.sql.execution.SQLExecution$.withRootExecution(SQLExecution.scala:771)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:572)
	at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.scala:18)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.DatabricksTracingHelper.withAttributionContext(DatabricksSparkTracingHelper.scala:65)
	at com.databricks.spark.util.DatabricksTracingHelper.withSpanFromRequest(DatabricksSparkTracingHelper.scala:92)
	at com.databricks.spark.util.DBRTracing$.withSpanFromRequest(DBRTracing.scala:43)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$15(ThriftLocalProperties.scala:238)
	at com.databricks.logging.AttributionContextTracing.$anonfun$withAttributionContext$1(AttributionContextTracing.scala:49)
	at com.databricks.logging.AttributionContext$.$anonfun$withValue$1(AttributionContext.scala:291)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:59)
	at com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:287)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext(AttributionContextTracing.scala:47)
	at com.databricks.logging.AttributionContextTracing.withAttributionContext$(AttributionContextTracing.scala:44)
	at com.databricks.spark.util.PublicDBLogging.withAttributionContext(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags(AttributionContextTracing.scala:96)
	at com.databricks.logging.AttributionContextTracing.withAttributionTags$(AttributionContextTracing.scala:77)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags(DatabricksSparkUsageLogger.scala:30)
	at com.databricks.spark.util.PublicDBLogging.withAttributionTags0(DatabricksSparkUsageLogger.scala:124)
	at com.databricks.spark.util.DatabricksSparkUsageLogger.withAttributionTags(DatabricksSparkUsageLogger.scala:232)
	at com.databricks.spark.util.UsageLogging.$anonfun$withAttributionTags$1(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:780)
	at com.databricks.spark.util.UsageLogging$.withAttributionTags(UsageLogger.scala:789)
	at com.databricks.spark.util.UsageLogging.withAttributionTags(UsageLogger.scala:668)
	at com.databricks.spark.util.UsageLogging.withAttributionTags$(UsageLogger.scala:666)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withAttributionTags(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.$anonfun$withLocalProperties$12(ThriftLocalProperties.scala:233)
	at com.databricks.spark.util.IdentityClaim$.withClaim(IdentityClaim.scala:48)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties(ThriftLocalProperties.scala:229)
	at org.apache.spark.sql.hive.thriftserver.ThriftLocalProperties.withLocalProperties$(ThriftLocalProperties.scala:89)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:75)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:549)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:535)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:712)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:439)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1953)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:585)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:539)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1136)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:635)
	at java.base/java.lang.Thread.run(Thread.java:840)
Caused by: org.apache.spark.sql.catalyst.ExtendedAnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33
	at org.apache.spark.sql.catalyst.ExtendedAnalysisException.copyPlan(ExtendedAnalysisException.scala:91)
	at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.$anonfun$execute$1(SparkExecuteStatementOperation.scala:998)
	... 53 more
, operation-id=01f08fef-cd48-1b49-8e73-7e4fa09ab6dc
[0m16:47:35.452953 [debug] [Thread-8 (]: On snapshot.dbt_eTl.gold_items: Close
[0m16:47:35.453960 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-cd27-1011-929c-865b12cfc719) - Closing
[0m16:47:36.168253 [debug] [Thread-8 (]: Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33
[0m16:47:36.168253 [error] [Thread-8 (]: 12 of 13 ERROR snapshotting gold.gold_items .................................... [[31mERROR[0m in 2.39s]
[0m16:47:36.172695 [debug] [Thread-8 (]: Finished running node snapshot.dbt_eTl.gold_items
[0m16:47:36.172695 [debug] [Thread-8 (]: Began running node model.dbt_eTl.silver_sales
[0m16:47:36.172695 [debug] [Thread-11 ]: Marking all children of 'snapshot.dbt_eTl.gold_items' to be skipped because of status 'error'.  Reason: Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33.
[0m16:47:36.175395 [info ] [Thread-8 (]: 13 of 13 START sql view model default.silver_sales ............................. [RUN]
[0m16:47:36.177403 [debug] [Thread-8 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m16:47:36.178409 [debug] [Thread-8 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m16:47:36.179419 [debug] [Thread-8 (]: Began compiling node model.dbt_eTl.silver_sales
[0m16:47:36.189421 [debug] [Thread-8 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m16:47:36.217392 [debug] [Thread-8 (]: Began executing node model.dbt_eTl.silver_sales
[0m16:47:36.223420 [debug] [Thread-8 (]: MATERIALIZING VIEW
[0m16:47:36.238052 [debug] [Thread-8 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m16:47:36.245061 [debug] [Thread-8 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m16:47:36.280106 [debug] [Thread-8 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m16:47:36.281103 [debug] [Thread-8 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m16:47:36.282103 [debug] [Thread-8 (]: Opening a new connection, currently in state init
[0m16:47:37.153767 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-ce91-1add-b0b6-c6da62f5bf51) - Created
[0m16:47:38.247212 [debug] [Thread-8 (]: SQL status: OK in 1.970 seconds
[0m16:47:38.247212 [debug] [Thread-8 (]: Databricks adapter: Cursor(session-id=01f08fef-ce91-1add-b0b6-c6da62f5bf51, command-id=01f08fef-ceb3-116d-a3c4-805d4addd0a0) - Closing
[0m16:47:38.247212 [debug] [Thread-8 (]: Applying tags to relation None
[0m16:47:38.247212 [debug] [Thread-8 (]: On model.dbt_eTl.silver_sales: Close
[0m16:47:38.247212 [debug] [Thread-8 (]: Databricks adapter: Connection(session-id=01f08fef-ce91-1add-b0b6-c6da62f5bf51) - Closing
[0m16:47:38.466198 [info ] [Thread-8 (]: 13 of 13 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 2.29s]
[0m16:47:38.480420 [debug] [Thread-8 (]: Finished running node model.dbt_eTl.silver_sales
[0m16:47:38.483179 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:47:38.483179 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:47:38.484284 [info ] [MainThread]: 
[0m16:47:38.484284 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 3 table models, 3 data tests, 5 view models in 0 hours 1 minutes and 5.01 seconds (65.01s).
[0m16:47:38.490125 [debug] [MainThread]: Command end result
[0m16:47:38.559192 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:47:38.566854 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:47:38.575685 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:47:38.576684 [info ] [MainThread]: 
[0m16:47:38.577686 [info ] [MainThread]: [31mCompleted with 1 error, 0 partial successes, and 0 warnings:[0m
[0m16:47:38.577686 [info ] [MainThread]: 
[0m16:47:38.579213 [error] [MainThread]: [31mFailure in snapshot gold_items (snapshots\gold_items.yml)[0m
[0m16:47:38.580288 [error] [MainThread]:   Database Error in snapshot gold_items (snapshots\gold_items.yml)
  [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column, variable, or function parameter with name `updated_at` cannot be resolved. Did you mean one of the following? [`updatedate`, `category`, `name`, `id`]. SQLSTATE: 42703; line 8 pos 33
[0m16:47:38.580288 [info ] [MainThread]: 
[0m16:47:38.581587 [info ] [MainThread]: Done. PASS=12 WARN=0 ERROR=1 SKIP=0 NO-OP=0 TOTAL=13
[0m16:47:38.584052 [debug] [MainThread]: Command `dbt build` failed at 16:47:38.582943 after 71.72 seconds
[0m16:47:38.584052 [debug] [MainThread]: Flushing usage events
[0m16:48:20.780210 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:48:21.076749 | ece9ef81-5d88-4544-bd95-803cb769a568 ==============================
[0m16:48:21.076749 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:48:21.078833 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'printer_width': '80', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m16:48:24.233526 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:48:24.235533 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:48:24.237542 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:48:28.617258 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:48:30.179753 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:48:31.027542 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m16:48:31.029247 [debug] [MainThread]: Partial parsing: updated file: dbt_eTl://snapshots\gold_items.yml
[0m16:48:32.920126 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:48:32.927589 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:48:33.020124 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:48:33.029416 [info ] [MainThread]: 
[0m16:48:33.030428 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:48:33.031425 [info ] [MainThread]: 
[0m16:48:33.032423 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:48:33.033426 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:48:33.045267 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:48:33.048270 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:48:33.048270 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:48:33.049271 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:48:33.049271 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:34.257212 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f096-1a48-8d75-80b1f50deac4) - Created
[0m16:48:34.706499 [debug] [ThreadPool]: SQL status: OK in 1.660 seconds
[0m16:48:34.719888 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f096-1a48-8d75-80b1f50deac4, command-id=01f08fef-f0ba-17c1-b3e0-287936f6238b) - Closing
[0m16:48:34.722891 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:48:34.724889 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f096-1a48-8d75-80b1f50deac4) - Closing
[0m16:48:34.945307 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:48:34.947317 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:48:34.949315 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:48:34.951314 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:48:34.953317 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:35.850388 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f18c-1f0c-aee5-642964097763) - Created
[0m16:48:36.229429 [debug] [ThreadPool]: SQL status: OK in 1.280 seconds
[0m16:48:36.233030 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f18c-1f0c-aee5-642964097763, command-id=01f08fef-f1ac-1fc1-9fa7-8eefbdb59fd1) - Closing
[0m16:48:36.234027 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:48:36.235030 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f18c-1f0c-aee5-642964097763) - Closing
[0m16:48:36.478665 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:48:36.479664 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:48:36.480663 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:48:36.480663 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:48:36.481663 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:37.407375 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f279-1e42-b512-2254b55cc611) - Created
[0m16:48:37.778761 [debug] [ThreadPool]: SQL status: OK in 1.300 seconds
[0m16:48:37.784650 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f279-1e42-b512-2254b55cc611, command-id=01f08fef-f29a-17c8-a72e-8ae3b0733af3) - Closing
[0m16:48:37.786666 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:48:37.788677 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f279-1e42-b512-2254b55cc611) - Closing
[0m16:48:38.025876 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m16:48:38.027389 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m16:48:38.076145 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m16:48:38.077549 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m16:48:38.078550 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:38.984328 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f369-1cb5-9a4a-55fa3b99ea9c) - Created
[0m16:48:39.460828 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m16:48:39.477647 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f369-1cb5-9a4a-55fa3b99ea9c, command-id=01f08fef-f38c-142c-98d1-6d7441ae19b5) - Closing
[0m16:48:39.478660 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m16:48:39.480737 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f369-1cb5-9a4a-55fa3b99ea9c) - Closing
[0m16:48:39.726860 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:48:39.729778 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:48:39.733795 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:48:39.735803 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:48:39.735803 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:40.572163 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f45d-12c3-9f2d-079c7dd55f55) - Created
[0m16:48:41.142127 [debug] [ThreadPool]: SQL status: OK in 1.410 seconds
[0m16:48:41.148994 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f45d-12c3-9f2d-079c7dd55f55, command-id=01f08fef-f480-1613-93cb-b355fb35e095) - Closing
[0m16:48:41.151002 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:48:41.152004 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f45d-12c3-9f2d-079c7dd55f55) - Closing
[0m16:48:41.371157 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:48:41.374156 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:48:41.390974 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:48:41.391974 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:48:41.392974 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:48:42.240651 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f55c-15d6-9920-ec0fc5dfaf28) - Created
[0m16:48:42.896397 [debug] [ThreadPool]: SQL status: OK in 1.500 seconds
[0m16:48:42.902156 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08fef-f55c-15d6-9920-ec0fc5dfaf28, command-id=01f08fef-f582-1452-aaa1-22013d677d43) - Closing
[0m16:48:42.904166 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:48:42.904166 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08fef-f55c-15d6-9920-ec0fc5dfaf28) - Closing
[0m16:48:43.139165 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_customer
[0m16:48:43.141167 [info ] [Thread-7 (]: 1 of 13 START sql table model default.bronze_customer .......................... [RUN]
[0m16:48:43.143169 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m16:48:43.143903 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m16:48:43.145040 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m16:48:43.171946 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m16:48:43.175945 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_customer
[0m16:48:43.246462 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:48:43.246462 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:48:43.504932 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m16:48:43.514045 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m16:48:43.518042 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m16:48:43.522553 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:44.413000 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-f6a6-1795-8357-4ca517de8b12) - Created
[0m16:48:46.726873 [debug] [Thread-7 (]: SQL status: OK in 3.200 seconds
[0m16:48:46.729592 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-f6a6-1795-8357-4ca517de8b12, command-id=01f08fef-f6c7-12d2-a613-bc40995ba3d8) - Closing
[0m16:48:46.757449 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:46.794694 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: Close
[0m16:48:46.796701 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-f6a6-1795-8357-4ca517de8b12) - Closing
[0m16:48:47.015792 [info ] [Thread-7 (]: 1 of 13 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 3.87s]
[0m16:48:47.018797 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_customer
[0m16:48:47.020809 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_date
[0m16:48:47.021707 [info ] [Thread-7 (]: 2 of 13 START sql view model bronze.bronze_date ................................ [RUN]
[0m16:48:47.023756 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m16:48:47.025712 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m16:48:47.027311 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_date
[0m16:48:47.037916 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m16:48:47.039927 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_date
[0m16:48:47.099946 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:48:47.139161 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m16:48:47.140088 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m16:48:47.142234 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m16:48:47.143235 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m16:48:47.144690 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:47.937049 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-f8c3-1657-a4ee-74b3ca163030) - Created
[0m16:48:48.968883 [debug] [Thread-7 (]: SQL status: OK in 1.820 seconds
[0m16:48:48.972907 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-f8c3-1657-a4ee-74b3ca163030, command-id=01f08fef-f8e3-13d6-91c4-75e8636e41ae) - Closing
[0m16:48:48.976960 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:48.980072 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: Close
[0m16:48:48.981070 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-f8c3-1657-a4ee-74b3ca163030) - Closing
[0m16:48:49.222054 [info ] [Thread-7 (]: 2 of 13 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.20s]
[0m16:48:49.225058 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_date
[0m16:48:49.226055 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m16:48:49.228228 [info ] [Thread-7 (]: 3 of 13 START sql table model default.bronze_dim_product ....................... [RUN]
[0m16:48:49.230324 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m16:48:49.230324 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m16:48:49.230324 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m16:48:49.238793 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m16:48:49.244671 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m16:48:49.252882 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:48:49.260885 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m16:48:49.265067 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m16:48:49.266066 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m16:48:49.267479 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:50.104803 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fa0a-1af3-a500-ee99622d3bad) - Created
[0m16:48:52.036073 [debug] [Thread-7 (]: SQL status: OK in 2.770 seconds
[0m16:48:52.047541 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-fa0a-1af3-a500-ee99622d3bad, command-id=01f08fef-fa2c-10e8-886a-70d25f15dc36) - Closing
[0m16:48:52.047541 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:52.047541 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m16:48:52.051763 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fa0a-1af3-a500-ee99622d3bad) - Closing
[0m16:48:52.273149 [info ] [Thread-7 (]: 3 of 13 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 3.04s]
[0m16:48:52.273149 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m16:48:52.273149 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_returns
[0m16:48:52.273149 [info ] [Thread-7 (]: 4 of 13 START sql view model default.bronze_returns ............................ [RUN]
[0m16:48:52.273149 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m16:48:52.273149 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m16:48:52.273149 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m16:48:52.297614 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m16:48:52.299643 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_returns
[0m16:48:52.310784 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:48:52.314300 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m16:48:52.315772 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m16:48:52.315772 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m16:48:52.315772 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m16:48:52.315772 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:53.135640 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fbdc-14a3-bed8-3a3b5454e4ce) - Created
[0m16:48:53.850734 [debug] [Thread-7 (]: SQL status: OK in 1.530 seconds
[0m16:48:53.850734 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-fbdc-14a3-bed8-3a3b5454e4ce, command-id=01f08fef-fbfc-140f-9354-af01fd862228) - Closing
[0m16:48:53.866898 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:53.866898 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: Close
[0m16:48:53.866898 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fbdc-14a3-bed8-3a3b5454e4ce) - Closing
[0m16:48:54.085386 [info ] [Thread-7 (]: 4 of 13 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 1.81s]
[0m16:48:54.086963 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_returns
[0m16:48:54.087480 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_sales
[0m16:48:54.088527 [info ] [Thread-7 (]: 5 of 13 START sql view model bronze.bronze_sales ............................... [RUN]
[0m16:48:54.089683 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m16:48:54.090246 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m16:48:54.090777 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m16:48:54.099588 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m16:48:54.101335 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_sales
[0m16:48:54.105234 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:48:54.107880 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m16:48:54.110709 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m16:48:54.112421 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m16:48:54.113602 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m16:48:54.114105 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:55.143233 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fd0a-131e-babe-24ff33724f0c) - Created
[0m16:48:55.872021 [debug] [Thread-7 (]: SQL status: OK in 1.760 seconds
[0m16:48:55.872021 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-fd0a-131e-babe-24ff33724f0c, command-id=01f08fef-fd2d-1c07-9ca9-3a42d6e4f60e) - Closing
[0m16:48:55.872021 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:55.872021 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: Close
[0m16:48:55.872021 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fd0a-131e-babe-24ff33724f0c) - Closing
[0m16:48:56.125038 [info ] [Thread-7 (]: 5 of 13 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.04s]
[0m16:48:56.125038 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_sales
[0m16:48:56.125038 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_store
[0m16:48:56.125038 [info ] [Thread-7 (]: 6 of 13 START sql table model default.bronze_store ............................. [RUN]
[0m16:48:56.125038 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m16:48:56.125038 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m16:48:56.125038 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_store
[0m16:48:56.141016 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m16:48:56.141016 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_store
[0m16:48:56.160272 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:48:56.163285 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m16:48:56.166283 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m16:48:56.169281 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m16:48:56.170244 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:48:56.977903 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fe23-1a53-a904-ae517f646086) - Created
[0m16:48:59.031966 [debug] [Thread-7 (]: SQL status: OK in 2.860 seconds
[0m16:48:59.031966 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08fef-fe23-1a53-a904-ae517f646086, command-id=01f08fef-fe46-16cf-88c0-475cec0a9b47) - Closing
[0m16:48:59.044041 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:48:59.048130 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: Close
[0m16:48:59.048914 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08fef-fe23-1a53-a904-ae517f646086) - Closing
[0m16:48:59.269364 [info ] [Thread-7 (]: 6 of 13 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 3.14s]
[0m16:48:59.269364 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_store
[0m16:48:59.269364 [debug] [Thread-7 (]: Began running node model.dbt_eTl.source_gold_items
[0m16:48:59.269364 [info ] [Thread-7 (]: 7 of 13 START sql view model default.source_gold_items ......................... [RUN]
[0m16:48:59.285382 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.source_gold_items) - Creating connection
[0m16:48:59.285382 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.source_gold_items'
[0m16:48:59.285382 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.source_gold_items
[0m16:48:59.285382 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.source_gold_items"
[0m16:48:59.285382 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.source_gold_items
[0m16:48:59.301025 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:48:59.301025 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`source_gold_items`
[0m16:48:59.301025 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.source_gold_items"
[0m16:48:59.301025 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.source_gold_items"
[0m16:48:59.301025 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.source_gold_items"} */

  
  
  create or replace view `dbt-project`.`default`.`source_gold_items`
  
  as (
    With dedup_query AS (
SELECT
*,
row_number() over (partition by id order by updatedate) as dedup_flag
FROM
`dbt-project`.`source`.`item`
)
SELECT
id, name, category,updatedate
FROM dedup_query
WHERE dedup_flag = 1
  )

[0m16:48:59.301025 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:00.427294 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0032-17a6-88f0-6653f4dbef37) - Created
[0m16:49:01.537026 [debug] [Thread-7 (]: SQL status: OK in 2.240 seconds
[0m16:49:01.539030 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-0032-17a6-88f0-6653f4dbef37, command-id=01f08ff0-0055-1781-bf69-527be0f80dee) - Closing
[0m16:49:01.539030 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:49:01.541035 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: Close
[0m16:49:01.541035 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0032-17a6-88f0-6653f4dbef37) - Closing
[0m16:49:01.772777 [info ] [Thread-7 (]: 7 of 13 OK created sql view model default.source_gold_items .................... [[32mOK[0m in 2.49s]
[0m16:49:01.772777 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.source_gold_items
[0m16:49:01.772777 [debug] [Thread-7 (]: Began running node seed.dbt_eTl.lookup
[0m16:49:01.772777 [info ] [Thread-7 (]: 8 of 13 START seed file bronze.lookup .......................................... [RUN]
[0m16:49:01.772777 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m16:49:01.772777 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m16:49:01.772777 [debug] [Thread-7 (]: Began compiling node seed.dbt_eTl.lookup
[0m16:49:01.788430 [debug] [Thread-7 (]: Began executing node seed.dbt_eTl.lookup
[0m16:49:01.878259 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:49:01.884292 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m16:49:01.884292 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:02.949769 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-01af-1d91-977e-5e3ad75c1313) - Created
[0m16:49:04.403541 [debug] [Thread-7 (]: SQL status: OK in 2.520 seconds
[0m16:49:04.405550 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-01af-1d91-977e-5e3ad75c1313, command-id=01f08ff0-01d3-1f7c-b700-1b72b3aac648) - Closing
[0m16:49:04.437188 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:49:04.439198 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m16:49:05.927919 [debug] [Thread-7 (]: SQL status: OK in 1.490 seconds
[0m16:49:05.927919 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-01af-1d91-977e-5e3ad75c1313, command-id=01f08ff0-02ba-1655-9ace-4fc6fd9b2ccb) - Closing
[0m16:49:05.927919 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m16:49:05.927919 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: Close
[0m16:49:05.927919 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-01af-1d91-977e-5e3ad75c1313) - Closing
[0m16:49:06.164614 [info ] [Thread-7 (]: 8 of 13 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.39s]
[0m16:49:06.164614 [debug] [Thread-7 (]: Finished running node seed.dbt_eTl.lookup
[0m16:49:06.164614 [debug] [Thread-7 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:49:06.164614 [info ] [Thread-7 (]: 9 of 13 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m16:49:06.164614 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:49:06.164614 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:49:06.164614 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:49:06.203496 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:49:06.209870 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:49:06.243974 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:49:06.243974 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:49:06.243974 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:49:06.243974 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:07.027451 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0424-1cfc-969d-4f73e5053533) - Created
[0m16:49:07.845208 [debug] [Thread-7 (]: SQL status: OK in 1.600 seconds
[0m16:49:07.845208 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-0424-1cfc-969d-4f73e5053533, command-id=01f08ff0-0444-12d3-b3f7-af84bb1e66f3) - Closing
[0m16:49:07.861104 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:49:07.861104 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0424-1cfc-969d-4f73e5053533) - Closing
[0m16:49:08.084513 [info ] [Thread-7 (]: 9 of 13 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 1.92s]
[0m16:49:08.084513 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:49:08.084513 [debug] [Thread-7 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:49:08.084513 [info ] [Thread-7 (]: 10 of 13 START test unique_bronze_customer_customer_sk ......................... [RUN]
[0m16:49:08.084513 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:49:08.084513 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:49:08.084513 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:49:08.115880 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:49:08.121159 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:49:08.129774 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:49:08.131690 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:49:08.133175 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:49:08.133175 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:09.182250 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-056d-1564-afcd-60453853a31d) - Created
[0m16:49:10.086735 [debug] [Thread-7 (]: SQL status: OK in 1.950 seconds
[0m16:49:10.101446 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-056d-1564-afcd-60453853a31d, command-id=01f08ff0-058c-16fa-956d-994d011c4699) - Closing
[0m16:49:10.101446 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:49:10.101446 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-056d-1564-afcd-60453853a31d) - Closing
[0m16:49:10.323787 [info ] [Thread-7 (]: 10 of 13 PASS unique_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.24s]
[0m16:49:10.329129 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:49:10.329129 [debug] [Thread-7 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:49:10.329129 [info ] [Thread-7 (]: 11 of 13 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:49:10.329129 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:49:10.329129 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:49:10.329129 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:49:10.371516 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:49:10.379783 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:49:10.389074 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:49:10.391082 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:49:10.391082 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:49:10.393090 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:11.210577 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-06a1-18ec-a2f0-7f5345224cf7) - Created
[0m16:49:11.998914 [debug] [Thread-7 (]: SQL status: OK in 1.610 seconds
[0m16:49:12.014631 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-06a1-18ec-a2f0-7f5345224cf7, command-id=01f08ff0-06c2-16cb-bf3d-d59d7e327db8) - Closing
[0m16:49:12.014631 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:49:12.014631 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-06a1-18ec-a2f0-7f5345224cf7) - Closing
[0m16:49:12.301164 [info ] [Thread-7 (]: 11 of 13 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 1.97s]
[0m16:49:12.301164 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:49:12.301164 [debug] [Thread-7 (]: Began running node snapshot.dbt_eTl.gold_items
[0m16:49:12.301164 [info ] [Thread-7 (]: 12 of 13 START snapshot gold.gold_items ........................................ [RUN]
[0m16:49:12.316962 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_eTl.gold_items) - Creating connection
[0m16:49:12.316962 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_eTl.gold_items'
[0m16:49:12.316962 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_eTl.gold_items
[0m16:49:12.316962 [debug] [Thread-7 (]: Began executing node snapshot.dbt_eTl.gold_items
[0m16:49:12.432689 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:49:12.432689 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id,
        updatedate as dbt_updated_at,
        updatedate as dbt_valid_from,
        
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt-project`.`default`.`source_gold_items`
    ) sbq



    ) as __dbt_sbq
    where false
    limit 0

[0m16:49:12.434696 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:13.243559 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-07d2-1f04-8634-4dcda1f448eb) - Created
[0m16:49:13.877971 [debug] [Thread-7 (]: SQL status: OK in 1.440 seconds
[0m16:49:13.889957 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:49:13.890572 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m16:49:13.891750 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-07d2-1f04-8634-4dcda1f448eb, command-id=01f08ff0-07f8-1557-ade2-234fdb457eef) - Closing
[0m16:49:14.154456 [debug] [Thread-7 (]: SQL status: OK in 0.260 seconds
[0m16:49:14.169402 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_eTl.gold_items"
[0m16:49:14.170474 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:49:14.170474 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

      
  
    
        create or replace table `dbt-project`.`gold`.`gold_items`
      
      
  using delta
      
      
      
      
      
      
      
      as
      
    

    select *,
        md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id,
        updatedate as dbt_updated_at,
        updatedate as dbt_valid_from,
        
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
from (
        select * from `dbt-project`.`default`.`source_gold_items`
    ) sbq



  
  
[0m16:49:14.170474 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-07d2-1f04-8634-4dcda1f448eb, command-id=01f08ff0-0859-1e86-ae37-a60dd439ac0c) - Closing
[0m16:49:18.164106 [debug] [Thread-7 (]: SQL status: OK in 3.990 seconds
[0m16:49:18.168145 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-07d2-1f04-8634-4dcda1f448eb, command-id=01f08ff0-0884-1e57-9ac9-254f8a52c427) - Closing
[0m16:49:18.177124 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: Close
[0m16:49:18.178671 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-07d2-1f04-8634-4dcda1f448eb) - Closing
[0m16:49:18.415755 [info ] [Thread-7 (]: 12 of 13 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 6.10s]
[0m16:49:18.415755 [debug] [Thread-7 (]: Finished running node snapshot.dbt_eTl.gold_items
[0m16:49:18.415755 [debug] [Thread-7 (]: Began running node model.dbt_eTl.silver_sales
[0m16:49:18.415755 [info ] [Thread-7 (]: 13 of 13 START sql view model default.silver_sales ............................. [RUN]
[0m16:49:18.415755 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m16:49:18.415755 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m16:49:18.415755 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.silver_sales
[0m16:49:18.431851 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m16:49:18.431851 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.silver_sales
[0m16:49:18.450007 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:49:18.450007 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m16:49:18.450007 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m16:49:18.450007 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m16:49:18.450007 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m16:49:18.450007 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:49:19.261257 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0b6d-1938-b5ad-e02a50e56978) - Created
[0m16:49:20.320557 [debug] [Thread-7 (]: SQL status: OK in 1.870 seconds
[0m16:49:20.320557 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff0-0b6d-1938-b5ad-e02a50e56978, command-id=01f08ff0-0b8e-1363-a081-b6f2efc1af06) - Closing
[0m16:49:20.335443 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:49:20.335443 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: Close
[0m16:49:20.335443 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff0-0b6d-1938-b5ad-e02a50e56978) - Closing
[0m16:49:20.555330 [info ] [Thread-7 (]: 13 of 13 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 2.14s]
[0m16:49:20.555330 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.silver_sales
[0m16:49:20.571229 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:49:20.571229 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:49:20.571229 [info ] [MainThread]: 
[0m16:49:20.571229 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 3 table models, 3 data tests, 5 view models in 0 hours 0 minutes and 47.54 seconds (47.54s).
[0m16:49:20.582775 [debug] [MainThread]: Command end result
[0m16:49:20.650768 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:49:20.654783 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:49:20.660242 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:49:20.660242 [info ] [MainThread]: 
[0m16:49:20.660242 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:49:20.660242 [info ] [MainThread]: 
[0m16:49:20.660242 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=13
[0m16:49:20.660242 [debug] [MainThread]: Command `dbt build` succeeded at 16:49:20.660242 after 59.99 seconds
[0m16:49:20.660242 [debug] [MainThread]: Flushing usage events
[0m16:50:32.822869 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:50:33.016815 | f9e0bd18-a5ff-4289-a740-fa1545c8ea0d ==============================
[0m16:50:33.016815 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:50:33.023401 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'version_check': 'True', 'invocation_command': 'dbt run --select models/silverr', 'log_format': 'default', 'use_colors': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'quiet': 'False', 'empty': 'False', 'log_cache_events': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m16:50:34.074162 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:50:34.074162 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:50:34.074162 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:50:35.067783 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:50:35.482457 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:50:35.753292 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:35.753292 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:35.976207 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:50:35.992286 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:50:36.008032 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:50:36.008032 [warn ] [MainThread]: The selection criterion 'models/silverr' does not match any enabled nodes
[0m16:50:36.008032 [warn ] [MainThread]: Nothing to do. Try checking your model configs and model specification args
[0m16:50:36.008032 [debug] [MainThread]: Command end result
[0m16:50:36.066639 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:50:36.070672 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:50:36.077280 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:50:36.078981 [debug] [MainThread]: Command `dbt run` succeeded at 16:50:36.078981 after 3.31 seconds
[0m16:50:36.080211 [debug] [MainThread]: Flushing usage events
[0m16:50:43.377015 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:50:43.455162 | d84f566b-7858-424b-817f-b6b1f478e515 ==============================
[0m16:50:43.455162 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:50:43.455162 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt run --select models/silver', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'quiet': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt'}
[0m16:50:44.508110 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:50:44.508110 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:50:44.508110 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:50:45.560947 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:50:46.042361 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:50:46.330251 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:50:46.330251 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:50:46.556998 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:50:46.556998 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:50:46.574666 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:50:46.579944 [info ] [MainThread]: 
[0m16:50:46.579944 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:50:46.579944 [info ] [MainThread]: 
[0m16:50:46.579944 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:50:46.579944 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:50:46.579944 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:50:46.579944 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:50:46.579944 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:50:46.579944 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:50:46.579944 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:47.683062 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-3ffc-101e-b952-2caf41e3ac38) - Created
[0m16:50:48.319318 [debug] [ThreadPool]: SQL status: OK in 1.740 seconds
[0m16:50:48.319318 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff0-3ffc-101e-b952-2caf41e3ac38, command-id=01f08ff0-4042-10b3-9cba-2127d38bcbb4) - Closing
[0m16:50:48.319318 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:50:48.319318 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-3ffc-101e-b952-2caf41e3ac38) - Closing
[0m16:50:48.541101 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m16:50:48.541101 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m16:50:48.555946 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m16:50:48.555946 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m16:50:48.555946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:49.349918 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-4121-176a-a755-6f0e4456df04) - Created
[0m16:50:49.932267 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m16:50:49.941850 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff0-4121-176a-a755-6f0e4456df04, command-id=01f08ff0-4141-1bed-a629-3834d71c30b3) - Closing
[0m16:50:49.941850 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m16:50:49.943857 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-4121-176a-a755-6f0e4456df04) - Closing
[0m16:50:50.167828 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:50:50.168989 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:50:50.177165 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:50:50.177856 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:50:50.178393 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:51.274662 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-4245-101c-a376-28faa485d763) - Created
[0m16:50:51.851269 [debug] [ThreadPool]: SQL status: OK in 1.670 seconds
[0m16:50:51.855266 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff0-4245-101c-a376-28faa485d763, command-id=01f08ff0-4267-12ee-9b27-81a1d4694193) - Closing
[0m16:50:51.855266 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:50:51.857273 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-4245-101c-a376-28faa485d763) - Closing
[0m16:50:52.084950 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:50:52.086107 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:50:52.092393 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:50:52.093622 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:50:52.094928 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:50:53.203181 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-436c-1b25-80f3-6b32f056c147) - Created
[0m16:50:53.771032 [debug] [ThreadPool]: SQL status: OK in 1.680 seconds
[0m16:50:53.775047 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff0-436c-1b25-80f3-6b32f056c147, command-id=01f08ff0-438b-1a17-ab2f-9a012290d45a) - Closing
[0m16:50:53.775047 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:50:53.777054 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff0-436c-1b25-80f3-6b32f056c147) - Closing
[0m16:50:54.006901 [debug] [Thread-5 (]: Began running node model.dbt_eTl.silver_sales
[0m16:50:54.011172 [info ] [Thread-5 (]: 1 of 1 START sql view model default.silver_sales ............................... [RUN]
[0m16:50:54.013957 [debug] [Thread-5 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m16:50:54.014524 [debug] [Thread-5 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m16:50:54.015072 [debug] [Thread-5 (]: Began compiling node model.dbt_eTl.silver_sales
[0m16:50:54.038825 [debug] [Thread-5 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m16:50:54.041292 [debug] [Thread-5 (]: Began executing node model.dbt_eTl.silver_sales
[0m16:50:54.075299 [debug] [Thread-5 (]: MATERIALIZING VIEW
[0m16:50:54.078217 [warn ] [Thread-5 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:50:54.102335 [debug] [Thread-5 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m16:50:54.127528 [debug] [Thread-5 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m16:50:54.128758 [debug] [Thread-5 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m16:50:54.130205 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m16:50:54.131213 [debug] [Thread-5 (]: Opening a new connection, currently in state init
[0m16:50:54.976638 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08ff0-447a-16f8-980f-466b7d1f4b96) - Created
[0m16:50:55.806925 [debug] [Thread-5 (]: SQL status: OK in 1.680 seconds
[0m16:50:55.806925 [debug] [Thread-5 (]: Databricks adapter: Cursor(session-id=01f08ff0-447a-16f8-980f-466b7d1f4b96, command-id=01f08ff0-449b-13cd-a51d-1c9f904d5c8a) - Closing
[0m16:50:55.806925 [debug] [Thread-5 (]: Applying tags to relation None
[0m16:50:55.806925 [debug] [Thread-5 (]: On model.dbt_eTl.silver_sales: Close
[0m16:50:55.821974 [debug] [Thread-5 (]: Databricks adapter: Connection(session-id=01f08ff0-447a-16f8-980f-466b7d1f4b96) - Closing
[0m16:50:56.060904 [info ] [Thread-5 (]: 1 of 1 OK created sql view model default.silver_sales .......................... [[32mOK[0m in 2.05s]
[0m16:50:56.061912 [debug] [Thread-5 (]: Finished running node model.dbt_eTl.silver_sales
[0m16:50:56.063907 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:50:56.063907 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:50:56.064909 [info ] [MainThread]: 
[0m16:50:56.065906 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 9.48 seconds (9.48s).
[0m16:50:56.066906 [debug] [MainThread]: Command end result
[0m16:50:56.192048 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:50:56.204792 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:50:56.204792 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:50:56.204792 [info ] [MainThread]: 
[0m16:50:56.204792 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:50:56.204792 [info ] [MainThread]: 
[0m16:50:56.204792 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=1
[0m16:50:56.204792 [debug] [MainThread]: Command `dbt run` succeeded at 16:50:56.204792 after 12.91 seconds
[0m16:50:56.204792 [debug] [MainThread]: Flushing usage events
[0m16:56:14.504796 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:56:14.595824 | 766cf8b1-830b-4e0f-ba83-c2ef5d50c9f9 ==============================
[0m16:56:14.595824 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:56:14.595824 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'send_anonymous_usage_stats': 'True', 'warn_error': 'None', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'printer_width': '80', 'empty': 'False', 'use_experimental_parser': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'static_parser': 'True', 'write_json': 'True'}
[0m16:56:15.528432 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:56:15.528432 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:56:15.529428 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:56:16.352930 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:56:16.681476 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:56:16.885449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:56:16.901261 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:56:17.092766 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:56:17.099033 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:56:17.127827 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:56:17.127827 [info ] [MainThread]: 
[0m16:56:17.127827 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:56:17.127827 [info ] [MainThread]: 
[0m16:56:17.127827 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:56:17.134698 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:56:17.142491 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:56:17.142491 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:56:17.142491 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:56:17.142491 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:56:17.142491 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:18.001681 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-0506-13d0-adb7-7a6d1b801dda) - Created
[0m16:56:18.569655 [debug] [ThreadPool]: SQL status: OK in 1.430 seconds
[0m16:56:18.572717 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-0506-13d0-adb7-7a6d1b801dda, command-id=01f08ff1-0525-1ade-9b53-d9e2aa8a55be) - Closing
[0m16:56:18.572717 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:56:18.573796 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-0506-13d0-adb7-7a6d1b801dda) - Closing
[0m16:56:18.808030 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:56:18.808030 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:56:18.809030 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:56:18.809030 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:56:18.810180 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:19.580444 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-05f3-1d9f-a372-0e143bc20b49) - Created
[0m16:56:20.091795 [debug] [ThreadPool]: SQL status: OK in 1.280 seconds
[0m16:56:20.094511 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-05f3-1d9f-a372-0e143bc20b49, command-id=01f08ff1-0614-1f08-8b31-386bbb58b744) - Closing
[0m16:56:20.096517 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:56:20.097069 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-05f3-1d9f-a372-0e143bc20b49) - Closing
[0m16:56:20.324552 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:56:20.324552 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:56:20.324552 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:56:20.327411 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:56:20.327411 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:21.190527 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-06ea-1580-8834-63285688ef02) - Created
[0m16:56:21.711321 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m16:56:21.713997 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-06ea-1580-8834-63285688ef02, command-id=01f08ff1-070a-1e5a-8528-014f6960ece2) - Closing
[0m16:56:21.716003 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:56:21.716003 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-06ea-1580-8834-63285688ef02) - Closing
[0m16:56:21.934632 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:56:21.934632 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:56:21.962416 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:56:21.962416 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:56:21.964422 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:22.746149 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-07d6-1442-b542-7c1e97112294) - Created
[0m16:56:23.356399 [debug] [ThreadPool]: SQL status: OK in 1.390 seconds
[0m16:56:23.372037 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-07d6-1442-b542-7c1e97112294, command-id=01f08ff1-07f7-1abd-b590-029801c79ebf) - Closing
[0m16:56:23.372037 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:56:23.372037 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-07d6-1442-b542-7c1e97112294) - Closing
[0m16:56:23.593968 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:56:23.595973 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:56:23.595973 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:56:23.595973 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:56:23.595973 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:24.384514 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-08d2-1c61-987e-ee28d850dd49) - Created
[0m16:56:24.895402 [debug] [ThreadPool]: SQL status: OK in 1.300 seconds
[0m16:56:24.895402 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-08d2-1c61-987e-ee28d850dd49, command-id=01f08ff1-08f3-1bdd-b2fe-2ae01375744b) - Closing
[0m16:56:24.895402 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:56:24.895402 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-08d2-1c61-987e-ee28d850dd49) - Closing
[0m16:56:25.116589 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m16:56:25.121559 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m16:56:25.121559 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m16:56:25.121559 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m16:56:25.121559 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:56:25.986791 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-09c7-13c9-a352-ef7c4d1075f6) - Created
[0m16:56:26.562584 [debug] [ThreadPool]: SQL status: OK in 1.440 seconds
[0m16:56:26.562584 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-09c7-13c9-a352-ef7c4d1075f6, command-id=01f08ff1-09f0-1b94-a60f-aeeefba5499b) - Closing
[0m16:56:26.573910 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m16:56:26.573910 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-09c7-13c9-a352-ef7c4d1075f6) - Closing
[0m16:56:26.795662 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_customer
[0m16:56:26.795662 [info ] [Thread-7 (]: 1 of 13 START sql table model default.bronze_customer .......................... [RUN]
[0m16:56:26.795662 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m16:56:26.795662 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m16:56:26.795662 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m16:56:26.814560 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m16:56:26.815492 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_customer
[0m16:56:26.832112 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:56:26.832112 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:56:26.899960 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m16:56:26.899960 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m16:56:26.899960 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m16:56:26.899960 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:27.899672 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0aec-1197-a639-3da5dfe94b0d) - Created
[0m16:56:30.089809 [debug] [Thread-7 (]: SQL status: OK in 3.190 seconds
[0m16:56:30.089809 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-0aec-1197-a639-3da5dfe94b0d, command-id=01f08ff1-0b0b-188e-84e2-01b0eaf95d61) - Closing
[0m16:56:30.103579 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:30.125366 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: Close
[0m16:56:30.125366 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0aec-1197-a639-3da5dfe94b0d) - Closing
[0m16:56:30.357040 [info ] [Thread-7 (]: 1 of 13 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 3.56s]
[0m16:56:30.357040 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_customer
[0m16:56:30.357040 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_date
[0m16:56:30.357040 [info ] [Thread-7 (]: 2 of 13 START sql view model bronze.bronze_date ................................ [RUN]
[0m16:56:30.357040 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m16:56:30.357040 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m16:56:30.357040 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_date
[0m16:56:30.367518 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m16:56:30.367518 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_date
[0m16:56:30.522637 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:56:30.538861 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m16:56:30.539472 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m16:56:30.540713 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m16:56:30.541850 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m16:56:30.541850 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:31.298445 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0cef-1b77-aac9-c2cfbea0e10c) - Created
[0m16:56:32.087592 [debug] [Thread-7 (]: SQL status: OK in 1.540 seconds
[0m16:56:32.087592 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-0cef-1b77-aac9-c2cfbea0e10c, command-id=01f08ff1-0d10-1e49-94a6-7fd4c5ac0d4e) - Closing
[0m16:56:32.087592 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:32.089597 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: Close
[0m16:56:32.089597 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0cef-1b77-aac9-c2cfbea0e10c) - Closing
[0m16:56:32.312124 [info ] [Thread-7 (]: 2 of 13 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 1.95s]
[0m16:56:32.312124 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_date
[0m16:56:32.312124 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m16:56:32.312124 [info ] [Thread-7 (]: 3 of 13 START sql table model default.bronze_dim_product ....................... [RUN]
[0m16:56:32.312124 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m16:56:32.312124 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m16:56:32.312124 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m16:56:32.323266 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m16:56:32.325171 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m16:56:32.328380 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:56:32.333096 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m16:56:32.335121 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m16:56:32.336097 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m16:56:32.337096 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:33.331641 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0e29-125d-8a64-d1198a11153a) - Created
[0m16:56:35.232142 [debug] [Thread-7 (]: SQL status: OK in 2.900 seconds
[0m16:56:35.234149 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-0e29-125d-8a64-d1198a11153a, command-id=01f08ff1-0e48-1a04-b2ed-c304cba6937b) - Closing
[0m16:56:35.236158 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:35.238166 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m16:56:35.238166 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0e29-125d-8a64-d1198a11153a) - Closing
[0m16:56:35.465183 [info ] [Thread-7 (]: 3 of 13 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 3.15s]
[0m16:56:35.465183 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m16:56:35.465183 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_returns
[0m16:56:35.465183 [info ] [Thread-7 (]: 4 of 13 START sql view model default.bronze_returns ............................ [RUN]
[0m16:56:35.465183 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m16:56:35.465183 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m16:56:35.465183 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m16:56:35.465183 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m16:56:35.465183 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_returns
[0m16:56:35.478867 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:56:35.478867 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m16:56:35.480872 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m16:56:35.482470 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m16:56:35.483476 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m16:56:35.483996 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:36.231586 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0fe1-16aa-abb7-bb4cb06996b5) - Created
[0m16:56:37.118090 [debug] [Thread-7 (]: SQL status: OK in 1.630 seconds
[0m16:56:37.118090 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-0fe1-16aa-abb7-bb4cb06996b5, command-id=01f08ff1-1001-10b2-a7b5-03da62a363c3) - Closing
[0m16:56:37.118090 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:37.118090 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: Close
[0m16:56:37.118090 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-0fe1-16aa-abb7-bb4cb06996b5) - Closing
[0m16:56:37.349235 [info ] [Thread-7 (]: 4 of 13 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 1.88s]
[0m16:56:37.349235 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_returns
[0m16:56:37.349235 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_sales
[0m16:56:37.349235 [info ] [Thread-7 (]: 5 of 13 START sql view model bronze.bronze_sales ............................... [RUN]
[0m16:56:37.349235 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m16:56:37.349235 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m16:56:37.356597 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m16:56:37.356597 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m16:56:37.356597 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_sales
[0m16:56:37.356597 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:56:37.356597 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m16:56:37.356597 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m16:56:37.356597 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m16:56:37.356597 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m16:56:37.356597 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:38.132992 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1105-18af-a031-eb407ef1ac32) - Created
[0m16:56:38.889968 [debug] [Thread-7 (]: SQL status: OK in 1.530 seconds
[0m16:56:38.889968 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1105-18af-a031-eb407ef1ac32, command-id=01f08ff1-1124-1477-842a-09cb8dbf40f2) - Closing
[0m16:56:38.889968 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:38.889968 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: Close
[0m16:56:38.889968 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1105-18af-a031-eb407ef1ac32) - Closing
[0m16:56:39.112503 [info ] [Thread-7 (]: 5 of 13 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.76s]
[0m16:56:39.112503 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_sales
[0m16:56:39.112503 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_store
[0m16:56:39.112503 [info ] [Thread-7 (]: 6 of 13 START sql table model default.bronze_store ............................. [RUN]
[0m16:56:39.128208 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m16:56:39.128208 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m16:56:39.128208 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_store
[0m16:56:39.128208 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m16:56:39.128208 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_store
[0m16:56:39.145016 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:56:39.149711 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m16:56:39.151750 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m16:56:39.152712 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m16:56:39.153480 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:39.931695 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1216-1775-a0d6-f258eb002702) - Created
[0m16:56:41.914014 [debug] [Thread-7 (]: SQL status: OK in 2.760 seconds
[0m16:56:41.929899 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1216-1775-a0d6-f258eb002702, command-id=01f08ff1-1238-11bd-af5d-f645a2721a33) - Closing
[0m16:56:41.929899 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:41.929899 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: Close
[0m16:56:41.929899 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1216-1775-a0d6-f258eb002702) - Closing
[0m16:56:42.408659 [info ] [Thread-7 (]: 6 of 13 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 3.28s]
[0m16:56:42.413392 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_store
[0m16:56:42.413392 [debug] [Thread-7 (]: Began running node model.dbt_eTl.source_gold_items
[0m16:56:42.413392 [info ] [Thread-7 (]: 7 of 13 START sql view model default.source_gold_items ......................... [RUN]
[0m16:56:42.413392 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.source_gold_items) - Creating connection
[0m16:56:42.413392 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.source_gold_items'
[0m16:56:42.413392 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.source_gold_items
[0m16:56:42.425838 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.source_gold_items"
[0m16:56:42.426849 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.source_gold_items
[0m16:56:42.429326 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:56:42.432526 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`source_gold_items`
[0m16:56:42.433529 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.source_gold_items"
[0m16:56:42.434529 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.source_gold_items"
[0m16:56:42.435528 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.source_gold_items"} */

  
  
  create or replace view `dbt-project`.`default`.`source_gold_items`
  
  as (
    With dedup_query AS (
SELECT
*,
row_number() over (partition by id order by updatedate) as dedup_flag
FROM
`dbt-project`.`source`.`item`
)
SELECT
id, name, category,updatedate
FROM dedup_query
WHERE dedup_flag = 1
  )

[0m16:56:42.435528 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:43.567918 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-143e-1a65-905b-77a8be186564) - Created
[0m16:56:44.305883 [debug] [Thread-7 (]: SQL status: OK in 1.870 seconds
[0m16:56:44.305883 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-143e-1a65-905b-77a8be186564, command-id=01f08ff1-1461-1e93-b296-d6053c9fd6ef) - Closing
[0m16:56:44.305883 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:56:44.305883 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: Close
[0m16:56:44.305883 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-143e-1a65-905b-77a8be186564) - Closing
[0m16:56:44.736605 [info ] [Thread-7 (]: 7 of 13 OK created sql view model default.source_gold_items .................... [[32mOK[0m in 2.32s]
[0m16:56:44.736605 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.source_gold_items
[0m16:56:44.736605 [debug] [Thread-7 (]: Began running node seed.dbt_eTl.lookup
[0m16:56:44.736605 [info ] [Thread-7 (]: 8 of 13 START seed file bronze.lookup .......................................... [RUN]
[0m16:56:44.736605 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m16:56:44.736605 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m16:56:44.736605 [debug] [Thread-7 (]: Began compiling node seed.dbt_eTl.lookup
[0m16:56:44.736605 [debug] [Thread-7 (]: Began executing node seed.dbt_eTl.lookup
[0m16:56:44.782537 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:56:44.782537 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m16:56:44.782537 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:45.836106 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1598-1bff-a558-8184e2f091e0) - Created
[0m16:56:47.291671 [debug] [Thread-7 (]: SQL status: OK in 2.510 seconds
[0m16:56:47.291671 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1598-1bff-a558-8184e2f091e0, command-id=01f08ff1-15bc-1047-8087-263f5cff1c81) - Closing
[0m16:56:47.307345 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:56:47.307345 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m16:56:48.560054 [debug] [Thread-7 (]: SQL status: OK in 1.250 seconds
[0m16:56:48.560054 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1598-1bff-a558-8184e2f091e0, command-id=01f08ff1-169b-1e00-b23a-6b032aeaf299) - Closing
[0m16:56:48.576245 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m16:56:48.576245 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: Close
[0m16:56:48.576245 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1598-1bff-a558-8184e2f091e0) - Closing
[0m16:56:48.813935 [info ] [Thread-7 (]: 8 of 13 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 4.08s]
[0m16:56:48.813935 [debug] [Thread-7 (]: Finished running node seed.dbt_eTl.lookup
[0m16:56:48.813935 [debug] [Thread-7 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:56:48.813935 [info ] [Thread-7 (]: 9 of 13 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m16:56:48.813935 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:56:48.813935 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:56:48.813935 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:56:48.833659 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:56:48.833659 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:56:48.860373 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:56:48.860373 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:56:48.860373 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:56:48.860373 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:49.665505 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-17de-1d62-871d-2990a70d19f3) - Created
[0m16:56:50.231733 [debug] [Thread-7 (]: SQL status: OK in 1.370 seconds
[0m16:56:50.233771 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-17de-1d62-871d-2990a70d19f3, command-id=01f08ff1-1804-1214-894c-16872a6105cc) - Closing
[0m16:56:50.239906 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:56:50.239906 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-17de-1d62-871d-2990a70d19f3) - Closing
[0m16:56:50.452618 [info ] [Thread-7 (]: 9 of 13 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 1.64s]
[0m16:56:50.452618 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:56:50.452618 [debug] [Thread-7 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:56:50.452618 [info ] [Thread-7 (]: 10 of 13 START test unique_bronze_customer_customer_sk ......................... [RUN]
[0m16:56:50.468600 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:56:50.468600 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:56:50.468600 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:56:50.485222 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:56:50.498443 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:56:50.503794 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:56:50.506797 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:56:50.508718 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:56:50.508718 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:51.597817 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-190a-19ed-a5bc-dda51e10b1ce) - Created
[0m16:56:52.491801 [debug] [Thread-7 (]: SQL status: OK in 1.980 seconds
[0m16:56:52.496733 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-190a-19ed-a5bc-dda51e10b1ce, command-id=01f08ff1-192b-150e-a2f3-a8c20d01182f) - Closing
[0m16:56:52.498745 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:56:52.500256 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-190a-19ed-a5bc-dda51e10b1ce) - Closing
[0m16:56:52.803048 [info ] [Thread-7 (]: 10 of 13 PASS unique_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.33s]
[0m16:56:52.803048 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:56:52.813119 [debug] [Thread-7 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:56:52.813119 [info ] [Thread-7 (]: 11 of 13 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:56:52.816429 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:56:52.816429 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:56:52.818813 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:56:52.841347 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:56:52.847185 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:56:52.855862 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:56:52.860584 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:56:52.862302 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:56:52.862302 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:53.663685 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1a45-189c-b263-2edebe48af43) - Created
[0m16:56:54.310765 [debug] [Thread-7 (]: SQL status: OK in 1.450 seconds
[0m16:56:54.310765 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1a45-189c-b263-2edebe48af43, command-id=01f08ff1-1a64-1c73-a795-f275aad843c6) - Closing
[0m16:56:54.320682 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:56:54.320682 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1a45-189c-b263-2edebe48af43) - Closing
[0m16:56:54.541997 [info ] [Thread-7 (]: 11 of 13 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 1.73s]
[0m16:56:54.541997 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:56:54.541997 [debug] [Thread-7 (]: Began running node snapshot.dbt_eTl.gold_items
[0m16:56:54.541997 [info ] [Thread-7 (]: 12 of 13 START snapshot gold.gold_items ........................................ [RUN]
[0m16:56:54.541997 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_eTl.gold_items) - Creating connection
[0m16:56:54.541997 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_eTl.gold_items'
[0m16:56:54.546450 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_eTl.gold_items
[0m16:56:54.546450 [debug] [Thread-7 (]: Began executing node snapshot.dbt_eTl.gold_items
[0m16:56:54.654855 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:56:55.536989 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c) - Created
[0m16:56:55.547804 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:55.547804 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:56:55.995015 [debug] [Thread-7 (]: SQL status: OK in 0.450 seconds
[0m16:56:55.995015 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1b86-162f-a34e-ef9dd05e695f) - Closing
[0m16:56:56.137953 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:56.137953 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

        
  
    create or replace temporary view `gold_items__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m16:56:56.631712 [debug] [Thread-7 (]: SQL status: OK in 0.490 seconds
[0m16:56:56.631712 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1bdf-1e9a-a161-dcaff5e22f24) - Closing
[0m16:56:56.648550 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:56.648550 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:56:56.941738 [debug] [Thread-7 (]: SQL status: OK in 0.290 seconds
[0m16:56:56.945757 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1c2c-1f0e-a18b-10855968ce44) - Closing
[0m16:56:56.954233 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:56.954233 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:56:57.296786 [debug] [Thread-7 (]: SQL status: OK in 0.340 seconds
[0m16:56:57.296786 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1c5b-166c-8b39-b95a5732606b) - Closing
[0m16:56:57.296786 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:57.296786 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:56:57.582205 [debug] [Thread-7 (]: SQL status: OK in 0.290 seconds
[0m16:56:57.582205 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1c91-1aef-9708-f9e1042c8711) - Closing
[0m16:56:57.582205 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:57.598229 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:56:57.927107 [debug] [Thread-7 (]: SQL status: OK in 0.330 seconds
[0m16:56:57.930539 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1cbd-153d-a468-c91241743135) - Closing
[0m16:56:57.930539 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:57.930539 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:56:58.218209 [debug] [Thread-7 (]: SQL status: OK in 0.290 seconds
[0m16:56:58.220214 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1cf0-1e30-8eef-8d4887652c5a) - Closing
[0m16:56:58.242004 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:58.242004 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m16:56:58.792923 [debug] [Thread-7 (]: SQL status: OK in 0.550 seconds
[0m16:56:58.810784 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:58.810784 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m16:56:58.810784 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1d1f-1b29-a73e-43701dc01a34) - Closing
[0m16:56:59.070944 [debug] [Thread-7 (]: SQL status: OK in 0.260 seconds
[0m16:56:59.070944 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_eTl.gold_items"
[0m16:56:59.070944 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:56:59.070944 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

      merge into `dbt-project`.`gold`.`gold_items` as DBT_INTERNAL_DEST
    
      using `gold_items__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m16:56:59.070944 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1d77-14d1-8038-9cefefac8eb3) - Closing
[0m16:57:03.259708 [debug] [Thread-7 (]: SQL status: OK in 4.190 seconds
[0m16:57:03.261715 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-1d9f-1a31-b005-8a4fed1005d8) - Closing
[0m16:57:03.280980 [debug] [Thread-7 (]: Applying DROP to: `gold_items__dbt_tmp`
[0m16:57:03.296648 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:57:03.297816 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
DROP VIEW IF EXISTS `gold_items__dbt_tmp`
[0m16:57:03.596745 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m16:57:03.596745 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c, command-id=01f08ff1-2022-1c7d-a117-535cdf298ab9) - Closing
[0m16:57:03.596745 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: Close
[0m16:57:03.596745 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-1b61-15ce-935d-b8e0c8f8309c) - Closing
[0m16:57:03.836270 [info ] [Thread-7 (]: 12 of 13 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 9.29s]
[0m16:57:03.836270 [debug] [Thread-7 (]: Finished running node snapshot.dbt_eTl.gold_items
[0m16:57:03.836270 [debug] [Thread-7 (]: Began running node model.dbt_eTl.silver_sales
[0m16:57:03.836270 [info ] [Thread-7 (]: 13 of 13 START sql view model default.silver_sales ............................. [RUN]
[0m16:57:03.836270 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m16:57:03.836270 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m16:57:03.836270 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.silver_sales
[0m16:57:03.853264 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m16:57:03.869915 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.silver_sales
[0m16:57:03.880340 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:57:03.883321 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m16:57:03.883321 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m16:57:03.883321 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m16:57:03.883321 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m16:57:03.883321 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:57:04.780579 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-20e6-1741-aa36-b675fe54df6d) - Created
[0m16:57:05.671055 [debug] [Thread-7 (]: SQL status: OK in 1.790 seconds
[0m16:57:05.671055 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-20e6-1741-aa36-b675fe54df6d, command-id=01f08ff1-2106-1e7f-9c89-abf3365ae9f2) - Closing
[0m16:57:05.671055 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:57:05.671055 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: Close
[0m16:57:05.671055 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-20e6-1741-aa36-b675fe54df6d) - Closing
[0m16:57:05.909446 [info ] [Thread-7 (]: 13 of 13 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 2.07s]
[0m16:57:05.909446 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.silver_sales
[0m16:57:05.909446 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:57:05.909446 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:57:05.922216 [info ] [MainThread]: 
[0m16:57:05.922216 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 3 table models, 3 data tests, 5 view models in 0 hours 0 minutes and 48.79 seconds (48.79s).
[0m16:57:05.924262 [debug] [MainThread]: Command end result
[0m16:57:05.997668 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:57:06.008279 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:57:06.031833 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:57:06.037507 [info ] [MainThread]: 
[0m16:57:06.037507 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:57:06.037507 [info ] [MainThread]: 
[0m16:57:06.041203 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=13
[0m16:57:06.041203 [debug] [MainThread]: Command `dbt build` succeeded at 16:57:06.041203 after 51.59 seconds
[0m16:57:06.046751 [debug] [MainThread]: Flushing usage events
[0m16:57:58.185651 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 16:57:58.282921 | 9d2d89de-08cb-4cc9-80ac-65a35920d232 ==============================
[0m16:57:58.282921 [info ] [MainThread]: Running with dbt=1.10.11
[0m16:57:58.282921 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt build', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'printer_width': '80', 'fail_fast': 'False', 'no_print': 'None', 'empty': 'False', 'quiet': 'False', 'use_experimental_parser': 'False', 'log_cache_events': 'False', 'indirect_selection': 'eager', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'write_json': 'True', 'static_parser': 'True', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])'}
[0m16:57:59.299990 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m16:57:59.301996 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m16:57:59.301996 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m16:58:00.275374 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m16:58:00.716429 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m16:58:00.968107 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m16:58:00.968107 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m16:58:01.190279 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:58:01.206071 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:58:01.222218 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m16:58:01.222218 [info ] [MainThread]: 
[0m16:58:01.222218 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m16:58:01.238312 [info ] [MainThread]: 
[0m16:58:01.239553 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:58:01.239553 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:58:01.249456 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:58:01.249456 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:58:01.250457 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:58:01.250457 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:58:01.250457 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:02.062869 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-430d-13f8-a12d-489074617da9) - Created
[0m16:58:02.442997 [debug] [ThreadPool]: SQL status: OK in 1.190 seconds
[0m16:58:02.442997 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-430d-13f8-a12d-489074617da9, command-id=01f08ff1-432b-1630-86bf-75f4065375aa) - Closing
[0m16:58:02.442997 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:58:02.442997 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-430d-13f8-a12d-489074617da9) - Closing
[0m16:58:02.658047 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:58:02.658047 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:58:02.658047 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:58:02.658047 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:58:02.673721 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:03.536026 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-43ec-1ce8-9245-a0aa72deb958) - Created
[0m16:58:03.910663 [debug] [ThreadPool]: SQL status: OK in 1.240 seconds
[0m16:58:03.912951 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-43ec-1ce8-9245-a0aa72deb958, command-id=01f08ff1-440c-18c9-9a9c-62532ff976d4) - Closing
[0m16:58:03.913950 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:58:03.913950 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-43ec-1ce8-9245-a0aa72deb958) - Closing
[0m16:58:04.117658 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m16:58:04.117658 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m16:58:04.131466 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m16:58:04.131466 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m16:58:04.131466 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:05.011782 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-44cd-101f-ad50-00b7fca80490) - Created
[0m16:58:05.388275 [debug] [ThreadPool]: SQL status: OK in 1.260 seconds
[0m16:58:05.388275 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-44cd-101f-ad50-00b7fca80490, command-id=01f08ff1-44ec-17d9-b149-f7b0ddb9cc12) - Closing
[0m16:58:05.388275 [debug] [ThreadPool]: On list_dbt-project: Close
[0m16:58:05.388275 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-44cd-101f-ad50-00b7fca80490) - Closing
[0m16:58:05.623640 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m16:58:05.623640 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m16:58:05.639768 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m16:58:05.639768 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m16:58:05.639768 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:06.392785 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-459f-11d6-acb2-0ad8eb017c7f) - Created
[0m16:58:07.049917 [debug] [ThreadPool]: SQL status: OK in 1.410 seconds
[0m16:58:07.061325 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-459f-11d6-acb2-0ad8eb017c7f, command-id=01f08ff1-45bf-10a2-ab79-3336039290b1) - Closing
[0m16:58:07.062457 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m16:58:07.062989 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-459f-11d6-acb2-0ad8eb017c7f) - Closing
[0m16:58:07.271047 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m16:58:07.271047 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m16:58:07.271047 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m16:58:07.271047 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m16:58:07.271047 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:08.053623 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-469e-1767-87d7-1505c85be0f9) - Created
[0m16:58:08.653465 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m16:58:08.653465 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-469e-1767-87d7-1505c85be0f9, command-id=01f08ff1-46bd-19b0-bc2e-46c58c68fce6) - Closing
[0m16:58:08.656666 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m16:58:08.656666 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-469e-1767-87d7-1505c85be0f9) - Closing
[0m16:58:08.868976 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m16:58:08.868976 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m16:58:08.868976 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m16:58:08.868976 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m16:58:08.868976 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m16:58:09.622449 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-478c-1dbd-88cd-0a55ec943054) - Created
[0m16:58:10.097679 [debug] [ThreadPool]: SQL status: OK in 1.230 seconds
[0m16:58:10.099771 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff1-478c-1dbd-88cd-0a55ec943054, command-id=01f08ff1-47ad-1b9c-b8f9-33db84e2c41a) - Closing
[0m16:58:10.099771 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m16:58:10.099771 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff1-478c-1dbd-88cd-0a55ec943054) - Closing
[0m16:58:10.327659 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_customer
[0m16:58:10.327659 [info ] [Thread-7 (]: 1 of 13 START sql table model default.bronze_customer .......................... [RUN]
[0m16:58:10.327659 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m16:58:10.327659 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m16:58:10.327659 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m16:58:10.341624 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m16:58:10.343700 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_customer
[0m16:58:10.362176 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:58:10.362176 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m16:58:10.425263 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m16:58:10.426260 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m16:58:10.427259 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m16:58:10.428580 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:11.175688 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4879-1add-b23e-ba4558596aed) - Created
[0m16:58:13.450317 [debug] [Thread-7 (]: SQL status: OK in 3.020 seconds
[0m16:58:13.451317 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-4879-1add-b23e-ba4558596aed, command-id=01f08ff1-489b-1add-a086-bcb9711faa7d) - Closing
[0m16:58:13.461309 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:13.492322 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: Close
[0m16:58:13.492822 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4879-1add-b23e-ba4558596aed) - Closing
[0m16:58:13.900782 [info ] [Thread-7 (]: 1 of 13 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 3.57s]
[0m16:58:13.900782 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_customer
[0m16:58:13.900782 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_date
[0m16:58:13.900782 [info ] [Thread-7 (]: 2 of 13 START sql view model bronze.bronze_date ................................ [RUN]
[0m16:58:13.900782 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m16:58:13.900782 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m16:58:13.900782 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_date
[0m16:58:13.900782 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m16:58:13.900782 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_date
[0m16:58:14.026228 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:58:14.026228 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m16:58:14.026228 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m16:58:14.026228 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m16:58:14.041863 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m16:58:14.041863 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:15.061552 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4ac6-1c6b-8125-967bc6f52b7d) - Created
[0m16:58:15.911960 [debug] [Thread-7 (]: SQL status: OK in 1.870 seconds
[0m16:58:15.911960 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-4ac6-1c6b-8125-967bc6f52b7d, command-id=01f08ff1-4aeb-1327-9394-f1a05d9314bd) - Closing
[0m16:58:15.913969 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:15.913969 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: Close
[0m16:58:15.915977 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4ac6-1c6b-8125-967bc6f52b7d) - Closing
[0m16:58:16.143093 [info ] [Thread-7 (]: 2 of 13 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.24s]
[0m16:58:16.143093 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_date
[0m16:58:16.143093 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m16:58:16.143093 [info ] [Thread-7 (]: 3 of 13 START sql table model default.bronze_dim_product ....................... [RUN]
[0m16:58:16.143093 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m16:58:16.143093 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m16:58:16.143093 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m16:58:16.160138 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m16:58:16.161849 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m16:58:16.165181 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:58:16.165181 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m16:58:16.165181 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m16:58:16.165181 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m16:58:16.165181 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:17.306390 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4c1e-1141-9cfa-253c1ccee03c) - Created
[0m16:58:19.279125 [debug] [Thread-7 (]: SQL status: OK in 3.110 seconds
[0m16:58:19.280122 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-4c1e-1141-9cfa-253c1ccee03c, command-id=01f08ff1-4c41-1851-ae95-713b8f3c47d7) - Closing
[0m16:58:19.281122 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:19.282122 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m16:58:19.282122 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4c1e-1141-9cfa-253c1ccee03c) - Closing
[0m16:58:19.501867 [info ] [Thread-7 (]: 3 of 13 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 3.36s]
[0m16:58:19.501867 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m16:58:19.501867 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_returns
[0m16:58:19.501867 [info ] [Thread-7 (]: 4 of 13 START sql view model default.bronze_returns ............................ [RUN]
[0m16:58:19.501867 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m16:58:19.501867 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m16:58:19.501867 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m16:58:19.501867 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m16:58:19.501867 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_returns
[0m16:58:19.520746 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:58:19.521853 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m16:58:19.523927 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m16:58:19.524918 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m16:58:19.524918 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m16:58:19.524918 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:20.284214 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4de7-1ceb-9ae9-245f31ac6fe1) - Created
[0m16:58:21.115257 [debug] [Thread-7 (]: SQL status: OK in 1.590 seconds
[0m16:58:21.128785 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-4de7-1ceb-9ae9-245f31ac6fe1, command-id=01f08ff1-4e07-1a49-adee-e73a057f8d08) - Closing
[0m16:58:21.128785 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:21.128785 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: Close
[0m16:58:21.128785 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4de7-1ceb-9ae9-245f31ac6fe1) - Closing
[0m16:58:21.351430 [info ] [Thread-7 (]: 4 of 13 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 1.85s]
[0m16:58:21.351430 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_returns
[0m16:58:21.351430 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_sales
[0m16:58:21.351430 [info ] [Thread-7 (]: 5 of 13 START sql view model bronze.bronze_sales ............................... [RUN]
[0m16:58:21.351430 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m16:58:21.351430 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m16:58:21.351430 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m16:58:21.351430 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m16:58:21.351430 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_sales
[0m16:58:21.367163 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:58:21.369585 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m16:58:21.370127 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m16:58:21.373604 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m16:58:21.373604 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m16:58:21.373604 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:22.161609 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4f04-1de3-9acf-cbc574c04710) - Created
[0m16:58:22.898013 [debug] [Thread-7 (]: SQL status: OK in 1.520 seconds
[0m16:58:22.898013 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-4f04-1de3-9acf-cbc574c04710, command-id=01f08ff1-4f25-16a9-b207-24924ad14ec3) - Closing
[0m16:58:22.898013 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:22.898013 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: Close
[0m16:58:22.898013 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-4f04-1de3-9acf-cbc574c04710) - Closing
[0m16:58:23.131200 [info ] [Thread-7 (]: 5 of 13 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 1.78s]
[0m16:58:23.131200 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_sales
[0m16:58:23.131200 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_store
[0m16:58:23.137866 [info ] [Thread-7 (]: 6 of 13 START sql table model default.bronze_store ............................. [RUN]
[0m16:58:23.137866 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m16:58:23.137866 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m16:58:23.137866 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_store
[0m16:58:23.146007 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m16:58:23.146007 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_store
[0m16:58:23.148014 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m16:58:23.150021 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m16:58:23.152026 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m16:58:23.152026 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m16:58:23.152026 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:23.899962 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-500e-1fb4-8f92-ff6ca92e7e5f) - Created
[0m16:58:26.240916 [debug] [Thread-7 (]: SQL status: OK in 3.090 seconds
[0m16:58:26.240916 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-500e-1fb4-8f92-ff6ca92e7e5f, command-id=01f08ff1-502f-10a6-b875-6658480647c6) - Closing
[0m16:58:26.240916 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:26.240916 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: Close
[0m16:58:26.240916 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-500e-1fb4-8f92-ff6ca92e7e5f) - Closing
[0m16:58:26.475763 [info ] [Thread-7 (]: 6 of 13 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 3.34s]
[0m16:58:26.477310 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_store
[0m16:58:26.477838 [debug] [Thread-7 (]: Began running node model.dbt_eTl.source_gold_items
[0m16:58:26.478433 [info ] [Thread-7 (]: 7 of 13 START sql view model default.source_gold_items ......................... [RUN]
[0m16:58:26.479494 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.source_gold_items) - Creating connection
[0m16:58:26.480010 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.source_gold_items'
[0m16:58:26.480528 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.source_gold_items
[0m16:58:26.485137 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.source_gold_items"
[0m16:58:26.486163 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.source_gold_items
[0m16:58:26.489305 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:58:26.489305 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`source_gold_items`
[0m16:58:26.489305 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.source_gold_items"
[0m16:58:26.489305 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.source_gold_items"
[0m16:58:26.489305 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.source_gold_items"} */

  
  
  create or replace view `dbt-project`.`default`.`source_gold_items`
  
  as (
    With dedup_query AS (
SELECT
*,
row_number() over (partition by id order by updatedate) as dedup_flag
FROM
`dbt-project`.`source`.`item`
)
SELECT
id, name, category,updatedate
FROM dedup_query
WHERE dedup_flag = 1
  )

[0m16:58:26.489305 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:27.259473 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5210-1127-9b3e-aa12e285f845) - Created
[0m16:58:28.017308 [debug] [Thread-7 (]: SQL status: OK in 1.530 seconds
[0m16:58:28.017308 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-5210-1127-9b3e-aa12e285f845, command-id=01f08ff1-522f-1bc6-90f6-8c355f4418e2) - Closing
[0m16:58:28.017308 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:28.017308 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: Close
[0m16:58:28.017308 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5210-1127-9b3e-aa12e285f845) - Closing
[0m16:58:28.254969 [info ] [Thread-7 (]: 7 of 13 OK created sql view model default.source_gold_items .................... [[32mOK[0m in 1.78s]
[0m16:58:28.254969 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.source_gold_items
[0m16:58:28.254969 [debug] [Thread-7 (]: Began running node seed.dbt_eTl.lookup
[0m16:58:28.254969 [info ] [Thread-7 (]: 8 of 13 START seed file bronze.lookup .......................................... [RUN]
[0m16:58:28.254969 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m16:58:28.254969 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m16:58:28.254969 [debug] [Thread-7 (]: Began compiling node seed.dbt_eTl.lookup
[0m16:58:28.254969 [debug] [Thread-7 (]: Began executing node seed.dbt_eTl.lookup
[0m16:58:28.301445 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:58:28.302444 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m16:58:28.302444 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:29.050678 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5320-135c-84c1-3037c1e0ce28) - Created
[0m16:58:30.506441 [debug] [Thread-7 (]: SQL status: OK in 2.200 seconds
[0m16:58:30.506441 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-5320-135c-84c1-3037c1e0ce28, command-id=01f08ff1-5344-1095-98fa-017aea88cbe0) - Closing
[0m16:58:30.524234 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m16:58:30.524234 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m16:58:31.828464 [debug] [Thread-7 (]: SQL status: OK in 1.300 seconds
[0m16:58:31.828464 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-5320-135c-84c1-3037c1e0ce28, command-id=01f08ff1-5421-1a72-a90a-5841a02e47ed) - Closing
[0m16:58:31.839013 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m16:58:31.842028 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: Close
[0m16:58:31.842028 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5320-135c-84c1-3037c1e0ce28) - Closing
[0m16:58:32.055361 [info ] [Thread-7 (]: 8 of 13 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 3.80s]
[0m16:58:32.055361 [debug] [Thread-7 (]: Finished running node seed.dbt_eTl.lookup
[0m16:58:32.055361 [debug] [Thread-7 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:58:32.059461 [info ] [Thread-7 (]: 9 of 13 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m16:58:32.059461 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m16:58:32.061263 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m16:58:32.061263 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:58:32.083038 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:58:32.084036 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:58:32.113570 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:58:32.116873 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m16:58:32.117599 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m16:58:32.117599 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:32.907218 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-556d-15b3-aae0-30b88bc254b1) - Created
[0m16:58:33.508518 [debug] [Thread-7 (]: SQL status: OK in 1.390 seconds
[0m16:58:33.514266 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-556d-15b3-aae0-30b88bc254b1, command-id=01f08ff1-5590-1900-9b7c-e653c1cd17a6) - Closing
[0m16:58:33.518369 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m16:58:33.518954 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-556d-15b3-aae0-30b88bc254b1) - Closing
[0m16:58:33.769725 [info ] [Thread-7 (]: 9 of 13 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 1.71s]
[0m16:58:33.771333 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m16:58:33.771333 [debug] [Thread-7 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:58:33.773343 [info ] [Thread-7 (]: 10 of 13 START test unique_bronze_customer_customer_sk ......................... [RUN]
[0m16:58:33.774501 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m16:58:33.774501 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m16:58:33.774501 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:58:33.790167 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:58:33.793387 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:58:33.799855 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:58:33.801125 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m16:58:33.802131 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m16:58:33.803589 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:34.579801 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-566d-132d-a426-4ea664a2e6da) - Created
[0m16:58:35.253974 [debug] [Thread-7 (]: SQL status: OK in 1.450 seconds
[0m16:58:35.256721 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-566d-132d-a426-4ea664a2e6da, command-id=01f08ff1-5690-186e-84a8-9bcd60942bde) - Closing
[0m16:58:35.257766 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m16:58:35.258288 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-566d-132d-a426-4ea664a2e6da) - Closing
[0m16:58:35.459733 [info ] [Thread-7 (]: 10 of 13 PASS unique_bronze_customer_customer_sk ............................... [[32mPASS[0m in 1.69s]
[0m16:58:35.459733 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m16:58:35.459733 [debug] [Thread-7 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:58:35.459733 [info ] [Thread-7 (]: 11 of 13 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m16:58:35.459733 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m16:58:35.459733 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m16:58:35.459733 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:58:35.487292 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:58:35.489293 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:58:35.492293 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:58:35.493293 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m16:58:35.494294 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m16:58:35.494294 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:36.248746 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-576b-1745-874f-ff48a97ec87a) - Created
[0m16:58:36.918834 [debug] [Thread-7 (]: SQL status: OK in 1.420 seconds
[0m16:58:36.918834 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-576b-1745-874f-ff48a97ec87a, command-id=01f08ff1-578a-18c4-a572-39161e0a1bc0) - Closing
[0m16:58:36.934978 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m16:58:36.934978 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-576b-1745-874f-ff48a97ec87a) - Closing
[0m16:58:37.156439 [info ] [Thread-7 (]: 11 of 13 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 1.70s]
[0m16:58:37.156439 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m16:58:37.156439 [debug] [Thread-7 (]: Began running node snapshot.dbt_eTl.gold_items
[0m16:58:37.156439 [info ] [Thread-7 (]: 12 of 13 START snapshot gold.gold_items ........................................ [RUN]
[0m16:58:37.172469 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_eTl.gold_items) - Creating connection
[0m16:58:37.172469 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_eTl.gold_items'
[0m16:58:37.172469 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_eTl.gold_items
[0m16:58:37.172469 [debug] [Thread-7 (]: Began executing node snapshot.dbt_eTl.gold_items
[0m16:58:37.217562 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:38.144335 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f) - Created
[0m16:58:38.144335 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:38.158910 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:58:38.599736 [debug] [Thread-7 (]: SQL status: OK in 0.440 seconds
[0m16:58:38.599736 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-58ad-130f-bcd4-7dc851116495) - Closing
[0m16:58:38.659913 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:38.659913 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

        
  
    create or replace temporary view `gold_items__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m16:58:39.364797 [debug] [Thread-7 (]: SQL status: OK in 0.700 seconds
[0m16:58:39.364797 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-58f9-185d-92b7-7f00b070752a) - Closing
[0m16:58:39.364797 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:39.364797 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:58:39.690456 [debug] [Thread-7 (]: SQL status: OK in 0.330 seconds
[0m16:58:39.692578 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5966-1a83-b277-2b666cdf0776) - Closing
[0m16:58:39.697640 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:39.698206 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:58:40.032016 [debug] [Thread-7 (]: SQL status: OK in 0.330 seconds
[0m16:58:40.034210 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5998-18c4-b6ba-c754ce846053) - Closing
[0m16:58:40.037040 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:40.038039 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:58:40.312641 [debug] [Thread-7 (]: SQL status: OK in 0.270 seconds
[0m16:58:40.315445 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-59cc-12a5-adaa-5833fd229232) - Closing
[0m16:58:40.318669 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:40.319674 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m16:58:40.672649 [debug] [Thread-7 (]: SQL status: OK in 0.350 seconds
[0m16:58:40.672649 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-59f7-1030-896e-087ec6184617) - Closing
[0m16:58:40.672649 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:40.672649 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m16:58:40.967224 [debug] [Thread-7 (]: SQL status: OK in 0.290 seconds
[0m16:58:40.969242 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5a2f-1017-b180-a3bd7473a59b) - Closing
[0m16:58:40.977240 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:40.977240 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m16:58:41.621733 [debug] [Thread-7 (]: SQL status: OK in 0.640 seconds
[0m16:58:41.630162 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:41.631170 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m16:58:41.631932 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5a5d-1399-9d58-2b5e80702fc2) - Closing
[0m16:58:41.932134 [debug] [Thread-7 (]: SQL status: OK in 0.300 seconds
[0m16:58:41.934125 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_eTl.gold_items"
[0m16:58:41.936597 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:41.937677 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

      merge into `dbt-project`.`gold`.`gold_items` as DBT_INTERNAL_DEST
    
      using `gold_items__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m16:58:41.938392 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5abf-1cea-8fe3-2db8406c6936) - Closing
[0m16:58:44.811378 [debug] [Thread-7 (]: SQL status: OK in 2.870 seconds
[0m16:58:44.813442 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5aee-1799-aef8-4219aaa65198) - Closing
[0m16:58:44.826390 [debug] [Thread-7 (]: Applying DROP to: `gold_items__dbt_tmp`
[0m16:58:44.833758 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m16:58:44.833758 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
DROP VIEW IF EXISTS `gold_items__dbt_tmp`
[0m16:58:45.110914 [debug] [Thread-7 (]: SQL status: OK in 0.280 seconds
[0m16:58:45.110914 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f, command-id=01f08ff1-5ca8-1406-a7cc-73ddbdd2d64e) - Closing
[0m16:58:45.110914 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: Close
[0m16:58:45.110914 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-588c-1e6b-950b-b02509ab302f) - Closing
[0m16:58:45.352408 [info ] [Thread-7 (]: 12 of 13 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 8.18s]
[0m16:58:45.352408 [debug] [Thread-7 (]: Finished running node snapshot.dbt_eTl.gold_items
[0m16:58:45.352408 [debug] [Thread-7 (]: Began running node model.dbt_eTl.silver_sales
[0m16:58:45.352408 [info ] [Thread-7 (]: 13 of 13 START sql view model default.silver_sales ............................. [RUN]
[0m16:58:45.352408 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m16:58:45.352408 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m16:58:45.352408 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.silver_sales
[0m16:58:45.352408 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m16:58:45.352408 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.silver_sales
[0m16:58:45.367680 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m16:58:45.367680 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m16:58:45.369094 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m16:58:45.370821 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m16:58:45.371139 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m16:58:45.371971 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m16:58:46.171636 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5d54-1676-ae61-adf111d53380) - Created
[0m16:58:47.044807 [debug] [Thread-7 (]: SQL status: OK in 1.670 seconds
[0m16:58:47.044807 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff1-5d54-1676-ae61-adf111d53380, command-id=01f08ff1-5d75-107b-b143-b97812f42f6a) - Closing
[0m16:58:47.044807 [debug] [Thread-7 (]: Applying tags to relation None
[0m16:58:47.044807 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: Close
[0m16:58:47.044807 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff1-5d54-1676-ae61-adf111d53380) - Closing
[0m16:58:47.265729 [info ] [Thread-7 (]: 13 of 13 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 1.91s]
[0m16:58:47.265729 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.silver_sales
[0m16:58:47.265729 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m16:58:47.265729 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m16:58:47.265729 [info ] [MainThread]: 
[0m16:58:47.265729 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 3 table models, 3 data tests, 5 view models in 0 hours 0 minutes and 46.03 seconds (46.03s).
[0m16:58:47.265729 [debug] [MainThread]: Command end result
[0m16:58:47.318522 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m16:58:47.318522 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m16:58:47.329146 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m16:58:47.329146 [info ] [MainThread]: 
[0m16:58:47.329146 [info ] [MainThread]: [32mCompleted successfully[0m
[0m16:58:47.329146 [info ] [MainThread]: 
[0m16:58:47.329146 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=13
[0m16:58:47.329146 [debug] [MainThread]: Command `dbt build` succeeded at 16:58:47.329146 after 49.23 seconds
[0m16:58:47.329146 [debug] [MainThread]: Flushing usage events
[0m17:09:48.469492 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 17:09:49.041395 | a2eb228e-f767-4920-b067-d05faa06de55 ==============================
[0m17:09:49.041395 [info ] [MainThread]: Running with dbt=1.10.11
[0m17:09:49.046706 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'static_parser': 'True', 'send_anonymous_usage_stats': 'True', 'version_check': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'use_colors': 'True', 'invocation_command': 'dbt build', 'log_format': 'default', 'warn_error': 'None', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'use_experimental_parser': 'False', 'empty': 'False', 'printer_width': '80', 'quiet': 'False', 'log_path': 'C:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'indirect_selection': 'eager', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'write_json': 'True'}
[0m17:09:51.403871 [debug] [MainThread]: Spark adapter: Setting pyhive.hive logging to ERROR
[0m17:09:51.403871 [debug] [MainThread]: Spark adapter: Setting thrift.transport logging to ERROR
[0m17:09:51.405882 [debug] [MainThread]: Spark adapter: Setting thrift.protocol logging to ERROR
[0m17:09:52.756846 [info ] [MainThread]: Registered adapter: databricks=1.10.9
[0m17:09:53.289422 [debug] [MainThread]: checksum: 5335e1629744fab92fa7809c625edbb36f0d7063a879d6215c971798f27e66f9, vars: {}, profile: , target: , version: 1.10.11
[0m17:09:53.609299 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m17:09:53.609299 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m17:09:53.887505 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m17:09:53.887505 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m17:09:53.929157 [info ] [MainThread]: Found 2 analyses, 1 seed, 8 models, 3 data tests, 1 snapshot, 7 sources, 688 macros
[0m17:09:53.931265 [info ] [MainThread]: 
[0m17:09:53.931265 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m17:09:53.936143 [info ] [MainThread]: 
[0m17:09:53.937152 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:09:53.937700 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:09:53.946193 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m17:09:53.946193 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m17:09:53.946193 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m17:09:53.953261 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m17:09:53.953261 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:09:55.214925 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff2-ebf8-107c-b1b9-304ea68bdc40) - Created
[0m17:10:56.642755 [debug] [ThreadPool]: SQL status: OK in 62.690 seconds
[0m17:10:56.658444 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff2-ebf8-107c-b1b9-304ea68bdc40, command-id=01f08ff3-102d-15b4-a288-6fd665fd03b8) - Closing
[0m17:10:56.658444 [debug] [ThreadPool]: On list_dbt-project: Close
[0m17:10:56.658444 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff2-ebf8-107c-b1b9-304ea68bdc40) - Closing
[0m17:10:57.182797 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m17:10:57.182797 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m17:10:57.182797 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m17:10:57.182797 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m17:10:57.198136 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:10:58.243622 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-1198-1d31-8dc4-5931bb53e995) - Created
[0m17:10:58.882615 [debug] [ThreadPool]: SQL status: OK in 1.680 seconds
[0m17:10:58.896342 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff3-1198-1d31-8dc4-5931bb53e995, command-id=01f08ff3-11ce-1a92-abe2-3096b318bb69) - Closing
[0m17:10:58.896342 [debug] [ThreadPool]: On list_dbt-project: Close
[0m17:10:58.896342 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-1198-1d31-8dc4-5931bb53e995) - Closing
[0m17:10:59.134456 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project) - Creating connection
[0m17:10:59.134456 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project'
[0m17:10:59.134456 [debug] [ThreadPool]: Using databricks connection "list_dbt-project"
[0m17:10:59.134456 [debug] [ThreadPool]: On list_dbt-project: GetSchemas(database=dbt-project, schema=None)
[0m17:10:59.134456 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:10:59.917136 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-12ad-14d0-a481-a13f8e9d69b1) - Created
[0m17:11:00.283002 [debug] [ThreadPool]: SQL status: OK in 1.150 seconds
[0m17:11:00.285243 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff3-12ad-14d0-a481-a13f8e9d69b1, command-id=01f08ff3-12cc-1d04-a78c-0b23eb80541e) - Closing
[0m17:11:00.285909 [debug] [ThreadPool]: On list_dbt-project: Close
[0m17:11:00.286665 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-12ad-14d0-a481-a13f8e9d69b1) - Closing
[0m17:11:00.509721 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_default) - Creating connection
[0m17:11:00.511733 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_default'
[0m17:11:00.530375 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_default"
[0m17:11:00.530375 [debug] [ThreadPool]: On list_dbt-project_default: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_default"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'default'

  
[0m17:11:00.530375 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:11:01.388152 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-138a-1339-a53e-98a87b653894) - Created
[0m17:11:04.017838 [debug] [ThreadPool]: SQL status: OK in 3.490 seconds
[0m17:11:04.041973 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff3-138a-1339-a53e-98a87b653894, command-id=01f08ff3-13ae-1469-baaf-5661a4101d49) - Closing
[0m17:11:04.041973 [debug] [ThreadPool]: On list_dbt-project_default: Close
[0m17:11:04.041973 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-138a-1339-a53e-98a87b653894) - Closing
[0m17:11:04.254495 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_gold) - Creating connection
[0m17:11:04.270446 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_gold'
[0m17:11:04.270446 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_gold"
[0m17:11:04.270446 [debug] [ThreadPool]: On list_dbt-project_gold: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_gold"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'gold'

  
[0m17:11:04.270446 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:11:05.371555 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-15eb-1226-8b55-d2afd07ae381) - Created
[0m17:11:06.237623 [debug] [ThreadPool]: SQL status: OK in 1.970 seconds
[0m17:11:06.237623 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff3-15eb-1226-8b55-d2afd07ae381, command-id=01f08ff3-160e-1e51-8e25-284842b0b84e) - Closing
[0m17:11:06.237623 [debug] [ThreadPool]: On list_dbt-project_gold: Close
[0m17:11:06.237623 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-15eb-1226-8b55-d2afd07ae381) - Closing
[0m17:11:06.469835 [debug] [ThreadPool]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=list_dbt-project_bronze) - Creating connection
[0m17:11:06.469835 [debug] [ThreadPool]: Acquiring new databricks connection 'list_dbt-project_bronze'
[0m17:11:06.487644 [debug] [ThreadPool]: Using databricks connection "list_dbt-project_bronze"
[0m17:11:06.487644 [debug] [ThreadPool]: On list_dbt-project_bronze: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "connection_name": "list_dbt-project_bronze"} */

    
SELECT
  table_name,
  if(table_type IN ('EXTERNAL', 'MANAGED', 'MANAGED_SHALLOW_CLONE', 'EXTERNAL_SHALLOW_CLONE'), 'table', lower(table_type)) AS table_type,
  lower(data_source_format) AS file_format,
  table_owner,
  if(
    table_type IN (
      'EXTERNAL',
      'MANAGED',
      'MANAGED_SHALLOW_CLONE',
      'EXTERNAL_SHALLOW_CLONE'
    ),
    lower(table_type),
    NULL
  ) AS databricks_table_type
FROM `system`.`information_schema`.`tables`
WHERE table_catalog = 'dbt-project' 
  AND table_schema = 'bronze'

  
[0m17:11:06.487644 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m17:11:07.269613 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-170d-1263-9e02-4bd64ca4684f) - Created
[0m17:11:07.869456 [debug] [ThreadPool]: SQL status: OK in 1.380 seconds
[0m17:11:07.869456 [debug] [ThreadPool]: Databricks adapter: Cursor(session-id=01f08ff3-170d-1263-9e02-4bd64ca4684f, command-id=01f08ff3-172f-1fc1-b15b-331cbe0d687d) - Closing
[0m17:11:07.869456 [debug] [ThreadPool]: On list_dbt-project_bronze: Close
[0m17:11:07.869456 [debug] [ThreadPool]: Databricks adapter: Connection(session-id=01f08ff3-170d-1263-9e02-4bd64ca4684f) - Closing
[0m17:11:08.095114 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_customer
[0m17:11:08.095114 [info ] [Thread-7 (]: 1 of 13 START sql table model default.bronze_customer .......................... [RUN]
[0m17:11:08.095114 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_customer) - Creating connection
[0m17:11:08.095114 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_customer'
[0m17:11:08.095114 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_customer
[0m17:11:08.106557 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_customer"
[0m17:11:08.108208 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_customer
[0m17:11:08.124164 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m17:11:08.124164 [warn ] [Thread-7 (]: [[33mWARNING[0m]: Use revamped materializations based on separating create and insert.  This allows more performant column comments, as well as new column features.
You may opt into the new behavior sooner by setting `flags.use_materialization_v2` to `True` in `dbt_project.yml`.
Visit https://docs.getdbt.com/reference/global-configs/behavior-changes for more information.
[0m17:11:08.178637 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_customer"
[0m17:11:08.180644 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_customer"
[0m17:11:08.180644 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_customer"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_customer`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_customer`
  
[0m17:11:08.180644 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:08.917738 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-180c-19b3-ac3f-83a88ad50c15) - Created
[0m17:11:16.051380 [debug] [Thread-7 (]: SQL status: OK in 7.870 seconds
[0m17:11:16.053390 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-180c-19b3-ac3f-83a88ad50c15, command-id=01f08ff3-182b-1e84-91d2-ea89413928f8) - Closing
[0m17:11:16.501659 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:16.521229 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_customer: Close
[0m17:11:16.521229 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-180c-19b3-ac3f-83a88ad50c15) - Closing
[0m17:11:16.757115 [info ] [Thread-7 (]: 1 of 13 OK created sql table model default.bronze_customer ..................... [[32mOK[0m in 8.66s]
[0m17:11:16.757115 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_customer
[0m17:11:16.757115 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_date
[0m17:11:16.757115 [info ] [Thread-7 (]: 2 of 13 START sql view model bronze.bronze_date ................................ [RUN]
[0m17:11:16.757115 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_date) - Creating connection
[0m17:11:16.757115 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_date'
[0m17:11:16.757115 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_date
[0m17:11:16.774846 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_date"
[0m17:11:16.774846 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_date
[0m17:11:16.889557 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m17:11:16.890880 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_date`
[0m17:11:16.902520 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_date"
[0m17:11:16.902520 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_date"
[0m17:11:16.902520 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_date"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_date`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_date`
  )

[0m17:11:16.902520 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:17.666296 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-1d3f-18c0-82fd-a687b0b02ae4) - Created
[0m17:11:18.634360 [debug] [Thread-7 (]: SQL status: OK in 1.730 seconds
[0m17:11:18.634360 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-1d3f-18c0-82fd-a687b0b02ae4, command-id=01f08ff3-1d63-1117-9ee8-1bf7c834a8b3) - Closing
[0m17:11:18.636367 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:18.636367 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_date: Close
[0m17:11:18.636367 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-1d3f-18c0-82fd-a687b0b02ae4) - Closing
[0m17:11:18.856571 [info ] [Thread-7 (]: 2 of 13 OK created sql view model bronze.bronze_date ........................... [[32mOK[0m in 2.10s]
[0m17:11:18.856571 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_date
[0m17:11:18.856571 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_dim_product
[0m17:11:18.856571 [info ] [Thread-7 (]: 3 of 13 START sql table model default.bronze_dim_product ....................... [RUN]
[0m17:11:18.856571 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_dim_product) - Creating connection
[0m17:11:18.856571 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_dim_product'
[0m17:11:18.856571 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_dim_product
[0m17:11:18.856571 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_dim_product"
[0m17:11:18.856571 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_dim_product
[0m17:11:18.856571 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m17:11:18.856571 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_dim_product"
[0m17:11:18.872245 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_dim_product"
[0m17:11:18.872913 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_dim_product"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_dim_product`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_product`
  
[0m17:11:18.872913 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:19.650380 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-1e6c-17f4-ae9e-99acb9ce43d0) - Created
[0m17:11:24.808953 [debug] [Thread-7 (]: SQL status: OK in 5.940 seconds
[0m17:11:24.808953 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-1e6c-17f4-ae9e-99acb9ce43d0, command-id=01f08ff3-1e8f-1fcc-b85a-46b385ae458a) - Closing
[0m17:11:24.808953 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:24.808953 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_dim_product: Close
[0m17:11:24.808953 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-1e6c-17f4-ae9e-99acb9ce43d0) - Closing
[0m17:11:25.035095 [info ] [Thread-7 (]: 3 of 13 OK created sql table model default.bronze_dim_product .................. [[32mOK[0m in 6.18s]
[0m17:11:25.035095 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_dim_product
[0m17:11:25.035095 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_returns
[0m17:11:25.035095 [info ] [Thread-7 (]: 4 of 13 START sql view model default.bronze_returns ............................ [RUN]
[0m17:11:25.035095 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_returns) - Creating connection
[0m17:11:25.035095 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_returns'
[0m17:11:25.035095 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_returns
[0m17:11:25.050820 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_returns"
[0m17:11:25.050820 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_returns
[0m17:11:25.050820 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m17:11:25.050820 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`bronze_returns`
[0m17:11:25.050820 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_returns"
[0m17:11:25.050820 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_returns"
[0m17:11:25.050820 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_returns"} */

  
  
  create or replace view `dbt-project`.`default`.`bronze_returns`
  
  as (
    SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_returns`
  )

[0m17:11:25.050820 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:25.827379 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2220-1490-87e8-67c2ab99c41f) - Created
[0m17:11:26.731167 [debug] [Thread-7 (]: SQL status: OK in 1.680 seconds
[0m17:11:26.731167 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-2220-1490-87e8-67c2ab99c41f, command-id=01f08ff3-2240-11f4-a7a8-43ea268a2dec) - Closing
[0m17:11:26.733173 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:26.733173 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_returns: Close
[0m17:11:26.733173 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2220-1490-87e8-67c2ab99c41f) - Closing
[0m17:11:27.013848 [info ] [Thread-7 (]: 4 of 13 OK created sql view model default.bronze_returns ....................... [[32mOK[0m in 1.98s]
[0m17:11:27.013848 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_returns
[0m17:11:27.013848 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_sales
[0m17:11:27.013848 [info ] [Thread-7 (]: 5 of 13 START sql view model bronze.bronze_sales ............................... [RUN]
[0m17:11:27.013848 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_sales) - Creating connection
[0m17:11:27.013848 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_sales'
[0m17:11:27.013848 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_sales
[0m17:11:27.027783 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_sales"
[0m17:11:27.027783 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_sales
[0m17:11:27.033068 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m17:11:27.034717 [debug] [Thread-7 (]: Creating view `dbt-project`.`bronze`.`bronze_sales`
[0m17:11:27.035724 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_sales"
[0m17:11:27.035724 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_sales"
[0m17:11:27.035724 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_sales"} */

  
  
  create or replace view `dbt-project`.`bronze`.`bronze_sales`
  
  as (
    ---
SELECT 
        *
 FROM
        `dbt-project`.`source`.`fact_sales`
  )

[0m17:11:27.035724 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:28.077900 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2375-1bbc-bded-962b5352b3cf) - Created
[0m17:11:28.871652 [debug] [Thread-7 (]: SQL status: OK in 1.840 seconds
[0m17:11:28.871652 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-2375-1bbc-bded-962b5352b3cf, command-id=01f08ff3-2397-1b04-b2b1-0c763de693b1) - Closing
[0m17:11:28.871652 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:28.871652 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_sales: Close
[0m17:11:28.871652 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2375-1bbc-bded-962b5352b3cf) - Closing
[0m17:11:29.102822 [info ] [Thread-7 (]: 5 of 13 OK created sql view model bronze.bronze_sales .......................... [[32mOK[0m in 2.09s]
[0m17:11:29.103823 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_sales
[0m17:11:29.103823 [debug] [Thread-7 (]: Began running node model.dbt_eTl.bronze_store
[0m17:11:29.104823 [info ] [Thread-7 (]: 6 of 13 START sql table model default.bronze_store ............................. [RUN]
[0m17:11:29.104823 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.bronze_store) - Creating connection
[0m17:11:29.105823 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.bronze_store'
[0m17:11:29.106340 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.bronze_store
[0m17:11:29.112468 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.bronze_store"
[0m17:11:29.113980 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.bronze_store
[0m17:11:29.115990 [debug] [Thread-7 (]: MATERIALIZING TABLE
[0m17:11:29.117991 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.bronze_store"
[0m17:11:29.117991 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.bronze_store"
[0m17:11:29.118993 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.bronze_store"} */

  
    
        create or replace table `dbt-project`.`default`.`bronze_store`
      
      
  using delta
      
      
      
      
      
      
      
      as
      SELECT 
        *
 FROM
        `dbt-project`.`source`.`dim_store`
  
[0m17:11:29.118993 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:29.881761 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-248b-1b70-b525-1f4d199b69ee) - Created
[0m17:11:32.490196 [debug] [Thread-7 (]: SQL status: OK in 3.370 seconds
[0m17:11:32.491266 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-248b-1b70-b525-1f4d199b69ee, command-id=01f08ff3-24aa-1ea5-9d63-3ab2845d4e19) - Closing
[0m17:11:32.492327 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:32.493397 [debug] [Thread-7 (]: On model.dbt_eTl.bronze_store: Close
[0m17:11:32.493923 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-248b-1b70-b525-1f4d199b69ee) - Closing
[0m17:11:32.720174 [info ] [Thread-7 (]: 6 of 13 OK created sql table model default.bronze_store ........................ [[32mOK[0m in 3.62s]
[0m17:11:32.720174 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.bronze_store
[0m17:11:32.720174 [debug] [Thread-7 (]: Began running node model.dbt_eTl.source_gold_items
[0m17:11:32.720174 [info ] [Thread-7 (]: 7 of 13 START sql view model default.source_gold_items ......................... [RUN]
[0m17:11:32.720174 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.source_gold_items) - Creating connection
[0m17:11:32.720174 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.source_gold_items'
[0m17:11:32.720174 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.source_gold_items
[0m17:11:32.738151 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.source_gold_items"
[0m17:11:32.739310 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.source_gold_items
[0m17:11:32.742350 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m17:11:32.743403 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`source_gold_items`
[0m17:11:32.744416 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.source_gold_items"
[0m17:11:32.745323 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.source_gold_items"
[0m17:11:32.745323 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.source_gold_items"} */

  
  
  create or replace view `dbt-project`.`default`.`source_gold_items`
  
  as (
    With dedup_query AS (
SELECT
*,
row_number() over (partition by id order by updatedate) as dedup_flag
FROM
`dbt-project`.`source`.`item`
)
SELECT
id, name, category,updatedate
FROM dedup_query
WHERE dedup_flag = 1
  )

[0m17:11:32.746319 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:33.501801 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-26af-1f86-b116-e95b78c65fb4) - Created
[0m17:11:34.256807 [debug] [Thread-7 (]: SQL status: OK in 1.510 seconds
[0m17:11:34.256807 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-26af-1f86-b116-e95b78c65fb4, command-id=01f08ff3-26d1-161b-8424-4b8cc9afd385) - Closing
[0m17:11:34.256807 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:11:34.256807 [debug] [Thread-7 (]: On model.dbt_eTl.source_gold_items: Close
[0m17:11:34.256807 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-26af-1f86-b116-e95b78c65fb4) - Closing
[0m17:11:34.496676 [info ] [Thread-7 (]: 7 of 13 OK created sql view model default.source_gold_items .................... [[32mOK[0m in 1.78s]
[0m17:11:34.497679 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.source_gold_items
[0m17:11:34.498677 [debug] [Thread-7 (]: Began running node seed.dbt_eTl.lookup
[0m17:11:34.498677 [info ] [Thread-7 (]: 8 of 13 START seed file bronze.lookup .......................................... [RUN]
[0m17:11:34.499677 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=seed.dbt_eTl.lookup) - Creating connection
[0m17:11:34.500677 [debug] [Thread-7 (]: Acquiring new databricks connection 'seed.dbt_eTl.lookup'
[0m17:11:34.500677 [debug] [Thread-7 (]: Began compiling node seed.dbt_eTl.lookup
[0m17:11:34.500677 [debug] [Thread-7 (]: Began executing node seed.dbt_eTl.lookup
[0m17:11:34.542309 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m17:11:34.542309 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "seed.dbt_eTl.lookup"} */

    create or replace table `dbt-project`.`bronze`.`lookup` (`customer_id` bigint ,`first_name` string ,`last_name` string ,`email` string ,`phone` string ,`address` string ,`city` string ,`state` string ,`zip_code` bigint ,`country` string )
    
  using delta
    
    
    
    
    
  
[0m17:11:34.542309 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:35.432315 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-27d9-1a93-a35c-993c295b82f1) - Created
[0m17:11:37.006167 [debug] [Thread-7 (]: SQL status: OK in 2.460 seconds
[0m17:11:37.006167 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-27d9-1a93-a35c-993c295b82f1, command-id=01f08ff3-27fa-15c2-9e96-ca46c0a97bdc) - Closing
[0m17:11:37.023223 [debug] [Thread-7 (]: Using databricks connection "seed.dbt_eTl.lookup"
[0m17:11:37.023223 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: 
          insert overwrite `dbt-project`.`bronze`.`lookup` values
          (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)
      ...
[0m17:11:41.453837 [debug] [Thread-7 (]: SQL status: OK in 4.430 seconds
[0m17:11:41.455845 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-27d9-1a93-a35c-993c295b82f1, command-id=01f08ff3-28ea-1e99-ab96-25ec9f0be976) - Closing
[0m17:11:41.463872 [debug] [Thread-7 (]: Writing runtime SQL for node "seed.dbt_eTl.lookup"
[0m17:11:41.467636 [debug] [Thread-7 (]: On seed.dbt_eTl.lookup: Close
[0m17:11:41.467636 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-27d9-1a93-a35c-993c295b82f1) - Closing
[0m17:11:41.688951 [info ] [Thread-7 (]: 8 of 13 OK loaded seed file bronze.lookup ...................................... [[32mINSERT 3[0m in 7.19s]
[0m17:11:41.688951 [debug] [Thread-7 (]: Finished running node seed.dbt_eTl.lookup
[0m17:11:41.688951 [debug] [Thread-7 (]: Began running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m17:11:41.688951 [info ] [Thread-7 (]: 9 of 13 START test not_null_bronze_customer_customer_sk ........................ [RUN]
[0m17:11:41.688951 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0) - Creating connection
[0m17:11:41.688951 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0'
[0m17:11:41.699264 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m17:11:41.729391 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m17:11:41.731397 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m17:11:41.760577 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m17:11:41.760577 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"
[0m17:11:41.760577 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    



select customer_sk
from `dbt-project`.`default`.`bronze_customer`
where customer_sk is null



  
  
      
    ) dbt_internal_test
[0m17:11:41.760577 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:42.543153 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2c16-107c-b7c9-779307cbcb40) - Created
[0m17:11:43.680630 [debug] [Thread-7 (]: SQL status: OK in 1.920 seconds
[0m17:11:43.696708 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-2c16-107c-b7c9-779307cbcb40, command-id=01f08ff3-2c36-184d-9932-acb6f4671a74) - Closing
[0m17:11:43.697404 [debug] [Thread-7 (]: On test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0: Close
[0m17:11:43.697404 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2c16-107c-b7c9-779307cbcb40) - Closing
[0m17:11:44.010077 [info ] [Thread-7 (]: 9 of 13 PASS not_null_bronze_customer_customer_sk .............................. [[32mPASS[0m in 2.31s]
[0m17:11:44.010077 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.not_null_bronze_customer_customer_sk.ca97edbdc0
[0m17:11:44.012086 [debug] [Thread-7 (]: Began running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m17:11:44.012837 [info ] [Thread-7 (]: 10 of 13 START test unique_bronze_customer_customer_sk ......................... [RUN]
[0m17:11:44.013139 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a) - Creating connection
[0m17:11:44.013139 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a'
[0m17:11:44.013139 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m17:11:44.024945 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m17:11:44.026451 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m17:11:44.033091 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m17:11:44.035167 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"
[0m17:11:44.035167 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

select
    customer_sk as unique_field,
    count(*) as n_records

from `dbt-project`.`default`.`bronze_customer`
where customer_sk is not null
group by customer_sk
having count(*) > 1



  
  
      
    ) dbt_internal_test
[0m17:11:44.035167 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:44.794461 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2d6d-1718-ae16-629ce1e3f806) - Created
[0m17:11:45.928584 [debug] [Thread-7 (]: SQL status: OK in 1.890 seconds
[0m17:11:45.928584 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-2d6d-1718-ae16-629ce1e3f806, command-id=01f08ff3-2d8c-1adc-8647-46b4d5095052) - Closing
[0m17:11:45.928584 [debug] [Thread-7 (]: On test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a: Close
[0m17:11:45.928584 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2d6d-1718-ae16-629ce1e3f806) - Closing
[0m17:11:46.155943 [info ] [Thread-7 (]: 10 of 13 PASS unique_bronze_customer_customer_sk ............................... [[32mPASS[0m in 2.14s]
[0m17:11:46.155943 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.unique_bronze_customer_customer_sk.72b7ad8a6a
[0m17:11:46.155943 [debug] [Thread-7 (]: Began running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m17:11:46.155943 [info ] [Thread-7 (]: 11 of 13 START test accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [RUN]
[0m17:11:46.155943 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517) - Creating connection
[0m17:11:46.155943 [debug] [Thread-7 (]: Acquiring new databricks connection 'test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517'
[0m17:11:46.155943 [debug] [Thread-7 (]: Began compiling node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m17:11:46.178778 [debug] [Thread-7 (]: Writing injected SQL for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m17:11:46.178778 [debug] [Thread-7 (]: Began executing node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m17:11:46.178778 [debug] [Thread-7 (]: Writing runtime sql for node "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m17:11:46.178778 [debug] [Thread-7 (]: Using databricks connection "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"
[0m17:11:46.189253 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517"} */

    select
      count(*) as failures,
      count(*) != 0 as should_warn,
      count(*) != 0 as should_error
    from (
      
    
  
    
    

with all_values as (

    select
        store_name as value_field,
        count(*) as n_records

    from `dbt-project`.`default`.`bronze_store`
    group by store_name

)

select *
from all_values
where value_field not in (
    'MegaMart Toronto','MegaMart San Jose','MegaMart Austin','MegaMart Brooklyn','MegaMart Manhattan'
)



  
  
      
    ) dbt_internal_test
[0m17:11:46.190962 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:47.286475 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2ee6-1974-9061-a930de408c6e) - Created
[0m17:11:48.211383 [debug] [Thread-7 (]: SQL status: OK in 2.020 seconds
[0m17:11:48.211383 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-2ee6-1974-9061-a930de408c6e, command-id=01f08ff3-2f08-1cfe-bee4-c277c4e716ab) - Closing
[0m17:11:48.211383 [debug] [Thread-7 (]: On test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517: Close
[0m17:11:48.211383 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-2ee6-1974-9061-a930de408c6e) - Closing
[0m17:11:48.431262 [info ] [Thread-7 (]: 11 of 13 PASS accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan  [[32mPASS[0m in 2.28s]
[0m17:11:48.431262 [debug] [Thread-7 (]: Finished running node test.dbt_eTl.accepted_values_bronze_store_store_name__MegaMart_Toronto__MegaMart_San_Jose__MegaMart_Austin__MegaMart_Brooklyn__MegaMart_Manhattan.5f2c8be517
[0m17:11:48.431262 [debug] [Thread-7 (]: Began running node snapshot.dbt_eTl.gold_items
[0m17:11:48.431262 [info ] [Thread-7 (]: 12 of 13 START snapshot gold.gold_items ........................................ [RUN]
[0m17:11:48.431262 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=snapshot.dbt_eTl.gold_items) - Creating connection
[0m17:11:48.431262 [debug] [Thread-7 (]: Acquiring new databricks connection 'snapshot.dbt_eTl.gold_items'
[0m17:11:48.431262 [debug] [Thread-7 (]: Began compiling node snapshot.dbt_eTl.gold_items
[0m17:11:48.431262 [debug] [Thread-7 (]: Began executing node snapshot.dbt_eTl.gold_items
[0m17:11:48.490911 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:49.251285 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545) - Created
[0m17:11:49.256203 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:49.257206 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m17:11:49.771138 [debug] [Thread-7 (]: SQL status: OK in 0.510 seconds
[0m17:11:49.772469 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-3036-1803-bc45-0b7176029872) - Closing
[0m17:11:49.819327 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:49.819327 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

        
  
    create or replace temporary view `gold_items__dbt_tmp` as
      
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

  
    
[0m17:11:50.405767 [debug] [Thread-7 (]: SQL status: OK in 0.590 seconds
[0m17:11:50.405767 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-308d-10b6-bb40-7f20c46e9973) - Closing
[0m17:11:50.405767 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:50.405767 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:11:50.722458 [debug] [Thread-7 (]: SQL status: OK in 0.320 seconds
[0m17:11:50.734819 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-30e6-1e8c-a1d6-65cb6f44b151) - Closing
[0m17:11:50.734819 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:50.738437 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m17:11:51.366150 [debug] [Thread-7 (]: SQL status: OK in 0.630 seconds
[0m17:11:51.366150 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-3118-15e0-87ba-f4845f7e2aa9) - Closing
[0m17:11:51.366150 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:51.366150 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:11:51.676542 [debug] [Thread-7 (]: SQL status: OK in 0.310 seconds
[0m17:11:51.692198 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-3179-12f9-bf99-a702ca915ceb) - Closing
[0m17:11:51.692198 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:51.692198 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `dbt-project`.`gold`.`gold_items` AS JSON

  
[0m17:11:52.004488 [debug] [Thread-7 (]: SQL status: OK in 0.310 seconds
[0m17:11:52.004488 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-31a9-1afb-b298-a347b297e65e) - Closing
[0m17:11:52.026418 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:52.026948 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

    
  DESCRIBE TABLE EXTENDED `gold_items__dbt_tmp` AS JSON

  
[0m17:11:52.296342 [debug] [Thread-7 (]: SQL status: OK in 0.270 seconds
[0m17:11:52.296342 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-31dc-1608-8983-902c45555ac9) - Closing
[0m17:11:52.304246 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:52.304246 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        
    
    with snapshot_query as (

        select * from `dbt-project`.`default`.`source_gold_items`

    ),

    snapshotted_data as (

        select *, 
    
        id as dbt_unique_key
    

        from `dbt-project`.`gold`.`gold_items`
        where
            
		
		

		
                ( (dbt_valid_to = to_date('9999-12-31'))
 or dbt_valid_to is null )
            

    ),

    insertions_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            
  
  coalesce(nullif(updatedate, updatedate), to_date('9999-12-31'))
  as dbt_valid_to
,
            md5(coalesce(cast(id as string ), '')
         || '|' || coalesce(cast(updatedate as string ), '')
        ) as dbt_scd_id

        from snapshot_query
    ),

    updates_source_data as (

        select *, 
    
        id as dbt_unique_key
    
,
            updatedate as dbt_updated_at,
            updatedate as dbt_valid_from,
            updatedate as dbt_valid_to

        from snapshot_query
    ),

    insertions as (

        select
            'insert' as dbt_change_type,
            source_data.*

        from insertions_source_data as source_data
        left outer join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

            where 
    
        snapshotted_data.dbt_unique_key is null
    

            or (
    
        snapshotted_data.dbt_unique_key is not null
    
 and (
               (snapshotted_data.dbt_valid_from < source_data.updatedate)
            )

        )

    ),

    updates as (

        select
            'update' as dbt_change_type,
            source_data.*,
            snapshotted_data.dbt_scd_id

        from updates_source_data as source_data
        join snapshotted_data
            on 
    
        snapshotted_data.dbt_unique_key = source_data.dbt_unique_key
    

        where (
            (snapshotted_data.dbt_valid_from < source_data.updatedate)
        )
    )

    select * from insertions
    union all
    select * from updates

    ) as __dbt_sbq
    where false
    limit 0

[0m17:11:53.292136 [debug] [Thread-7 (]: SQL status: OK in 0.990 seconds
[0m17:11:53.292136 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:53.292136 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
select * from (
        select 
    current_timestamp()
 as dbt_snapshot_time
    ) as __dbt_sbq
    where false
    limit 0

[0m17:11:53.292136 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-3208-1dfb-921d-9aa407745e40) - Closing
[0m17:11:53.609563 [debug] [Thread-7 (]: SQL status: OK in 0.320 seconds
[0m17:11:53.609563 [debug] [Thread-7 (]: Writing runtime sql for node "snapshot.dbt_eTl.gold_items"
[0m17:11:53.609563 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:53.611570 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */

      merge into `dbt-project`.`gold`.`gold_items` as DBT_INTERNAL_DEST
    
      using `gold_items__dbt_tmp` as DBT_INTERNAL_SOURCE
    
    on DBT_INTERNAL_SOURCE.dbt_scd_id = DBT_INTERNAL_DEST.dbt_scd_id
    when matched
     
       and ( DBT_INTERNAL_DEST.dbt_valid_to = to_date('9999-12-31') or
             DBT_INTERNAL_DEST.dbt_valid_to is null )
     
     and DBT_INTERNAL_SOURCE.dbt_change_type in ('update', 'delete')
        then update
        set dbt_valid_to = DBT_INTERNAL_SOURCE.dbt_valid_to

    when not matched
     and DBT_INTERNAL_SOURCE.dbt_change_type = 'insert'
        then insert *
    ;

  
[0m17:11:53.611570 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-329f-10c4-909b-403c421a18ce) - Closing
[0m17:11:58.075816 [debug] [Thread-7 (]: SQL status: OK in 4.460 seconds
[0m17:11:58.091618 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-32ce-176f-915b-85464a0d5cc2) - Closing
[0m17:11:58.091618 [debug] [Thread-7 (]: Applying DROP to: `gold_items__dbt_tmp`
[0m17:11:58.091618 [debug] [Thread-7 (]: Using databricks connection "snapshot.dbt_eTl.gold_items"
[0m17:11:58.107377 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "snapshot.dbt_eTl.gold_items"} */
DROP VIEW IF EXISTS `gold_items__dbt_tmp`
[0m17:11:58.387148 [debug] [Thread-7 (]: SQL status: OK in 0.280 seconds
[0m17:11:58.387148 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545, command-id=01f08ff3-357c-119f-be3e-1f5f53b930ed) - Closing
[0m17:11:58.387148 [debug] [Thread-7 (]: On snapshot.dbt_eTl.gold_items: Close
[0m17:11:58.387148 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-3016-13a4-ab9b-fda96d504545) - Closing
[0m17:11:58.641699 [info ] [Thread-7 (]: 12 of 13 OK snapshotted gold.gold_items ........................................ [[32mOK[0m in 10.21s]
[0m17:11:58.641699 [debug] [Thread-7 (]: Finished running node snapshot.dbt_eTl.gold_items
[0m17:11:58.641699 [debug] [Thread-7 (]: Began running node model.dbt_eTl.silver_sales
[0m17:11:58.641699 [info ] [Thread-7 (]: 13 of 13 START sql view model default.silver_sales ............................. [RUN]
[0m17:11:58.641699 [debug] [Thread-7 (]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=model.dbt_eTl.silver_sales) - Creating connection
[0m17:11:58.641699 [debug] [Thread-7 (]: Acquiring new databricks connection 'model.dbt_eTl.silver_sales'
[0m17:11:58.641699 [debug] [Thread-7 (]: Began compiling node model.dbt_eTl.silver_sales
[0m17:11:58.641699 [debug] [Thread-7 (]: Writing injected SQL for node "model.dbt_eTl.silver_sales"
[0m17:11:58.641699 [debug] [Thread-7 (]: Began executing node model.dbt_eTl.silver_sales
[0m17:11:58.641699 [debug] [Thread-7 (]: MATERIALIZING VIEW
[0m17:11:58.654024 [debug] [Thread-7 (]: Creating view `dbt-project`.`default`.`silver_sales`
[0m17:11:58.655354 [debug] [Thread-7 (]: Writing runtime sql for node "model.dbt_eTl.silver_sales"
[0m17:11:58.656368 [debug] [Thread-7 (]: Using databricks connection "model.dbt_eTl.silver_sales"
[0m17:11:58.657363 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: /* {"app": "dbt", "dbt_version": "1.10.11", "dbt_databricks_version": "1.10.9", "databricks_sql_connector_version": "4.1.2", "profile_name": "dbt_eTl", "target_name": "dev", "node_id": "model.dbt_eTl.silver_sales"} */

  
  
  create or replace view `dbt-project`.`default`.`silver_sales`
  
  as (
    with sales as (
    SELECT 
    sales_id,
    payment_method,
    product_sk,
    customer_sk,
    gross_amount,
    
    unit_price*quantity
 as cal_gross_amt
    from `dbt-project`.`bronze`.`bronze_sales`
),
products as (
    SELECT 
    product_sk,
    category
    from `dbt-project`.`default`.`bronze_dim_product`
),
customer as (
    SELECT 
    customer_sk,
    gender
    from `dbt-project`.`default`.`bronze_customer`

),

joinedtable as (SELECT 
    sales.sales_id,
    sales.gross_amount,
    sales.cal_gross_amt,
    products.category,
    sales.payment_method,
    customer.gender
from sales join products on sales.product_sk = products.product_sk
join customer on sales.customer_sk = customer.customer_sk)

SELECT category,
gender,
round(sum(gross_amount), 2) as total_sales
from joinedtable
group by all
---- category, gender, payment_method
  )

[0m17:11:58.658442 [debug] [Thread-7 (]: Opening a new connection, currently in state init
[0m17:11:59.468475 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-362a-1543-99a9-67a6d0a6be1d) - Created
[0m17:12:00.329347 [debug] [Thread-7 (]: SQL status: OK in 1.670 seconds
[0m17:12:00.330346 [debug] [Thread-7 (]: Databricks adapter: Cursor(session-id=01f08ff3-362a-1543-99a9-67a6d0a6be1d, command-id=01f08ff3-364d-12ab-b284-d4a20a503f07) - Closing
[0m17:12:00.330346 [debug] [Thread-7 (]: Applying tags to relation None
[0m17:12:00.331346 [debug] [Thread-7 (]: On model.dbt_eTl.silver_sales: Close
[0m17:12:00.332347 [debug] [Thread-7 (]: Databricks adapter: Connection(session-id=01f08ff3-362a-1543-99a9-67a6d0a6be1d) - Closing
[0m17:12:00.553005 [info ] [Thread-7 (]: 13 of 13 OK created sql view model default.silver_sales ........................ [[32mOK[0m in 1.91s]
[0m17:12:00.553005 [debug] [Thread-7 (]: Finished running node model.dbt_eTl.silver_sales
[0m17:12:00.553005 [debug] [MainThread]: Databricks adapter: DatabricksDBTConnection(session-id=None, name=master) - Creating connection
[0m17:12:00.553005 [debug] [MainThread]: Acquiring new databricks connection 'master'
[0m17:12:00.553005 [info ] [MainThread]: 
[0m17:12:00.553005 [info ] [MainThread]: Finished running 1 seed, 1 snapshot, 3 table models, 3 data tests, 5 view models in 0 hours 2 minutes and 6.62 seconds (126.62s).
[0m17:12:00.553005 [debug] [MainThread]: Command end result
[0m17:12:00.592370 [debug] [MainThread]: Wrote artifact WritableManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\manifest.json
[0m17:12:00.607114 [debug] [MainThread]: Wrote artifact SemanticManifest to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\semantic_manifest.json
[0m17:12:00.607114 [debug] [MainThread]: Wrote artifact RunExecutionResult to C:\Users\ADETUNJI\Documents\new_school_files\dbt-transformation\dbt_eTl\target\run_results.json
[0m17:12:00.607114 [info ] [MainThread]: 
[0m17:12:00.607114 [info ] [MainThread]: [32mCompleted successfully[0m
[0m17:12:00.607114 [info ] [MainThread]: 
[0m17:12:00.623880 [info ] [MainThread]: Done. PASS=13 WARN=0 ERROR=0 SKIP=0 NO-OP=0 TOTAL=13
[0m17:12:00.626418 [debug] [MainThread]: Command `dbt build` succeeded at 17:12:00.626418 after 132.23 seconds
[0m17:12:00.626418 [debug] [MainThread]: Flushing usage events
[0m12:45:08.569502 [debug] [MainThread]: Got an exception trying to initialize tracking


============================== 12:45:08.694331 | d0f88add-e0e4-4c6e-89c2-a98b3805c4c5 ==============================
[0m12:45:08.694331 [info ] [MainThread]: Running with dbt=1.10.11
[0m12:45:08.694884 [debug] [MainThread]: running dbt with arguments {'partial_parse': 'True', 'write_json': 'True', 'send_anonymous_usage_stats': 'True', 'use_colors': 'True', 'cache_selected_only': 'False', 'target_path': 'None', 'warn_error': 'None', 'invocation_command': 'dbt ', 'log_format': 'default', 'version_check': 'True', 'introspect': 'True', 'debug': 'False', 'log_cache_events': 'False', 'fail_fast': 'False', 'no_print': 'None', 'quiet': 'False', 'empty': 'None', 'use_experimental_parser': 'False', 'printer_width': '80', 'indirect_selection': 'eager', 'log_path': 'c:\\Users\\ADETUNJI\\Documents\\new_school_files\\dbt-transformation\\dbt_eTl\\logs', 'profiles_dir': 'C:\\Users\\ADETUNJI\\.dbt', 'warn_error_options': 'WarnErrorOptionsV2(error=[], warn=[], silence=[])', 'static_parser': 'True'}
[0m12:45:09.173396 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:45:09.175985 [info ] [MainThread]: Warning: No packages were found in packages.yml
[0m12:45:09.177996 [debug] [MainThread]: Command `cli deps` succeeded at 12:45:09.175985 after 0.73 seconds
[0m12:45:09.178550 [debug] [MainThread]: Flushing usage events
